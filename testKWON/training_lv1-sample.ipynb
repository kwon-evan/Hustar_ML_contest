{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "none",
     "id": "b06072eb-fd2a-43e1-a702-67ea305d63db",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import DataCollatorWithPadding, TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "from datasets import load_metric, load_dataset, load_from_disk\n",
    "import torch\n",
    "from transformers import RobertaForSequenceClassification, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-42082c856f8fca10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/piai/.cache/huggingface/datasets/csv/default-42082c856f8fca10/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c57f3d0245204fe8b487d388682376ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e431165d0d3403ab209ab6eaba5830d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/piai/.cache/huggingface/datasets/csv/default-42082c856f8fca10/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8201f1baf4dd4ec0ac6ab8a7d4cf71ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-8eafd8204a1f3d6a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/piai/.cache/huggingface/datasets/csv/default-8eafd8204a1f3d6a/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80c891c52352476ababbd59e7660a3ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc894fd91c804d4e98b8c674b1ac7d3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/piai/.cache/huggingface/datasets/csv/default-8eafd8204a1f3d6a/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91b71c4409ac4d8b97fc888dc78591e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78342fde1b874c71a7ec40122ba9c1df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5133767 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ca66b5299114c4594a34c556ef4f952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59389 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL = \"microsoft/graphcodebert-base\"\n",
    "TRAIN_INPUT = \"./data/train_data.csv\"\n",
    "VALID_INPUT = \"./data/valid_data.csv\"\n",
    "MAX_LEN = 512\n",
    "\n",
    "train_dataset = load_dataset(\"csv\", data_files=TRAIN_INPUT)['train']\n",
    "valid_dataset = load_dataset(\"csv\", data_files=VALID_INPUT)[\"train\"]\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "tokenizer.truncation_side='left'\n",
    "\n",
    "def example_fn(examples):\n",
    "    outputs = tokenizer(examples['code1'], examples['code2'], padding=True, max_length=MAX_LEN,truncation=True,)\n",
    "    if 'similar' in examples:\n",
    "        outputs[\"labels\"] = examples[\"similar\"]\n",
    "    return outputs\n",
    "\n",
    "train_dataset = train_dataset.map(example_fn, remove_columns=['code1', 'code2', 'similar'])\n",
    "valid_dataset = valid_dataset.map(example_fn, remove_columns=['code1', 'code2', 'similar'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "none",
     "id": "861f71b9-8980-4173-9674-431edd014f88",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/graphcodebert-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "MODEL = \"microsoft/graphcodebert-base\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = RobertaForSequenceClassification.from_pretrained(MODEL)\n",
    "model.to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "tokenizer.truncation_side = 'left'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "none",
     "id": "4528f711-89f7-481a-bdb5-13c55ebedab1",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "_metric = load_metric(\"glue\", \"sst2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "none",
     "id": "5c3a4b33-874d-438e-974b-c3736fcfc259",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def metric_fn(p):\n",
    "    preds, labels = p\n",
    "    output =  _metric.compute(references=labels, predictions=np.argmax(preds, axis=-1))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "none",
     "id": "4514262a-bedb-4e3a-a3e8-9697e07999f5",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir='./models/',\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=3,\n",
    "    disable_tqdm = False,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    save_strategy=\"steps\",\n",
    "    logging_strategy=\"steps\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    learning_rate=1e-5,\n",
    "    optim='adamw_torch',\n",
    "    # metric_for_best_model= \"f1\",\n",
    "    save_total_limit=5,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        data_collator=_collator,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=valid_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics= metric_fn,\n",
    "        callbacks = [EarlyStoppingCallback(early_stopping_patience=10)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "none",
     "id": "4e659920-e286-4cfa-af72-6dc46f766183",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "from knockknock import discord_sender\n",
    "\n",
    "webhook_url='https://discord.com/api/webhooks/981021972697858078/cKpZXsyxyFGptLsMiFfWdEbjwavkO0qgkgWGW3fyYeBxMkJFebDq9U5M4vgDibgM3Ew6'\n",
    "\n",
    "@discord_sender(webhook_url=webhook_url)\n",
    "def do_train():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "none",
     "id": "219c0af9-96d3-4a56-b494-d478cd7bb144",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 5133767\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 4\n",
      "  Total optimization steps = 481290\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36000' max='481290' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 36000/481290 26:09:59 < 323:40:34, 0.38 it/s, Epoch 0/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.368400</td>\n",
       "      <td>0.313474</td>\n",
       "      <td>0.881409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.180100</td>\n",
       "      <td>0.275722</td>\n",
       "      <td>0.905471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.153300</td>\n",
       "      <td>0.184461</td>\n",
       "      <td>0.934011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.122900</td>\n",
       "      <td>0.199417</td>\n",
       "      <td>0.930728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.113600</td>\n",
       "      <td>0.309453</td>\n",
       "      <td>0.917476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.107600</td>\n",
       "      <td>0.155413</td>\n",
       "      <td>0.951843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.095300</td>\n",
       "      <td>0.186740</td>\n",
       "      <td>0.947061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.087600</td>\n",
       "      <td>0.146518</td>\n",
       "      <td>0.956187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.095100</td>\n",
       "      <td>0.140978</td>\n",
       "      <td>0.961138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.085400</td>\n",
       "      <td>0.141808</td>\n",
       "      <td>0.960346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>0.194367</td>\n",
       "      <td>0.950765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.076000</td>\n",
       "      <td>0.144660</td>\n",
       "      <td>0.962215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.068100</td>\n",
       "      <td>0.142811</td>\n",
       "      <td>0.963950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.066700</td>\n",
       "      <td>0.131822</td>\n",
       "      <td>0.965802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.061300</td>\n",
       "      <td>0.136832</td>\n",
       "      <td>0.964253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.069500</td>\n",
       "      <td>0.117852</td>\n",
       "      <td>0.967267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.057800</td>\n",
       "      <td>0.132647</td>\n",
       "      <td>0.970129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.068200</td>\n",
       "      <td>0.108123</td>\n",
       "      <td>0.971409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.058500</td>\n",
       "      <td>0.104034</td>\n",
       "      <td>0.971931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.053600</td>\n",
       "      <td>0.099530</td>\n",
       "      <td>0.972251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.058100</td>\n",
       "      <td>0.127305</td>\n",
       "      <td>0.966728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.051000</td>\n",
       "      <td>0.126900</td>\n",
       "      <td>0.969355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.043300</td>\n",
       "      <td>0.098917</td>\n",
       "      <td>0.975938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.040700</td>\n",
       "      <td>0.098458</td>\n",
       "      <td>0.975534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.051600</td>\n",
       "      <td>0.110454</td>\n",
       "      <td>0.973682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.051600</td>\n",
       "      <td>0.089896</td>\n",
       "      <td>0.976494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.048600</td>\n",
       "      <td>0.092217</td>\n",
       "      <td>0.976898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.045600</td>\n",
       "      <td>0.091828</td>\n",
       "      <td>0.978262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.042100</td>\n",
       "      <td>0.104733</td>\n",
       "      <td>0.974810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.043000</td>\n",
       "      <td>0.093072</td>\n",
       "      <td>0.976629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.046400</td>\n",
       "      <td>0.084546</td>\n",
       "      <td>0.979020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.035400</td>\n",
       "      <td>0.102500</td>\n",
       "      <td>0.977521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.040100</td>\n",
       "      <td>0.081575</td>\n",
       "      <td>0.978447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.040400</td>\n",
       "      <td>0.091193</td>\n",
       "      <td>0.977639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.085136</td>\n",
       "      <td>0.978986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>0.156460</td>\n",
       "      <td>0.969691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.041800</td>\n",
       "      <td>0.083278</td>\n",
       "      <td>0.979356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.038300</td>\n",
       "      <td>0.093836</td>\n",
       "      <td>0.979542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>0.033900</td>\n",
       "      <td>0.092536</td>\n",
       "      <td>0.979895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.032100</td>\n",
       "      <td>0.087889</td>\n",
       "      <td>0.979845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>0.035700</td>\n",
       "      <td>0.087459</td>\n",
       "      <td>0.980518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.029400</td>\n",
       "      <td>0.096364</td>\n",
       "      <td>0.979693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21500</td>\n",
       "      <td>0.036200</td>\n",
       "      <td>0.078430</td>\n",
       "      <td>0.982505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.031300</td>\n",
       "      <td>0.075283</td>\n",
       "      <td>0.981478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22500</td>\n",
       "      <td>0.036500</td>\n",
       "      <td>0.084175</td>\n",
       "      <td>0.979575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.031700</td>\n",
       "      <td>0.082328</td>\n",
       "      <td>0.982606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23500</td>\n",
       "      <td>0.034100</td>\n",
       "      <td>0.085372</td>\n",
       "      <td>0.981966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.030300</td>\n",
       "      <td>0.080979</td>\n",
       "      <td>0.982758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24500</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.072154</td>\n",
       "      <td>0.982993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.030200</td>\n",
       "      <td>0.091241</td>\n",
       "      <td>0.979979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25500</td>\n",
       "      <td>0.027300</td>\n",
       "      <td>0.073842</td>\n",
       "      <td>0.982488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.027700</td>\n",
       "      <td>0.074348</td>\n",
       "      <td>0.983381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26500</td>\n",
       "      <td>0.026500</td>\n",
       "      <td>0.067989</td>\n",
       "      <td>0.983616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.026700</td>\n",
       "      <td>0.068325</td>\n",
       "      <td>0.984761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27500</td>\n",
       "      <td>0.027400</td>\n",
       "      <td>0.066402</td>\n",
       "      <td>0.983987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.024800</td>\n",
       "      <td>0.074132</td>\n",
       "      <td>0.984543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28500</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>0.067422</td>\n",
       "      <td>0.983179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>0.023800</td>\n",
       "      <td>0.078157</td>\n",
       "      <td>0.982185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29500</td>\n",
       "      <td>0.025100</td>\n",
       "      <td>0.105657</td>\n",
       "      <td>0.978986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.025700</td>\n",
       "      <td>0.081534</td>\n",
       "      <td>0.982589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30500</td>\n",
       "      <td>0.024300</td>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.983465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>0.029200</td>\n",
       "      <td>0.055644</td>\n",
       "      <td>0.985149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31500</td>\n",
       "      <td>0.029500</td>\n",
       "      <td>0.058811</td>\n",
       "      <td>0.984879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.027100</td>\n",
       "      <td>0.056987</td>\n",
       "      <td>0.984846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32500</td>\n",
       "      <td>0.024200</td>\n",
       "      <td>0.072275</td>\n",
       "      <td>0.983734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>0.023500</td>\n",
       "      <td>0.070058</td>\n",
       "      <td>0.985014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33500</td>\n",
       "      <td>0.021400</td>\n",
       "      <td>0.068047</td>\n",
       "      <td>0.985873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.024400</td>\n",
       "      <td>0.062432</td>\n",
       "      <td>0.985435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34500</td>\n",
       "      <td>0.022500</td>\n",
       "      <td>0.069712</td>\n",
       "      <td>0.984442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>0.022500</td>\n",
       "      <td>0.075452</td>\n",
       "      <td>0.984660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35500</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.079133</td>\n",
       "      <td>0.984896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>0.070885</td>\n",
       "      <td>0.985418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-500\n",
      "Configuration saved in ./models/checkpoint-500/config.json\n",
      "Model weights saved in ./models/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-500/special_tokens_map.json\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-1000\n",
      "Configuration saved in ./models/checkpoint-1000/config.json\n",
      "Model weights saved in ./models/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-1000/special_tokens_map.json\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-1500\n",
      "Configuration saved in ./models/checkpoint-1500/config.json\n",
      "Model weights saved in ./models/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-1500/special_tokens_map.json\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-2000\n",
      "Configuration saved in ./models/checkpoint-2000/config.json\n",
      "Model weights saved in ./models/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-2000/special_tokens_map.json\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-2500\n",
      "Configuration saved in ./models/checkpoint-2500/config.json\n",
      "Model weights saved in ./models/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-2500/special_tokens_map.json\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-3000\n",
      "Configuration saved in ./models/checkpoint-3000/config.json\n",
      "Model weights saved in ./models/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-3000/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-500] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-3500\n",
      "Configuration saved in ./models/checkpoint-3500/config.json\n",
      "Model weights saved in ./models/checkpoint-3500/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-3500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-3500/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-1000] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-4000\n",
      "Configuration saved in ./models/checkpoint-4000/config.json\n",
      "Model weights saved in ./models/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-4000/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-1500] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-4500\n",
      "Configuration saved in ./models/checkpoint-4500/config.json\n",
      "Model weights saved in ./models/checkpoint-4500/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-4500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-4500/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-2000] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-5000\n",
      "Configuration saved in ./models/checkpoint-5000/config.json\n",
      "Model weights saved in ./models/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-5000/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-2500] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-5500\n",
      "Configuration saved in ./models/checkpoint-5500/config.json\n",
      "Model weights saved in ./models/checkpoint-5500/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-5500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-5500/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-3000] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-6000\n",
      "Configuration saved in ./models/checkpoint-6000/config.json\n",
      "Model weights saved in ./models/checkpoint-6000/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-6000/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-3500] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-6500\n",
      "Configuration saved in ./models/checkpoint-6500/config.json\n",
      "Model weights saved in ./models/checkpoint-6500/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-6500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-6500/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-4000] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-7000\n",
      "Configuration saved in ./models/checkpoint-7000/config.json\n",
      "Model weights saved in ./models/checkpoint-7000/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-7000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-7000/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-4500] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-7500\n",
      "Configuration saved in ./models/checkpoint-7500/config.json\n",
      "Model weights saved in ./models/checkpoint-7500/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-7500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-7500/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-5000] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-8000\n",
      "Configuration saved in ./models/checkpoint-8000/config.json\n",
      "Model weights saved in ./models/checkpoint-8000/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-8000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-8000/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-5500] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-8500\n",
      "Configuration saved in ./models/checkpoint-8500/config.json\n",
      "Model weights saved in ./models/checkpoint-8500/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-8500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-8500/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-6000] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-9000\n",
      "Configuration saved in ./models/checkpoint-9000/config.json\n",
      "Model weights saved in ./models/checkpoint-9000/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-9000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-9000/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-6500] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-9500\n",
      "Configuration saved in ./models/checkpoint-9500/config.json\n",
      "Model weights saved in ./models/checkpoint-9500/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-9500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-9500/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-7000] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-10000\n",
      "Configuration saved in ./models/checkpoint-10000/config.json\n",
      "Model weights saved in ./models/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-10000/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-7500] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-10500\n",
      "Configuration saved in ./models/checkpoint-10500/config.json\n",
      "Model weights saved in ./models/checkpoint-10500/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-10500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-10500/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-8000] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-11000\n",
      "Configuration saved in ./models/checkpoint-11000/config.json\n",
      "Model weights saved in ./models/checkpoint-11000/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-11000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-11000/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-8500] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-11500\n",
      "Configuration saved in ./models/checkpoint-11500/config.json\n",
      "Model weights saved in ./models/checkpoint-11500/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-11500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-11500/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-9000] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-12000\n",
      "Configuration saved in ./models/checkpoint-12000/config.json\n",
      "Model weights saved in ./models/checkpoint-12000/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-12000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-12000/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-9500] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-12500\n",
      "Configuration saved in ./models/checkpoint-12500/config.json\n",
      "Model weights saved in ./models/checkpoint-12500/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-12500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-12500/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-10000] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-13000\n",
      "Configuration saved in ./models/checkpoint-13000/config.json\n",
      "Model weights saved in ./models/checkpoint-13000/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-13000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-13000/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-10500] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-13500\n",
      "Configuration saved in ./models/checkpoint-13500/config.json\n",
      "Model weights saved in ./models/checkpoint-13500/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-13500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-13500/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-11000] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-14000\n",
      "Configuration saved in ./models/checkpoint-14000/config.json\n",
      "Model weights saved in ./models/checkpoint-14000/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-14000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-14000/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-11500] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-14500\n",
      "Configuration saved in ./models/checkpoint-14500/config.json\n",
      "Model weights saved in ./models/checkpoint-14500/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-14500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-14500/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-12000] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-15000\n",
      "Configuration saved in ./models/checkpoint-15000/config.json\n",
      "Model weights saved in ./models/checkpoint-15000/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-15000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-15000/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-12500] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-15500\n",
      "Configuration saved in ./models/checkpoint-15500/config.json\n",
      "Model weights saved in ./models/checkpoint-15500/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-15500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-15500/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-13000] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-16000\n",
      "Configuration saved in ./models/checkpoint-16000/config.json\n",
      "Model weights saved in ./models/checkpoint-16000/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-16000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-16000/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-13500] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-16500\n",
      "Configuration saved in ./models/checkpoint-16500/config.json\n",
      "Model weights saved in ./models/checkpoint-16500/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-16500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-16500/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-14000] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-17000\n",
      "Configuration saved in ./models/checkpoint-17000/config.json\n",
      "Model weights saved in ./models/checkpoint-17000/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-17000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-17000/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-14500] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-17500\n",
      "Configuration saved in ./models/checkpoint-17500/config.json\n",
      "Model weights saved in ./models/checkpoint-17500/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-17500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-17500/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-15000] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-18000\n",
      "Configuration saved in ./models/checkpoint-18000/config.json\n",
      "Model weights saved in ./models/checkpoint-18000/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-18000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-18000/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-15500] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-18500\n",
      "Configuration saved in ./models/checkpoint-18500/config.json\n",
      "Model weights saved in ./models/checkpoint-18500/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-18500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-18500/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-16000] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-19000\n",
      "Configuration saved in ./models/checkpoint-19000/config.json\n",
      "Model weights saved in ./models/checkpoint-19000/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-19000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-19000/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-17000] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-19500\n",
      "Configuration saved in ./models/checkpoint-19500/config.json\n",
      "Model weights saved in ./models/checkpoint-19500/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-19500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-19500/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-17500] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-20000\n",
      "Configuration saved in ./models/checkpoint-20000/config.json\n",
      "Model weights saved in ./models/checkpoint-20000/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-20000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-20000/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-18000] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-20500\n",
      "Configuration saved in ./models/checkpoint-20500/config.json\n",
      "Model weights saved in ./models/checkpoint-20500/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-20500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-20500/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-18500] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-21000\n",
      "Configuration saved in ./models/checkpoint-21000/config.json\n",
      "Model weights saved in ./models/checkpoint-21000/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-21000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-21000/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-19000] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-21500\n",
      "Configuration saved in ./models/checkpoint-21500/config.json\n",
      "Model weights saved in ./models/checkpoint-21500/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-21500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-21500/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-16500] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-22000\n",
      "Configuration saved in ./models/checkpoint-22000/config.json\n",
      "Model weights saved in ./models/checkpoint-22000/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-22000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-22000/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-19500] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-22500\n",
      "Configuration saved in ./models/checkpoint-22500/config.json\n",
      "Model weights saved in ./models/checkpoint-22500/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-22500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-22500/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-20000] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-23000\n",
      "Configuration saved in ./models/checkpoint-23000/config.json\n",
      "Model weights saved in ./models/checkpoint-23000/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-23000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-23000/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-20500] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-23500\n",
      "Configuration saved in ./models/checkpoint-23500/config.json\n",
      "Model weights saved in ./models/checkpoint-23500/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-23500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-23500/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-21000] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-24000\n",
      "Configuration saved in ./models/checkpoint-24000/config.json\n",
      "Model weights saved in ./models/checkpoint-24000/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-24000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-24000/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-21500] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-24500\n",
      "Configuration saved in ./models/checkpoint-24500/config.json\n",
      "Model weights saved in ./models/checkpoint-24500/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-24500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-24500/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-22000] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-25000\n",
      "Configuration saved in ./models/checkpoint-25000/config.json\n",
      "Model weights saved in ./models/checkpoint-25000/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-25000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-25000/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-22500] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-25500\n",
      "Configuration saved in ./models/checkpoint-25500/config.json\n",
      "Model weights saved in ./models/checkpoint-25500/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-25500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-25500/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-23000] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-26000\n",
      "Configuration saved in ./models/checkpoint-26000/config.json\n",
      "Model weights saved in ./models/checkpoint-26000/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-26000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-26000/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-23500] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-26500\n",
      "Configuration saved in ./models/checkpoint-26500/config.json\n",
      "Model weights saved in ./models/checkpoint-26500/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-26500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-26500/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-24000] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-27000\n",
      "Configuration saved in ./models/checkpoint-27000/config.json\n",
      "Model weights saved in ./models/checkpoint-27000/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-27000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-27000/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-24500] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-27500\n",
      "Configuration saved in ./models/checkpoint-27500/config.json\n",
      "Model weights saved in ./models/checkpoint-27500/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-27500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-27500/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-25000] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-28000\n",
      "Configuration saved in ./models/checkpoint-28000/config.json\n",
      "Model weights saved in ./models/checkpoint-28000/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-28000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-28000/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-25500] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-28500\n",
      "Configuration saved in ./models/checkpoint-28500/config.json\n",
      "Model weights saved in ./models/checkpoint-28500/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-28500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-28500/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-26000] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-29000\n",
      "Configuration saved in ./models/checkpoint-29000/config.json\n",
      "Model weights saved in ./models/checkpoint-29000/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-29000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-29000/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-26500] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-29500\n",
      "Configuration saved in ./models/checkpoint-29500/config.json\n",
      "Model weights saved in ./models/checkpoint-29500/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-29500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-29500/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-27000] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-30000\n",
      "Configuration saved in ./models/checkpoint-30000/config.json\n",
      "Model weights saved in ./models/checkpoint-30000/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-30000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-30000/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-28000] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-30500\n",
      "Configuration saved in ./models/checkpoint-30500/config.json\n",
      "Model weights saved in ./models/checkpoint-30500/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-30500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-30500/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-28500] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-31000\n",
      "Configuration saved in ./models/checkpoint-31000/config.json\n",
      "Model weights saved in ./models/checkpoint-31000/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-31000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-31000/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-27500] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-31500\n",
      "Configuration saved in ./models/checkpoint-31500/config.json\n",
      "Model weights saved in ./models/checkpoint-31500/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-31500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-31500/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-29000] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-32000\n",
      "Configuration saved in ./models/checkpoint-32000/config.json\n",
      "Model weights saved in ./models/checkpoint-32000/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-32000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-32000/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-29500] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-32500\n",
      "Configuration saved in ./models/checkpoint-32500/config.json\n",
      "Model weights saved in ./models/checkpoint-32500/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-32500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-32500/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-30000] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-33000\n",
      "Configuration saved in ./models/checkpoint-33000/config.json\n",
      "Model weights saved in ./models/checkpoint-33000/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-33000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-33000/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-30500] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-33500\n",
      "Configuration saved in ./models/checkpoint-33500/config.json\n",
      "Model weights saved in ./models/checkpoint-33500/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-33500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-33500/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-31500] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-34000\n",
      "Configuration saved in ./models/checkpoint-34000/config.json\n",
      "Model weights saved in ./models/checkpoint-34000/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-34000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-34000/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-32000] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-34500\n",
      "Configuration saved in ./models/checkpoint-34500/config.json\n",
      "Model weights saved in ./models/checkpoint-34500/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-34500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-34500/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-32500] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-35000\n",
      "Configuration saved in ./models/checkpoint-35000/config.json\n",
      "Model weights saved in ./models/checkpoint-35000/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-35000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-35000/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-33000] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-35500\n",
      "Configuration saved in ./models/checkpoint-35500/config.json\n",
      "Model weights saved in ./models/checkpoint-35500/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-35500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-35500/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-33500] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-36000\n",
      "Configuration saved in ./models/checkpoint-36000/config.json\n",
      "Model weights saved in ./models/checkpoint-36000/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-36000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-36000/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-34000] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./models/checkpoint-31000 (score: 0.05564408004283905).\n"
     ]
    }
   ],
   "source": [
    "do_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 512\n",
    "def example_fn(examples):\n",
    "    outputs = tokenizer(examples['code1'], examples['code2'], padding=True, max_length=MAX_LEN,truncation=True)\n",
    "    if 'similar' in examples:\n",
    "        outputs[\"labels\"] = examples[\"similar\"]\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "none",
     "id": "b2960977-35fb-4563-a6aa-a738b0f660f3",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-034bfdc908dab38a\n",
      "Reusing dataset csv (/home/piai/.cache/huggingface/datasets/csv/default-034bfdc908dab38a/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "498faef826b84251b4cd8890740e6c02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/piai/.cache/huggingface/datasets/csv/default-034bfdc908dab38a/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-32e57adf0ac1f496.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: pair_id. If pair_id are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 179700\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2808' max='2808' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2808/2808 31:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "TEST = \"./data/test.csv\"\n",
    "SUB = \"./data/sample_submission.csv\"\n",
    "\n",
    "test_dataset = load_dataset(\"csv\", data_files=TEST)[\"train\"]\n",
    "test_dataset = test_dataset.map(example_fn, remove_columns=[\"code1\", \"code2\"])\n",
    "\n",
    "predictions = trainer.predict(test_dataset)\n",
    "\n",
    "df = pd.read_csv(SUB)\n",
    "df[\"similar\"] = np.argmax(predictions.predictions, axis=-1)\n",
    "df.to_csv(\"./submissions/submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "canvas": {
   "colorPalette": [
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit"
   ],
   "parameters": [],
   "version": "1.0"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
