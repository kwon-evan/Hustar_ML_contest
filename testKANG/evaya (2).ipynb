{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22308,"status":"ok","timestamp":1654737651878,"user":{"displayName":"Lainie Kang","userId":"17932680864583243195"},"user_tz":-540},"id":"S5FigcyWzxgi","outputId":"58668f33-57f6-4a34-f837-cb535b21a0fc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"markdown","metadata":{"id":"0uSilsCYzfL9"},"source":["# pip, import"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24365,"status":"ok","timestamp":1654737681024,"user":{"displayName":"Lainie Kang","userId":"17932680864583243195"},"user_tz":-540},"id":"QnfeB1olcFnz","outputId":"13d78815-9c1f-4458-f06c-b5a8bb9f333a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n","\u001b[K     |████████████████████████████████| 4.2 MB 6.7 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 60.9 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 73.9 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n","\u001b[K     |████████████████████████████████| 86 kB 6.5 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.7.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.19.2)\n","Collecting datasets\n","  Downloading datasets-2.2.2-py3-none-any.whl (346 kB)\n","\u001b[K     |████████████████████████████████| 346 kB 8.1 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.7.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Collecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Collecting fsspec[http]>=2021.05.0\n","  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n","\u001b[K     |████████████████████████████████| 140 kB 76.9 MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Collecting xxhash\n","  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 57.8 MB/s \n","\u001b[?25hCollecting aiohttp\n","  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 79.3 MB/s \n","\u001b[?25hCollecting dill<0.3.5\n","  Downloading dill-0.3.4-py2.py3-none-any.whl (86 kB)\n","\u001b[K     |████████████████████████████████| 86 kB 7.8 MB/s \n","\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 106.9 MB/s \n","\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n","\u001b[K     |████████████████████████████████| 271 kB 96.2 MB/s \n","\u001b[?25hCollecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n","\u001b[K     |████████████████████████████████| 94 kB 4.3 MB/s \n","\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n","Collecting asynctest==0.13.0\n","  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n","\u001b[K     |████████████████████████████████| 144 kB 97.7 MB/s \n","\u001b[?25hCollecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n","Collecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.12.2-py37-none-any.whl (112 kB)\n","\u001b[K     |████████████████████████████████| 112 kB 79.4 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: multidict, frozenlist, yarl, urllib3, asynctest, async-timeout, aiosignal, fsspec, dill, aiohttp, xxhash, responses, multiprocess, datasets\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","  Attempting uninstall: dill\n","    Found existing installation: dill 0.3.5.1\n","    Uninstalling dill-0.3.5.1:\n","      Successfully uninstalled dill-0.3.5.1\n","  Attempting uninstall: multiprocess\n","    Found existing installation: multiprocess 0.70.13\n","    Uninstalling multiprocess-0.70.13:\n","      Successfully uninstalled multiprocess-0.70.13\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-2.2.2 dill-0.3.4 frozenlist-1.3.0 fsspec-2022.5.0 multidict-6.0.2 multiprocess-0.70.12.2 responses-0.18.0 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting wandb\n","  Downloading wandb-0.12.17-py2.py3-none-any.whl (1.8 MB)\n","\u001b[K     |████████████████████████████████| 1.8 MB 7.5 MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Collecting setproctitle\n","  Downloading setproctitle-1.2.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n","Collecting docker-pycreds>=0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Collecting shortuuid>=0.5.0\n","  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n","Collecting pathtools\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Collecting GitPython>=1.0.0\n","  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n","\u001b[K     |████████████████████████████████| 181 kB 83.2 MB/s \n","\u001b[?25hCollecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.5.12-py2.py3-none-any.whl (145 kB)\n","\u001b[K     |████████████████████████████████| 145 kB 88.5 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.2.0)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 2.0 MB/s \n","\u001b[?25hCollecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.25.11)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2022.5.18.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n","Building wheels for collected packages: pathtools\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=91b7b52fb9716b49277b90d42b24a16f61342a0f82eacc988234a7085814d836\n","  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n","Successfully built pathtools\n","Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n","Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.5.12 setproctitle-1.2.3 shortuuid-1.0.9 smmap-5.0.0 wandb-0.12.17\n"]}],"source":["!pip install transformers\n","!pip install transformers datasets\n","!pip install wandb"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":6510,"status":"ok","timestamp":1654737687518,"user":{"displayName":"Lainie Kang","userId":"17932680864583243195"},"user_tz":-540},"id":"VXWGFFQLcLDY"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import random\n","import copy\n","from pprint import pprint\n","from tqdm import tqdm, tqdm_notebook\n","from collections import defaultdict, Counter, deque\n","import re\n","from itertools import chain\n","from importlib import import_module\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.nn import CrossEntropyLoss, MSELoss\n","from torch.utils.data import (Dataset,\n","                              DataLoader, \n","                              RandomSampler, \n","                              SequentialSampler, \n","                              TensorDataset)\n","from transformers import TrainingArguments, Trainer\n","from transformers import (AutoConfig, \n","                          AutoTokenizer, \n","                          RobertaForSequenceClassification,\n","                          Trainer,\n","                          TrainingArguments,\n","                          DataCollatorWithPadding,\n","                          EarlyStoppingCallback)\n","from transformers import AdamW\n","from transformers import (get_scheduler, \n","                          get_cosine_with_hard_restarts_schedule_with_warmup,\n","                          get_linear_schedule_with_warmup)\n","from torch.optim.lr_scheduler import ReduceLROnPlateau, _LRScheduler\n","from tqdm.auto import tqdm\n","from datasets import load_metric, load_dataset, Dataset, concatenate_datasets\n","import warnings\n","warnings.filterwarnings('ignore')\n","from sklearn.metrics import (accuracy_score, \n","                             precision_recall_curve,\n","                             f1_score,\n","                             auc)\n","from sklearn.model_selection import StratifiedKFold\n","from torch.optim import Adam, AdamW\n","from torch.optim.optimizer import Optimizer, required\n","import math\n","import easydict\n","import wandb"]},{"cell_type":"markdown","metadata":{"id":"2FCZRkoS8jqh"},"source":["# 시드고정"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":312,"status":"ok","timestamp":1654737712318,"user":{"displayName":"Lainie Kang","userId":"17932680864583243195"},"user_tz":-540},"id":"zD8_uSE-dAZG","outputId":"25652dac-9348-4ea7-d359-842f15d006b4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Seed set as 42\n"]}],"source":["def seed_everything(seed: int = 42, contain_cuda: bool = False):\n","  os.environ['PYTHONHASHSEED'] = str(seed)\n","  random.seed(seed)\n","  np.random.seed(seed)\n","\n","  torch.backends.cudnn.deterministic = True\n","  torch.backends.cudnn.benchmark = False\n","\n","  torch.manual_seed(seed)\n","  torch.cuda.manual_seed(seed)\n","  torch.cuda.manual_seed_all(seed)\n","  print(f\"Seed set as {seed}\")\n","\n","seed = 42\n","seed_everything(seed)"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1654737712655,"user":{"displayName":"Lainie Kang","userId":"17932680864583243195"},"user_tz":-540},"id":"VRZvRVX6ek2J"},"outputs":[],"source":["root_dir = '/content/drive/MyDrive'\n","project_folder = \"DACON\"\n","os.chdir(os.path.join(root_dir,project_folder))\n","\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"markdown","metadata":{"id":"Os1EX6BY9N9e"},"source":["# wandb로 잘못 분류하는 문장 기록"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1654737713265,"user":{"displayName":"Lainie Kang","userId":"17932680864583243195"},"user_tz":-540},"id":"JqfGgBR_fGhZ"},"outputs":[],"source":["def wrong_batch_for_wandb(tokenizer,\n","                          wrong_sample_index,\n","                          input_ids,\n","                          valid_labels,\n","                          valid_predict,\n","                          valid_output,\n","                          ):\n","  num_to_label_dict = {0:'diff', 1:'same',}\n","\n","  wrong_sample_index = np.where(valid_labels!=valid_predict)[0]\n","  wrong_sample_text = [tokenizer.decode(element, skip_special_tokens=False) for element in input_ids[wrong_sample_index]]\n","  wrong_sample_label = [num_to_label_dict[lab] for lab in list(valid_labels[wrong_sample_index])]\n","  wrong_sample_pred = [num_to_label_dict[pred] for pred in list(valid_predict[wrong_sample_index])]\n","  wrong_sample_output = valid_output[wrong_sample_index].tolist()\n","\n","  diff_prob, same_prob = [], []\n","  for element in wrong_sample_output:\n","      diff_prob.append(element[0])\n","      same_prob.append(element[1])\n","\n","  return wrong_sample_text, wrong_sample_label, wrong_sample_pred, diff_prob, same_prob\n"]},{"cell_type":"markdown","metadata":{"id":"gNeLWJwJ9SkK"},"source":["# Optimizer"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":359,"status":"ok","timestamp":1654737714275,"user":{"displayName":"Lainie Kang","userId":"17932680864583243195"},"user_tz":-540},"id":"TRxJ9tkkfodE"},"outputs":[],"source":["class AdamP(Optimizer):\n","  def __init__(\n","      self,\n","      params,\n","      lr=1e-3,\n","      betas=(0.9, 0.999),\n","      eps=1e-8,\n","      weight_decay=0,\n","      delta=0.1,\n","      wd_ratio=0.1,\n","      nesterov=False,\n","      ):\n","    defaults = dict(\n","        lr=lr,\n","        betas=betas,\n","        eps=eps,\n","        weight_decay=weight_decay,\n","        delta=delta,\n","        wd_ratio=wd_ratio,\n","        nesterov=nesterov,\n","        )\n","    super(AdamP, self).__init__(params, defaults)\n","\n","  def _channel_view(self, x):\n","    return x.view(x.size(0), -1)\n","\n","  def _layer_view(self, x):\n","    return x.view(1, -1)\n","\n","  def _cosine_similarity(self, x, y, eps, view_func):\n","    x = view_func(x)\n","    y = view_func(y)\n","\n","    return F.cosine_similarity(x, y, dim=1, eps=eps).abs_()\n","\n","  def _projection(self, p, grad, perturb, delta, wd_ratio, eps):\n","    wd = 1\n","    expand_size = [-1] + [1] * (len(p.shape) - 1)\n","    for view_func in [self._channel_view, self._layer_view]:\n","      \n","      cosine_sim = self._cosine_similarity(grad, p.data, eps, view_func)\n","      \n","      if cosine_sim.max() < delta / math.sqrt(view_func(p.data).size(1)):\n","        p_n = p.data / view_func(p.data).norm(dim=1).view(expand_size).add_(eps)\n","        perturb -= p_n * view_func(p_n * perturb).sum(dim=1).view(expand_size)\n","        wd = wd_ratio\n","        return perturb, wd\n","\n","    return perturb, wd\n","\n","  def step(self, closure=None):\n","    loss = None\n","    if closure is not None:\n","      loss = closure()\n","\n","    for group in self.param_groups:\n","      for p in group[\"params\"]:\n","        if p.grad is None:\n","          continue\n","\n","        grad = p.grad.data\n","        beta1, beta2 = group[\"betas\"]\n","        nesterov = group[\"nesterov\"]\n","\n","        state = self.state[p]\n","\n","        # State initialization\n","        if len(state) == 0:\n","          state[\"step\"] = 0\n","          state[\"exp_avg\"] = torch.zeros_like(p.data)\n","          state[\"exp_avg_sq\"] = torch.zeros_like(p.data)\n","\n","        # Adam\n","        exp_avg, exp_avg_sq = state[\"exp_avg\"], state[\"exp_avg_sq\"]\n","\n","        state[\"step\"] += 1\n","        bias_correction1 = 1 - beta1 ** state[\"step\"]\n","        bias_correction2 = 1 - beta2 ** state[\"step\"]\n","\n","        exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n","        exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=1 - beta2)\n","\n","        denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(\n","            group[\"eps\"]\n","            )\n","        step_size = group[\"lr\"] / bias_correction1\n","\n","        if nesterov:\n","          perturb = (beta1 * exp_avg + (1 - beta1) * grad) / denom\n","        else:\n","          perturb = exp_avg / denom\n","\n","        # Projection\n","        wd_ratio = 1\n","        if len(p.shape) > 1:\n","          perturb, wd_ratio = self._projection(\n","              p,\n","              grad,\n","              perturb,\n","              group[\"delta\"],\n","              group[\"wd_ratio\"],\n","              group[\"eps\"],\n","              )\n","\n","          # Weight decay\n","        if group[\"weight_decay\"] > 0:\n","          p.data.mul_(1 - group[\"lr\"] * group[\"weight_decay\"] * wd_ratio)\n","\n","          # Step\n","        p.data.add_(perturb, alpha=-step_size)\n","\n","    return loss\n","\n","def get_optimizer(model, args):\n","  if args.optimizer == \"Adam\":\n","    optimizer = Adam(model.parameters(), lr=args.lr, weight_decay=0.01)\n","  elif args.optimizer == \"AdamW\":\n","    optimizer = AdamW(model.parameters(), lr=args.lr, weight_decay=0.01)\n","  elif args.optimizer == \"AdamP\":\n","    optimizer = AdamP(\n","        model.parameters(),\n","        lr=args.lr,\n","        betas=(0.9, 0.999),\n","        weight_decay=0.01,\n","        delta=0.1,\n","        wd_ratio=0.1,\n","        nesterov=False,\n","        )\n","  else:\n","    raise NotImplementedError('Optimizer not available')\n","\n","  # 모든 parameter들의 grad값을 0으로 초기화\n","  optimizer.zero_grad()\n","\n","  return optimizer"]},{"cell_type":"markdown","metadata":{"id":"himCwOP89Vau"},"source":["# Scheduler"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1654737715019,"user":{"displayName":"Lainie Kang","userId":"17932680864583243195"},"user_tz":-540},"id":"ocL5AzhqgUrw"},"outputs":[],"source":["class CosineAnnealingWarmupRestarts(_LRScheduler):\n","  \"\"\"\n","    optimizer (Optimizer): Wrapped optimizer.\n","    first_cycle_steps (int): First cycle step size.\n","    cycle_mult(float): Cycle steps magnification. Default: -1.\n","    max_lr(float): First cycle's max learning rate. Default: 0.1.\n","    min_lr(float): Min learning rate. Default: 0.001.\n","    warmup_steps(int): Linear warmup step size. Default: 0.\n","    gamma(float): Decrease rate of max learning rate by cycle. Default: 1.\n","    last_epoch (int): The index of last epoch. Default: -1.\n","  \"\"\"\n","  def __init__(self,\n","               optimizer : torch.optim.Optimizer,\n","               first_cycle_steps : int,\n","               cycle_mult : float = 1.,\n","               max_lr : float = 0.1,\n","               min_lr : float = 0.001,\n","               warmup_steps : int = 0,\n","               gamma : float = 1.,\n","               last_epoch : int = -1\n","               ):\n","    assert warmup_steps < first_cycle_steps\n","        \n","    self.first_cycle_steps = first_cycle_steps # first cycle step size\n","    self.cycle_mult = cycle_mult # cycle steps magnification\n","    self.base_max_lr = max_lr # first max learning rate\n","    self.max_lr = max_lr # max learning rate in the current cycle\n","    self.min_lr = min_lr # min learning rate\n","    self.warmup_steps = warmup_steps # warmup step size\n","    self.gamma = gamma # decrease rate of max learning rate by cycle\n","    \n","    self.cur_cycle_steps = first_cycle_steps # first cycle step size\n","    self.cycle = 0 # cycle count\n","    self.step_in_cycle = last_epoch # step size of the current cycle\n","    \n","    super(CosineAnnealingWarmupRestarts, self).__init__(optimizer, last_epoch)\n","        \n","    # set learning rate min_lr\n","    self.init_lr()\n","    \n","  def init_lr(self):\n","    self.base_lrs = []\n","    for param_group in self.optimizer.param_groups:\n","      param_group['lr'] = self.min_lr\n","      self.base_lrs.append(self.min_lr)\n","    \n","  def get_lr(self):\n","    if self.step_in_cycle == -1:\n","      return self.base_lrs\n","    elif self.step_in_cycle < self.warmup_steps:\n","      return [(self.max_lr - base_lr)*self.step_in_cycle / self.warmup_steps + base_lr for base_lr in self.base_lrs]\n","    else:\n","      return [base_lr + (self.max_lr - base_lr) \\\n","              * (1 + math.cos(math.pi * (self.step_in_cycle-self.warmup_steps) \\\n","                              / (self.cur_cycle_steps - self.warmup_steps))) / 2\n","              for base_lr in self.base_lrs]\n","\n","  def step(self, epoch=None):\n","    if epoch is None:\n","      epoch = self.last_epoch + 1\n","      self.step_in_cycle = self.step_in_cycle + 1\n","      if self.step_in_cycle >= self.cur_cycle_steps:\n","        self.cycle += 1\n","        self.step_in_cycle = self.step_in_cycle - self.cur_cycle_steps\n","        self.cur_cycle_steps = int((self.cur_cycle_steps - self.warmup_steps) * self.cycle_mult) + self.warmup_steps\n","      else:\n","        if epoch >= self.first_cycle_steps:\n","          if self.cycle_mult == 1.:\n","            self.step_in_cycle = epoch % self.first_cycle_steps\n","            self.cycle = epoch // self.first_cycle_steps\n","          else:\n","            n = int(math.log((epoch / self.first_cycle_steps * (self.cycle_mult - 1) + 1), self.cycle_mult))\n","            self.cycle = n\n","            self.step_in_cycle = epoch - int(self.first_cycle_steps * (self.cycle_mult ** n - 1) / (self.cycle_mult - 1))\n","            self.cur_cycle_steps = self.first_cycle_steps * self.cycle_mult ** (n)\n","        else:\n","          self.cur_cycle_steps = self.first_cycle_steps\n","          self.step_in_cycle = epoch\n","                \n","        self.max_lr = self.base_max_lr * (self.gamma**self.cycle)\n","        self.last_epoch = math.floor(epoch)\n","        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n","            param_group['lr'] = lr\n","\n","\n","def get_scheduler(optimizer, args, total_batch_):\n","  if args.scheduler == \"plateau\":\n","      scheduler = ReduceLROnPlateau(\n","          optimizer, patience=2, factor=0.85, mode=\"max\", verbose=True\n","      )\n","  elif args.scheduler == \"linear\":\n","      scheduler = get_linear_schedule_with_warmup(\n","          optimizer,\n","          # num_warmup_steps=int(total_batch_*args.epochs*0.1),\n","          num_warmup_steps=args.warmup_steps,\n","          num_training_steps=int(total_batch_*args.epochs),\n","      )\n","  elif args.scheduler == \"cosine\":\n","      scheduler = CosineAnnealingWarmupRestarts( # ver1: first_cycle=20, warmup_steps=5, cycle_mult=1.0, max_lr=args.lr, min_lr=args.lr/100, gamma=0.8, patience=7, \n","          optimizer,                             # ver2: first_cycle=30, warmup_steps=5, cycle_mult=0.8, max_lr=args.lr, min_lr=args.lr/100, gamma=0.8, patience=5\n","          first_cycle_steps=200,                  # ver3: first_cycle=50, warmup_steps=10, cycle_mult=1.0, max_lr=args.lr, min_lr=args.lr/100, gamma=0.8, patience=7\n","          warmup_steps=args.warmup_steps,\n","          cycle_mult=args.cycle_mult,\n","          max_lr=args.lr,\n","          min_lr=args.lr * 0.01,\n","          gamma=0.9,\n","      )\n","  else:\n","    raise NotImplementedError('LR Scheduler not available')\n","\n","  return scheduler\n"]},{"cell_type":"markdown","metadata":{"id":"AxK5yqcP9Yfa"},"source":["# Loss"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1654737716370,"user":{"displayName":"Lainie Kang","userId":"17932680864583243195"},"user_tz":-540},"id":"YqORvLbsgbm1"},"outputs":[],"source":["class FocalLoss(nn.Module):\n","  def __init__(self, weight=None,\n","               gamma=2., reduction='mean'):\n","    nn.Module.__init__(self)\n","    self.weight = weight\n","    self.gamma = gamma\n","    self.reduction = reduction\n","\n","  def forward(self, input_tensor, target_tensor):\n","    log_prob = F.log_softmax(input_tensor, dim=-1)\n","    prob = torch.exp(log_prob)\n","    return F.nll_loss(\n","        ((1 - prob) ** self.gamma) * log_prob,\n","        target_tensor,\n","        weight=self.weight,\n","        reduction=self.reduction\n","        )\n","\n","class LabelSmoothingLoss(nn.Module):\n","  def __init__(self, classes=3, smoothing=0.0, dim=-1):\n","    super(LabelSmoothingLoss, self).__init__()\n","    self.confidence = 1.0 - smoothing\n","    self.smoothing = smoothing\n","    self.cls = classes\n","    self.dim = dim\n","\n","  def forward(self, pred, target):\n","    pred = pred.log_softmax(dim=self.dim)\n","    with torch.no_grad():\n","      true_dist = torch.zeros_like(pred)\n","      true_dist.fill_(self.smoothing / (self.cls - 1))\n","      true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n","    return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))\n","\n","\n","def get_criterion(args):\n","  if args.smoothing!=0 and args.criterion == 'smoothing':\n","    criterion = LabelSmoothingLoss(smoothing=args.smoothing)\n","  elif args.criterion == 'cross':\n","    criterion = nn.CrossEntropyLoss()\n","  elif args.criterion == 'focal':\n","    criterion = FocalLoss(gamma=2.0)\n","  else:\n","    raise NotImplementedError('Criterion not available')\n","  return criterion"]},{"cell_type":"markdown","metadata":{"id":"jUPKLxXQBvsg"},"source":["# Tokenize"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":525,"referenced_widgets":["112844234ed34baeae8078de9fe35cc1","b1c338ed5fc44be59058575e5e30b711","993c1a270e0c4b70afa177bf85065e68","d705c5bb43294582ac59eccc361b9e42","8e82722f7105415f8784f179d02d51f3","cc2e24c639344c44bef14492c7073c16","5222d9693e6f44ada7d83b16864a4277","f98cd6661ab84221a5329670e8885d32","00be25629bbd4dcdbdc5842fca4a60a9","2235c063da3245ef846a7770dba10c09","359015d2c1fa4fe28ba112ce004a97f2","4293e482d481450b8e825065d533bccb","5d6a59032dff4f01b2c9ded016e364dc","9a1972301743424690d54d957230e0f5","47a8c27b623a458ab85e0d8be9f56930","0fe125574804428bbab3b2520d8d0629","5e981c910459484eaff3102c302d5876","d5efa316226048a9a7cb7086f0a6de63","73215ffad18243e8b7ee29c31727d96b","fc53609b207f4c1f89ecf3e46dff4fda","5242f0dc8d974a02866dbafa162bdf37","cc9e8b959ec046fe8ae871454afa2bc6","013caefa41504366b8fdef2f1f859431","b742bc63634c4a279b3ce6eaabfb24dc","f4f16d4c57924555b53c1c6d8becbe44","5b19797748b34c3e85620e64ae94ee49","eb8f6d6b2f684da88c9d6ba8deecd143","4b8a00768f624728acd581bfe5bb223f","277ed4f96e92425192bc2891c53d2b55","d17e516b4b6a4c62b6cf9db8645df0ef","86a34006d456476597692efbbbac154c","d47661fc3ed74fee888527c0987c6faf","0c9626f369bf4756ad4c40e0393567de","38058c752ec9489dbe93d56314742c09","da6b0526c7564196a0a0bb14da839445","01321919e3b64ac8b84f8191c8426a5f","25918155e67c40e48a8679fc148fde95","dd31938070374b35bea2d224cc08c80d","dfb1ec85880547eda93443639da3998b","1811c9f58b954b669d780ff44d26eb29","8e34dc6db5904c8093a2b42a305c80dd","2681beb3b4fb40acb38ae241c2d401e6","cc72d31c413d4691bf8fa315378797af","d7df7110a06f478ea6ac07fd909ab9fc","efffaa722f7341b889e84349ff4ba9f1","9b4001b1726549839531d84c2cf0e07c","d544a8c9e0124ad6bb175de589b1a14e","7aac4283a2c34f4e8c1f3a9bd42a5abc","6e57fce3d7d24becbceb11bd87f37ba1","8bcec088fccd4a51a6f00398b52a354b","14c18a7f69a1465db9ddece3215ea3ca","fbe218a40ba146feb4a93080df331978","3ed9b521d6bf4ed5bd8eff74b4905fc2","62bb046ce5d5498fb0a2b604cbf31414","59fe5b9cf22245a2ba0766d4b5a05c1d","7d6203626a1a4fa9aca36dc3361b468f","35ae4f134b5f46f4b1d65d25f6dba08b","6ab664fd6563409887699f4bd6d0c7b5","f04ef6b79aa149fbb45e33a5570b6281","2700d8db40c641d48f37ddd3c7a5acdf","5c78cb1064104620b893511a0facf484","973c74bf0ef640cb94938fa80703de69","20470e454180403fbdc63fe76f23658b","4cf29f9fe7334237acba5082776f733d","bc613f29e50c4da2bd3937e48ee82220","0b8cb3d0dd7a4722a4bb1ba89cbb6148","b9312c7aa2bc47a68c306692f260aa2f","8bd69ba1525d4493a2e25bec21ebbb21","9252d5a43cd144a582ba847b30a8a56f","d0c6e20f3b6047fea186eab7957ba63d","82efbc933b05433481a2876ab16288ac","c2cbb3a79cfd4657886aa908ec048077","610a5d36ed68435bbb8e6d8346ef74a5","3bda627818b54583ad4e08ba26fc9235","02b8a64f6b5f4b90844d9cf23d994893","bae79945e61246f0b5188b1a81fb2abe","2ffb4a0f34cc44e498ca1b30b4eabe94","e7a62f6ada4d464cb5b9831dde9ad7be","2f3a4b25ec034906946af33ce319a1e5","dac97754ff4844e6a0ce5c389f58a4c6","29c7b94afddf4ddd8f479bdbbfd51fcb","108fb7feaad742dcaba8b32134afb893","1891ca41557c4454940295f0e519c46e","a0ca4512fc40463fb6e6d82d70a62cf3","a09295b921c94a2d86c56d9dc989044d","d16b1596053044fdb6722ccdbdc4f762","e8e5c066a4b5425281e4acee929f8060","2e5554212dd84a77a5a56bfa28d7e5f6","4db282fb60f744689e3ed92c8063e1f0","dc967b43eee24e15a61cf0444523c54f","8be4e9ce636c4de6a535d388477119d9","21446a9f3ee1497d9dd8fbc60ed05728","01e31275f7444aaf9e884ff09f2a4fa8","744c8660d9f34e19a955614f4910ae43","3040f8e4c47342929ebca6540a0f3de6","222733c8ae304d83868d63e161de4a90","db6e1aafb7464642b5a6c3eaeb9cfb0b","5b472740b5a1432993301388f2394a67","ecb2f2bc49cf4a5dbefaefb4b0d1c0af","6ae7d011d2184acd8d1741712e07c37d","9a6e6a6e96724dd9a0a69c9320ecc2f4","268e45e6d4af4d8cb79ca0c640f2e4a6","f076cdf849744b378ba54fbde58a064b","0c63a3459a544e0db3072ee6b23138e5","64e5fcf9d49f41ae80bbb9f7345062c1","9ae4de1a9c9e4540a18fa8b8ba13c3a6","b50e01bcbc654594a10fe8bffe228e2f","5724897745f0457e8a3870583af101b4","782c5fd9f94e4b5f8f4b5111aa4b4d8d","56a592e02e534221ab7077e2ef97c64f","de46fd632b274a79a3c515506f6d87c2","76e6a9ce52c041399272fded55ba08d3","e8c4833486b34955b87c30d872f9a08e","6c449e3821d54b67bdb8b507eb41bd25","4e9376a023664ef0b1df6b086e1780e6","71d495c3518349b9bc9cf365ff97bf7b","9a6fe04fc7514eb9b22437ca69a62665","c23344be027d4c93bd07d7de48a5dd7e","4c75af8bb6694dd5b19048fd93a41592","d50998c302af4ea4a6505b24c98fc233","a779e730ca8d4a75abd17ad3c2af3b03","713dd00540ab468ebcb09f4ba97258b7","e3036b1703f84c229e4f70d8d7a487a8","fc11ba12fb37456fb3924ae10535574a","25bcb5b890ce430da3d95372f9020e05","2a1b90149c99466aa1004e3bf5b8588e","9f11a6b3b3354ee4a7c1d8d974b76167","b92d5b6147bc43bd8cc209c13ec6ec95","283cf36952804e2ea72b04b0f2a67f90","a888e8c521954e479cc186fdfadd179a","3157617001a8469582ad1dce9125b1c3","16906426b0fd486d8dcb8e0397e9744b"]},"executionInfo":{"elapsed":655723,"status":"ok","timestamp":1654738374527,"user":{"displayName":"Lainie Kang","userId":"17932680864583243195"},"user_tz":-540},"id":"F4H-AP13fFCN","outputId":"a2a7889c-6c65-4c34-f91d-e00dd8cd71a5"},"outputs":[{"output_type":"stream","name":"stderr","text":["Using custom data configuration default-e7859c9c4620c0f4\n"]},{"output_type":"stream","name":"stdout","text":["Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-e7859c9c4620c0f4/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"112844234ed34baeae8078de9fe35cc1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4293e482d481450b8e825065d533bccb"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-e7859c9c4620c0f4/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"013caefa41504366b8fdef2f1f859431"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Using custom data configuration default-cf13ab19521ea58f\n"]},{"output_type":"stream","name":"stdout","text":["Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-cf13ab19521ea58f/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38058c752ec9489dbe93d56314742c09"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"efffaa722f7341b889e84349ff4ba9f1"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-cf13ab19521ea58f/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d6203626a1a4fa9aca36dc3361b468f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9312c7aa2bc47a68c306692f260aa2f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/539 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7a62f6ada4d464cb5b9831dde9ad7be"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4db282fb60f744689e3ed92c8063e1f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ae7d011d2184acd8d1741712e07c37d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/772 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de46fd632b274a79a3c515506f6d87c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/660000 [00:00<?, ?ex/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"713dd00540ab468ebcb09f4ba97258b7"}},"metadata":{}}],"source":["tdataset = load_dataset(\"csv\", data_files='/content/drive/MyDrive/train_data_lv1.csv')['train']\n","vdataset = load_dataset(\"csv\", data_files='/content/drive/MyDrive/valid_data_lv1.csv')['train']\n","rawdataset = concatenate_datasets([tdataset, vdataset])\n","tokenizer = AutoTokenizer.from_pretrained(\"microsoft/graphcodebert-base\")\n","tokenizer.truncation_side = 'left'\n","\n","def example_fn(examples):\n","    outputs = tokenizer(examples['code1'], examples['code2'], padding='max_length', max_length=512, truncation=True)\n","    outputs['labels'] = examples['similar']\n","    return outputs\n","\n","dataset = rawdataset.map(example_fn, remove_columns=['code1', 'code2', 'similar'])"]},{"cell_type":"markdown","metadata":{"id":"w77P1zyh9cXl"},"source":["# Arguments 설정"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":319,"status":"ok","timestamp":1654738410650,"user":{"displayName":"Lainie Kang","userId":"17932680864583243195"},"user_tz":-540},"id":"DLXFuzc0hXxs","outputId":"d5683a92-3e70-478c-a1cc-e95190631604"},"outputs":[{"output_type":"stream","name":"stdout","text":["current device : cuda:0\n","Seed set as 42\n"]}],"source":["device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","print(f'current device : {device}')\n","\n","args = easydict.EasyDict({\n","    \"seed\":42,\n","    \"optimizer\":\"AdamW\",    # help = (AdamW, Adam, AdamP)\n","    \"scheduler\":\"linear\",     # help= (linear, cosine, plateau ...)\n","    \"warmup_steps\":500,\n","    \"cycle_mult\":1.2,\n","    \"batch_size\": 16,\n","    \"patience\":5,\n","    \"n_splits\":5,\n","    \"epochs\":3,\n","    \"lr\": 2e-05,\n","    \"criterion\":'cross', # 'smoothing','focal','cross'\n","    \"smoothing\": 0.0,\n","    \"model\": \"microsoft/graphcodebert-base\",\n","    \"logging_wrong_samples\":True,\n","    })\n","\n","project_name = \"graphcodebert_Bs16_OptAdamW_ScduCosine_Sm0.0\"\n","args.update(\n","            {\n","                \"project_name\":project_name,\n","                \"model_name\":project_name,\n","             }\n","            )\n","\n","seed_everything(args.seed)"]},{"cell_type":"markdown","metadata":{"id":"Rwmiwb329aIF"},"source":["# Train"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":381,"status":"ok","timestamp":1654738413038,"user":{"displayName":"Lainie Kang","userId":"17932680864583243195"},"user_tz":-540},"id":"KpTcBOfFpAtK"},"outputs":[],"source":["import gc\n","gc.collect()\n","torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":156,"referenced_widgets":["172e97c6df2d414393eedd3167fda750","3961aa4379e6457abde58d199277d39c","d19d38dc7d3343a9956b1991cfc63268","1e92eceeb0664ef0b49ea7e645bf3f09","174d9f524eb3451db6f121f43bd6cfaf","8eaa2d3fcc91465597286eca5ab65c39","5b2f4bdc3d0643ba92b63378bfd177da","3ac640cf10e544f684b0aa646b6869bf","10835ec645a74d5fac9f536bd805a0c0","9638b8d5737e478fa9f21de5fa5a3d3f","12b1de06bee540e29f3558da0604a2ce"]},"executionInfo":{"elapsed":32409,"status":"ok","timestamp":1654738446806,"user":{"displayName":"Lainie Kang","userId":"17932680864583243195"},"user_tz":-540},"id":"icugmZZU0Y_-","outputId":"0daee6dc-cd89-4538-a7b6-b35f7a34e95c"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/476M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"172e97c6df2d414393eedd3167fda750"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/graphcodebert-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.dense.bias']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["criterion = get_criterion(args)\n","config =  AutoConfig.from_pretrained(\"microsoft/graphcodebert-base\")\n","config.num_labels = 2\n","model = RobertaForSequenceClassification.from_pretrained(\"microsoft/graphcodebert-base\", config=config)\n","model.to(device)\n","\n","best_val_acc_list = []"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":300,"status":"ok","timestamp":1654738478570,"user":{"displayName":"Lainie Kang","userId":"17932680864583243195"},"user_tz":-540},"id":"Onpzii511aee"},"outputs":[],"source":["gap = int(len(dataset) / args.n_splits)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":69},"executionInfo":{"elapsed":7138,"status":"ok","timestamp":1654738486949,"user":{"displayName":"Lainie Kang","userId":"17932680864583243195"},"user_tz":-540},"id":"2V1Q78kEhfFR","outputId":"b51661c6-eb35-42b6-947d-7e1f3a328e8d"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":15}],"source":["wandb.login()"]},{"cell_type":"markdown","metadata":{"id":"s34gSRG4O_fc"},"source":["# 2 fold"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":104},"executionInfo":{"elapsed":7141,"status":"ok","timestamp":1654565465484,"user":{"displayName":"Lainie Kang","userId":"17932680864583243195"},"user_tz":-540},"id":"Rm01669-O_fx","outputId":"5e93bdf0-f5c4-4bc7-a97a-8b07a2f6cf36"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnahyeonkang\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"name":"stdout","output_type":"stream","text":["---------------------------------- 2 fold----------------------------------\n"]},{"data":{"text/html":["Tracking run with wandb version 0.12.17"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/drive/MyDrive/DACON/wandb/run-20220607_013058-1w0vbvee</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href=\"https://wandb.ai/nahyeonkang/graphcodebert_Bs16_OptAdamW_ScduCosine_Sm0.0/runs/1w0vbvee\" target=\"_blank\">snowy-sound-10</a></strong> to <a href=\"https://wandb.ai/nahyeonkang/graphcodebert_Bs16_OptAdamW_ScduCosine_Sm0.0\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["f = 2\n","\n","print(f\"---------------------------------- {f} fold----------------------------------\")\n","\n","run = wandb.init(project=args.project_name)\n","wandb.run.name = f'{args.model_name}/{f}-fold'\n","wandb.config.update(args)\n","os.makedirs(f'./models/{args.model_name}/{f}-fold', exist_ok=True)\n","\n","total_size = len(dataset)\n","total_ids = list(range(total_size))\n","del_ids = list(range((f-1)*gap, f*gap))\n","training_ids = set(total_ids) - set(del_ids)\n","\n","training_dset = dataset.select(list(training_ids))\n","eval_dset = dataset.select(del_ids)\n","\n","collator = DataCollatorWithPadding(tokenizer=tokenizer)\n","\n","trainloader = DataLoader(training_dset,\n","                          batch_size=16,\n","                          shuffle=True,\n","                          collate_fn = collator\n","                          )\n","\n","validloader = DataLoader(eval_dset,\n","                          batch_size=16,\n","                          shuffle=False,\n","                          collate_fn = collator\n","                          )\n","\n","total_batch_ = len(trainloader)\n","valid_batch_ = len(validloader)\n","\n","optimizer = get_optimizer(model, args)\n","scheduler = get_scheduler(optimizer, args, total_batch_)"]},{"cell_type":"markdown","metadata":{"id":"Awugb7LXO_fy"},"source":["## 1 epoch"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["0f286c788f634d288560c83ee41c2d43","1216dd019ce4499a9710d81b9c655699","b3542b00ac7e4ba1998eac60058b51da","7501bc5a6b3a44dba16522696e2a28c5","9a0aa4fdb5be4b83a0d74f888cac0016","6745a54208064a80886a8cc075d26633","6b17a2e9b0af458a8c8d49b5297ede1e","726b0b11e9764f268aa7fce45a61e1f2","345f460ed5d04e70931d406d9877ee82","a5b380bebf2648ca9d55f35bf9ec4db2","e6f37051372b45e7a35c544c2a679c11"]},"executionInfo":{"elapsed":27707012,"status":"ok","timestamp":1654593176238,"user":{"displayName":"Lainie Kang","userId":"17932680864583243195"},"user_tz":-540},"id":"btTLE6oXO_fy","outputId":"0b88a73e-fc16-4527-b4aa-e1081a1c9bc4"},"outputs":[{"name":"stdout","output_type":"stream","text":["------------------------------ 2 fold 1 epoch------------------------------\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0f286c788f634d288560c83ee41c2d43","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/33000 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 1 #50 -- loss: 0.6944755041599273, acc: 0.48375\n","Epoch 1 #100 -- loss: 0.6875697326660156, acc: 0.53875\n","Epoch 1 #150 -- loss: 0.6842502653598785, acc: 0.54625\n","Epoch 1 #200 -- loss: 0.6417299628257751, acc: 0.64\n","Epoch 1 #250 -- loss: 0.49696703881025317, acc: 0.765\n","Epoch 1 #300 -- loss: 0.37552170783281325, acc: 0.8375\n","Epoch 1 #350 -- loss: 0.2988986775279045, acc: 0.88375\n","Epoch 1 #400 -- loss: 0.2359264947474003, acc: 0.90625\n","Epoch 1 #450 -- loss: 0.2389705354720354, acc: 0.91125\n","Epoch 1 #500 -- loss: 0.2591427024081349, acc: 0.895\n","Epoch 1 #550 -- loss: 0.24544144466519355, acc: 0.885\n","Epoch 1 #600 -- loss: 0.16852444712072612, acc: 0.93125\n","Epoch 1 #650 -- loss: 0.19004087373614312, acc: 0.93125\n","Epoch 1 #700 -- loss: 0.19206940002739428, acc: 0.92625\n","Epoch 1 #750 -- loss: 0.1746066513285041, acc: 0.93125\n","Epoch 1 #800 -- loss: 0.15200876073911787, acc: 0.94625\n","Epoch 1 #850 -- loss: 0.16907683610916138, acc: 0.93625\n","Epoch 1 #900 -- loss: 0.19010195594280957, acc: 0.9275\n","Epoch 1 #950 -- loss: 0.15182390443980695, acc: 0.95125\n","Epoch 1 #1000 -- loss: 0.1718721494078636, acc: 0.93875\n","Epoch 1 #1050 -- loss: 0.13802457988262176, acc: 0.95\n","Epoch 1 #1100 -- loss: 0.161279463712126, acc: 0.945\n","Epoch 1 #1150 -- loss: 0.16171866077929736, acc: 0.93875\n","Epoch 1 #1200 -- loss: 0.17277261175215244, acc: 0.93125\n","Epoch 1 #1250 -- loss: 0.16405658334493636, acc: 0.935\n","Epoch 1 #1300 -- loss: 0.12276738019660115, acc: 0.95125\n","Epoch 1 #1350 -- loss: 0.1250626766588539, acc: 0.95\n","Epoch 1 #1400 -- loss: 0.13423041950911282, acc: 0.9475\n","Epoch 1 #1450 -- loss: 0.1025693628937006, acc: 0.9675\n","Epoch 1 #1500 -- loss: 0.16408207713626324, acc: 0.94375\n","Epoch 1 #1550 -- loss: 0.1322189649194479, acc: 0.945\n","Epoch 1 #1600 -- loss: 0.10096843088045716, acc: 0.9575\n","Epoch 1 #1650 -- loss: 0.1355127658881247, acc: 0.94875\n","Epoch 1 #1700 -- loss: 0.13302867818623781, acc: 0.95375\n","Epoch 1 #1750 -- loss: 0.12253159936517477, acc: 0.95875\n","Epoch 1 #1800 -- loss: 0.1010688303783536, acc: 0.9625\n","Epoch 1 #1850 -- loss: 0.1341722666658461, acc: 0.95375\n","Epoch 1 #1900 -- loss: 0.11773218024522066, acc: 0.95\n","Epoch 1 #1950 -- loss: 0.1133537714369595, acc: 0.9625\n","Epoch 1 #2000 -- loss: 0.09832233197055756, acc: 0.96625\n","Epoch 1 #2050 -- loss: 0.12513647709041834, acc: 0.96\n","Epoch 1 #2100 -- loss: 0.11516740886028856, acc: 0.95125\n","Epoch 1 #2150 -- loss: 0.10274397942237556, acc: 0.96375\n","Epoch 1 #2200 -- loss: 0.13003783581778408, acc: 0.95125\n","Epoch 1 #2250 -- loss: 0.10636773288249969, acc: 0.96\n","Epoch 1 #2300 -- loss: 0.11893841594457627, acc: 0.96125\n","Epoch 1 #2350 -- loss: 0.10021173372864724, acc: 0.96375\n","Epoch 1 #2400 -- loss: 0.10028954810230062, acc: 0.95625\n","Epoch 1 #2450 -- loss: 0.12219881191849709, acc: 0.95375\n","Epoch 1 #2500 -- loss: 0.08215679707936943, acc: 0.97375\n","Epoch 1 #2550 -- loss: 0.06206538517959416, acc: 0.975\n","Epoch 1 #2600 -- loss: 0.11056593804620206, acc: 0.9625\n","Epoch 1 #2650 -- loss: 0.1107165245898068, acc: 0.96125\n","Epoch 1 #2700 -- loss: 0.10050148872192949, acc: 0.96625\n","Epoch 1 #2750 -- loss: 0.07127499052789062, acc: 0.97375\n","Epoch 1 #2800 -- loss: 0.06790807384531945, acc: 0.97375\n","Epoch 1 #2850 -- loss: 0.10861544441431761, acc: 0.96125\n","Epoch 1 #2900 -- loss: 0.07857629982288927, acc: 0.96875\n","Epoch 1 #2950 -- loss: 0.12056394138373434, acc: 0.96125\n","Epoch 1 #3000 -- loss: 0.09282410957384854, acc: 0.97\n","Epoch 1 #3050 -- loss: 0.11480901375412941, acc: 0.95625\n","Epoch 1 #3100 -- loss: 0.09794016847386956, acc: 0.9575\n","Epoch 1 #3150 -- loss: 0.10106467830948532, acc: 0.9575\n","Epoch 1 #3200 -- loss: 0.052367570740170774, acc: 0.98125\n","Epoch 1 #3250 -- loss: 0.06585491157602519, acc: 0.975\n","Epoch 1 #3300 -- loss: 0.08962746961507946, acc: 0.9675\n","Epoch 1 #3350 -- loss: 0.09282828883267939, acc: 0.965\n","Epoch 1 #3400 -- loss: 0.09365413593593985, acc: 0.9725\n","Epoch 1 #3450 -- loss: 0.09456386807607486, acc: 0.96625\n","Epoch 1 #3500 -- loss: 0.08037719835992903, acc: 0.97125\n","Epoch 1 #3550 -- loss: 0.05684786892496049, acc: 0.97875\n","Epoch 1 #3600 -- loss: 0.07898877297993749, acc: 0.9675\n","Epoch 1 #3650 -- loss: 0.09232207935769111, acc: 0.9625\n","Epoch 1 #3700 -- loss: 0.06685076560359449, acc: 0.975\n","Epoch 1 #3750 -- loss: 0.10747718609403818, acc: 0.96\n","Epoch 1 #3800 -- loss: 0.08549263482447714, acc: 0.9675\n","Epoch 1 #3850 -- loss: 0.07029472090769559, acc: 0.97375\n","Epoch 1 #3900 -- loss: 0.04993424927815795, acc: 0.985\n","Epoch 1 #3950 -- loss: 0.08635331779252738, acc: 0.9675\n","Epoch 1 #4000 -- loss: 0.07970659849699586, acc: 0.9725\n","Epoch 1 #4050 -- loss: 0.07296035432256759, acc: 0.97375\n","Epoch 1 #4100 -- loss: 0.07643712788820267, acc: 0.97125\n","Epoch 1 #4150 -- loss: 0.10617294077761472, acc: 0.95875\n","Epoch 1 #4200 -- loss: 0.07493826134130359, acc: 0.97\n","Epoch 1 #4250 -- loss: 0.09511399147566407, acc: 0.9675\n","Epoch 1 #4300 -- loss: 0.08372809605672955, acc: 0.97125\n","Epoch 1 #4350 -- loss: 0.0589515606884379, acc: 0.9775\n","Epoch 1 #4400 -- loss: 0.059124590221326795, acc: 0.98\n","Epoch 1 #4450 -- loss: 0.07701192355249077, acc: 0.97\n","Epoch 1 #4500 -- loss: 0.05977117934729904, acc: 0.9775\n","Epoch 1 #4550 -- loss: 0.08018106554169208, acc: 0.9725\n","Epoch 1 #4600 -- loss: 0.07784081147285178, acc: 0.9725\n","Epoch 1 #4650 -- loss: 0.04953695646720007, acc: 0.98375\n","Epoch 1 #4700 -- loss: 0.0617181656206958, acc: 0.97875\n","Epoch 1 #4750 -- loss: 0.05877743369201198, acc: 0.97875\n","Epoch 1 #4800 -- loss: 0.08987980962963775, acc: 0.965\n","Epoch 1 #4850 -- loss: 0.08389216002076864, acc: 0.975\n","Epoch 1 #4900 -- loss: 0.07997293809894472, acc: 0.96875\n","Epoch 1 #4950 -- loss: 0.07960804197005927, acc: 0.9725\n","Epoch 1 #5000 -- loss: 0.0912840032344684, acc: 0.9675\n","Epoch 1 #5050 -- loss: 0.053334612031467256, acc: 0.97875\n","Epoch 1 #5100 -- loss: 0.06816940994933247, acc: 0.9825\n","Epoch 1 #5150 -- loss: 0.08145452815573663, acc: 0.97125\n","Epoch 1 #5200 -- loss: 0.09153507275506854, acc: 0.97375\n","Epoch 1 #5250 -- loss: 0.07482409587595612, acc: 0.97625\n","Epoch 1 #5300 -- loss: 0.061923715865705165, acc: 0.9775\n","Epoch 1 #5350 -- loss: 0.08474431029520929, acc: 0.97125\n","Epoch 1 #5400 -- loss: 0.06843480613548308, acc: 0.97875\n","Epoch 1 #5450 -- loss: 0.06798444341402501, acc: 0.9725\n","Epoch 1 #5500 -- loss: 0.06590500203194097, acc: 0.975\n","Epoch 1 #5550 -- loss: 0.08381764514371753, acc: 0.97\n","Epoch 1 #5600 -- loss: 0.06698969886172562, acc: 0.98125\n","Epoch 1 #5650 -- loss: 0.07207385042915121, acc: 0.98\n","Epoch 1 #5700 -- loss: 0.042693486951757224, acc: 0.9875\n","Epoch 1 #5750 -- loss: 0.08574098675977439, acc: 0.9725\n","Epoch 1 #5800 -- loss: 0.06016522677382454, acc: 0.97875\n","Epoch 1 #5850 -- loss: 0.06173503721598536, acc: 0.98\n","Epoch 1 #5900 -- loss: 0.07817933017387986, acc: 0.9775\n","Epoch 1 #5950 -- loss: 0.046435331599786876, acc: 0.98125\n","Epoch 1 #6000 -- loss: 0.06492652290035039, acc: 0.98\n","Epoch 1 #6050 -- loss: 0.04469019537908025, acc: 0.985\n","Epoch 1 #6100 -- loss: 0.07328144527506084, acc: 0.975\n","Epoch 1 #6150 -- loss: 0.05025227487902157, acc: 0.98125\n","Epoch 1 #6200 -- loss: 0.06267183650983497, acc: 0.98\n","Epoch 1 #6250 -- loss: 0.06931341729359701, acc: 0.975\n","Epoch 1 #6300 -- loss: 0.0501441693957895, acc: 0.9825\n","Epoch 1 #6350 -- loss: 0.06619184085633606, acc: 0.9775\n","Epoch 1 #6400 -- loss: 0.04539683390816208, acc: 0.9875\n","Epoch 1 #6450 -- loss: 0.0746463631070219, acc: 0.97375\n","Epoch 1 #6500 -- loss: 0.06344903124030679, acc: 0.97875\n","Epoch 1 #6550 -- loss: 0.07630467587383465, acc: 0.96875\n","Epoch 1 #6600 -- loss: 0.06880683418363333, acc: 0.975\n","Epoch 1 #6650 -- loss: 0.06726034427527339, acc: 0.98\n","Epoch 1 #6700 -- loss: 0.06632268709363416, acc: 0.9775\n","Epoch 1 #6750 -- loss: 0.06339691867120564, acc: 0.97875\n","Epoch 1 #6800 -- loss: 0.053089354063849896, acc: 0.98375\n","Epoch 1 #6850 -- loss: 0.06377551634330303, acc: 0.975\n","Epoch 1 #6900 -- loss: 0.0698416510829702, acc: 0.97375\n","Epoch 1 #6950 -- loss: 0.06734869054984301, acc: 0.98\n","Epoch 1 #7000 -- loss: 0.06974254478001968, acc: 0.9775\n","Epoch 1 #7050 -- loss: 0.06818159756949171, acc: 0.97875\n","Epoch 1 #7100 -- loss: 0.05278886581538245, acc: 0.98125\n","Epoch 1 #7150 -- loss: 0.08337241961620748, acc: 0.9775\n","Epoch 1 #7200 -- loss: 0.05190782532095909, acc: 0.98375\n","Epoch 1 #7250 -- loss: 0.06188927915995009, acc: 0.97375\n","Epoch 1 #7300 -- loss: 0.05537889560684562, acc: 0.98\n","Epoch 1 #7350 -- loss: 0.04772982301656157, acc: 0.98625\n","Epoch 1 #7400 -- loss: 0.05846674608066678, acc: 0.9825\n","Epoch 1 #7450 -- loss: 0.06147235080017708, acc: 0.98375\n","Epoch 1 #7500 -- loss: 0.046359142647124825, acc: 0.9825\n","Epoch 1 #7550 -- loss: 0.059650439880788324, acc: 0.97875\n","Epoch 1 #7600 -- loss: 0.07855274039320648, acc: 0.97125\n","Epoch 1 #7650 -- loss: 0.05626226834021509, acc: 0.98375\n","Epoch 1 #7700 -- loss: 0.05841746939346194, acc: 0.98\n","Epoch 1 #7750 -- loss: 0.05363286135252565, acc: 0.98375\n","Epoch 1 #7800 -- loss: 0.06679543934296817, acc: 0.9775\n","Epoch 1 #7850 -- loss: 0.03813124729087576, acc: 0.98875\n","Epoch 1 #7900 -- loss: 0.04200814892537892, acc: 0.9875\n","Epoch 1 #7950 -- loss: 0.06178531643177848, acc: 0.9775\n","Epoch 1 #8000 -- loss: 0.0563782312523108, acc: 0.97875\n","Epoch 1 #8050 -- loss: 0.050173929671291265, acc: 0.985\n","Epoch 1 #8100 -- loss: 0.07745050347177312, acc: 0.97125\n","Epoch 1 #8150 -- loss: 0.05719786377856508, acc: 0.97625\n","Epoch 1 #8200 -- loss: 0.04896684237057343, acc: 0.98375\n","Epoch 1 #8250 -- loss: 0.047575497429352256, acc: 0.98375\n","Epoch 1 #8300 -- loss: 0.05458608175511472, acc: 0.97875\n","Epoch 1 #8350 -- loss: 0.06855797064257786, acc: 0.97\n","Epoch 1 #8400 -- loss: 0.044596935781883076, acc: 0.9825\n","Epoch 1 #8450 -- loss: 0.08383953950135037, acc: 0.97125\n","Epoch 1 #8500 -- loss: 0.04914330397034064, acc: 0.98125\n","Epoch 1 #8550 -- loss: 0.03791478089638986, acc: 0.9875\n","Epoch 1 #8600 -- loss: 0.04745296409353614, acc: 0.9825\n","Epoch 1 #8650 -- loss: 0.057089519827859474, acc: 0.97875\n","Epoch 1 #8700 -- loss: 0.05634619831107557, acc: 0.9775\n","Epoch 1 #8750 -- loss: 0.06053307229070924, acc: 0.96625\n","Epoch 1 #8800 -- loss: 0.05361124224145897, acc: 0.9775\n","Epoch 1 #8850 -- loss: 0.05637069582066033, acc: 0.9825\n","Epoch 1 #8900 -- loss: 0.036533237446565184, acc: 0.985\n","Epoch 1 #8950 -- loss: 0.03597725666302722, acc: 0.98625\n","Epoch 1 #9000 -- loss: 0.03607471065421123, acc: 0.985\n","Epoch 1 #9050 -- loss: 0.0546949608437717, acc: 0.985\n","Epoch 1 #9100 -- loss: 0.043292855706531554, acc: 0.985\n","Epoch 1 #9150 -- loss: 0.06338300328934565, acc: 0.98\n","Epoch 1 #9200 -- loss: 0.05775487957405858, acc: 0.97875\n","Epoch 1 #9250 -- loss: 0.06340573078370654, acc: 0.98\n","Epoch 1 #9300 -- loss: 0.06615795759949833, acc: 0.9825\n","Epoch 1 #9350 -- loss: 0.03620468173350673, acc: 0.98375\n","Epoch 1 #9400 -- loss: 0.07514735945966095, acc: 0.97875\n","Epoch 1 #9450 -- loss: 0.04298644956434146, acc: 0.98625\n","Epoch 1 #9500 -- loss: 0.07816770506789908, acc: 0.9725\n","Epoch 1 #9550 -- loss: 0.06574709254316985, acc: 0.97375\n","Epoch 1 #9600 -- loss: 0.06838688747957349, acc: 0.9725\n","Epoch 1 #9650 -- loss: 0.04133385339169763, acc: 0.98625\n","Epoch 1 #9700 -- loss: 0.03587474038009532, acc: 0.98875\n","Epoch 1 #9750 -- loss: 0.035240477088373155, acc: 0.98875\n","Epoch 1 #9800 -- loss: 0.05130504530214239, acc: 0.985\n","Epoch 1 #9850 -- loss: 0.06395918434718624, acc: 0.98125\n","Epoch 1 #9900 -- loss: 0.051434365774039176, acc: 0.975\n","Epoch 1 #9950 -- loss: 0.038025712759699674, acc: 0.98625\n","Epoch 1 #10000 -- loss: 0.041400518989539704, acc: 0.9875\n","Epoch 1 #10050 -- loss: 0.03134888313245028, acc: 0.99125\n","Epoch 1 #10100 -- loss: 0.04813710725808051, acc: 0.99\n","Epoch 1 #10150 -- loss: 0.044204017167212444, acc: 0.98875\n","Epoch 1 #10200 -- loss: 0.06538248993922025, acc: 0.98\n","Epoch 1 #10250 -- loss: 0.05995331806829199, acc: 0.9775\n","Epoch 1 #10300 -- loss: 0.06584786894498393, acc: 0.9775\n","Epoch 1 #10350 -- loss: 0.029873038644436748, acc: 0.98625\n","Epoch 1 #10400 -- loss: 0.05478193819755688, acc: 0.9775\n","Epoch 1 #10450 -- loss: 0.0386573904636316, acc: 0.99\n","Epoch 1 #10500 -- loss: 0.03982651904341765, acc: 0.98625\n","Epoch 1 #10550 -- loss: 0.043128830189816655, acc: 0.99\n","Epoch 1 #10600 -- loss: 0.05097504192497581, acc: 0.98375\n","Epoch 1 #10650 -- loss: 0.05908202631399036, acc: 0.97875\n","Epoch 1 #10700 -- loss: 0.056552124333102256, acc: 0.97875\n","Epoch 1 #10750 -- loss: 0.048112204764038324, acc: 0.985\n","Epoch 1 #10800 -- loss: 0.07980321310693399, acc: 0.97125\n","Epoch 1 #10850 -- loss: 0.03759310763096437, acc: 0.9875\n","Epoch 1 #10900 -- loss: 0.0667141232942231, acc: 0.98125\n","Epoch 1 #10950 -- loss: 0.031134983396623284, acc: 0.99125\n","Epoch 1 #11000 -- loss: 0.060961269785184416, acc: 0.9775\n","Epoch 1 #11050 -- loss: 0.04705386364832521, acc: 0.985\n","Epoch 1 #11100 -- loss: 0.03400553888059221, acc: 0.985\n","Epoch 1 #11150 -- loss: 0.04350808211020194, acc: 0.985\n","Epoch 1 #11200 -- loss: 0.059682549365097655, acc: 0.98125\n","Epoch 1 #11250 -- loss: 0.03204010800924152, acc: 0.98875\n","Epoch 1 #11300 -- loss: 0.032214882514672354, acc: 0.99\n","Epoch 1 #11350 -- loss: 0.035136738258879634, acc: 0.98375\n","Epoch 1 #11400 -- loss: 0.05743905638111755, acc: 0.9775\n","Epoch 1 #11450 -- loss: 0.05130759232561104, acc: 0.98375\n","Epoch 1 #11500 -- loss: 0.04404311147984117, acc: 0.985\n","Epoch 1 #11550 -- loss: 0.03171228703577071, acc: 0.98625\n","Epoch 1 #11600 -- loss: 0.047569382388610394, acc: 0.985\n","Epoch 1 #11650 -- loss: 0.04663200366776436, acc: 0.9825\n","Epoch 1 #11700 -- loss: 0.059452219121158126, acc: 0.98625\n","Epoch 1 #11750 -- loss: 0.0395838066295255, acc: 0.985\n","Epoch 1 #11800 -- loss: 0.035428494394291195, acc: 0.98375\n","Epoch 1 #11850 -- loss: 0.06120364352595061, acc: 0.97875\n","Epoch 1 #11900 -- loss: 0.046435776213183996, acc: 0.98625\n","Epoch 1 #11950 -- loss: 0.05858850449207239, acc: 0.975\n","Epoch 1 #12000 -- loss: 0.041043879315257076, acc: 0.98875\n","Epoch 1 #12050 -- loss: 0.03311102467065211, acc: 0.98375\n","Epoch 1 #12100 -- loss: 0.05733021773514338, acc: 0.9825\n","Epoch 1 #12150 -- loss: 0.027945012080599553, acc: 0.99\n","Epoch 1 #12200 -- loss: 0.04052140924148261, acc: 0.98625\n","Epoch 1 #12250 -- loss: 0.05142961559526157, acc: 0.98125\n","Epoch 1 #12300 -- loss: 0.041141381486086176, acc: 0.98375\n","Epoch 1 #12350 -- loss: 0.030103625417104922, acc: 0.98375\n","Epoch 1 #12400 -- loss: 0.0472982146719005, acc: 0.98\n","Epoch 1 #12450 -- loss: 0.04091622636129614, acc: 0.98375\n","Epoch 1 #12500 -- loss: 0.05339428963838145, acc: 0.985\n","Epoch 1 #12550 -- loss: 0.05805797152221203, acc: 0.98\n","Epoch 1 #12600 -- loss: 0.05024773614597507, acc: 0.98375\n","Epoch 1 #12650 -- loss: 0.032277975670294834, acc: 0.99125\n","Epoch 1 #12700 -- loss: 0.037282020017737526, acc: 0.98625\n","Epoch 1 #12750 -- loss: 0.031929382735397666, acc: 0.98875\n","Epoch 1 #12800 -- loss: 0.041156571329338476, acc: 0.98875\n","Epoch 1 #12850 -- loss: 0.03920728142315056, acc: 0.98375\n","Epoch 1 #12900 -- loss: 0.045081634284579196, acc: 0.98625\n","Epoch 1 #12950 -- loss: 0.04872440974460915, acc: 0.98375\n","Epoch 1 #13000 -- loss: 0.04208568998146802, acc: 0.98125\n","Epoch 1 #13050 -- loss: 0.03816495428909548, acc: 0.98625\n","Epoch 1 #13100 -- loss: 0.05340523685212247, acc: 0.98375\n","Epoch 1 #13150 -- loss: 0.032379642272135245, acc: 0.98625\n","Epoch 1 #13200 -- loss: 0.05695355999749154, acc: 0.98\n","Epoch 1 #13250 -- loss: 0.0271133917872794, acc: 0.99125\n","Epoch 1 #13300 -- loss: 0.03362328569812235, acc: 0.99\n","Epoch 1 #13350 -- loss: 0.028444234766066074, acc: 0.98875\n","Epoch 1 #13400 -- loss: 0.04098861495382153, acc: 0.9825\n","Epoch 1 #13450 -- loss: 0.029176544646616093, acc: 0.9925\n","Epoch 1 #13500 -- loss: 0.05249675747472793, acc: 0.9825\n","Epoch 1 #13550 -- loss: 0.034063804988982156, acc: 0.9825\n","Epoch 1 #13600 -- loss: 0.06736458244267851, acc: 0.98\n","Epoch 1 #13650 -- loss: 0.03751301080512349, acc: 0.9875\n","Epoch 1 #13700 -- loss: 0.03874294657027349, acc: 0.9825\n","Epoch 1 #13750 -- loss: 0.0432973967876751, acc: 0.9875\n","Epoch 1 #13800 -- loss: 0.05648518417961895, acc: 0.975\n","Epoch 1 #13850 -- loss: 0.05496841022511944, acc: 0.97875\n","Epoch 1 #13900 -- loss: 0.02930938945617527, acc: 0.9875\n","Epoch 1 #13950 -- loss: 0.04048941712186206, acc: 0.9875\n","Epoch 1 #14000 -- loss: 0.03263361348188482, acc: 0.98875\n","Epoch 1 #14050 -- loss: 0.038848244588298254, acc: 0.99\n","Epoch 1 #14100 -- loss: 0.04790488409576937, acc: 0.98625\n","Epoch 1 #14150 -- loss: 0.053673185622319576, acc: 0.9875\n","Epoch 1 #14200 -- loss: 0.05968983528902754, acc: 0.98125\n","Epoch 1 #14250 -- loss: 0.044095072885975244, acc: 0.99\n","Epoch 1 #14300 -- loss: 0.02640773469232954, acc: 0.99125\n","Epoch 1 #14350 -- loss: 0.05457337562344037, acc: 0.9825\n","Epoch 1 #14400 -- loss: 0.049978398624807595, acc: 0.9825\n","Epoch 1 #14450 -- loss: 0.020589911748538726, acc: 0.99125\n","Epoch 1 #14500 -- loss: 0.044782569501549005, acc: 0.9825\n","Epoch 1 #14550 -- loss: 0.025538748956751078, acc: 0.99\n","Epoch 1 #14600 -- loss: 0.038403439378598705, acc: 0.985\n","Epoch 1 #14650 -- loss: 0.04564242473803461, acc: 0.98125\n","Epoch 1 #14700 -- loss: 0.05372529847372789, acc: 0.9775\n","Epoch 1 #14750 -- loss: 0.03615105514472816, acc: 0.98625\n","Epoch 1 #14800 -- loss: 0.04060382417635992, acc: 0.9875\n","Epoch 1 #14850 -- loss: 0.03347776608192362, acc: 0.99\n","Epoch 1 #14900 -- loss: 0.03696997690421995, acc: 0.9875\n","Epoch 1 #14950 -- loss: 0.04764132342301309, acc: 0.98625\n","Epoch 1 #15000 -- loss: 0.04568558606086299, acc: 0.98625\n","Epoch 1 #15050 -- loss: 0.032572340075857936, acc: 0.99\n","Epoch 1 #15100 -- loss: 0.027415864893700927, acc: 0.99\n","Epoch 1 #15150 -- loss: 0.06782614050665871, acc: 0.975\n","Epoch 1 #15200 -- loss: 0.04944417280494236, acc: 0.9825\n","Epoch 1 #15250 -- loss: 0.04181647303048521, acc: 0.98375\n","Epoch 1 #15300 -- loss: 0.019770241967053154, acc: 0.99125\n","Epoch 1 #15350 -- loss: 0.032567649531993086, acc: 0.99\n","Epoch 1 #15400 -- loss: 0.07251853231748101, acc: 0.98\n","Epoch 1 #15450 -- loss: 0.037311742678284646, acc: 0.98875\n","Epoch 1 #15500 -- loss: 0.04663241038913839, acc: 0.98625\n","Epoch 1 #15550 -- loss: 0.025196715687634423, acc: 0.98625\n","Epoch 1 #15600 -- loss: 0.056877034524804915, acc: 0.98375\n","Epoch 1 #15650 -- loss: 0.03291803543339483, acc: 0.98875\n","Epoch 1 #15700 -- loss: 0.033939906111336314, acc: 0.985\n","Epoch 1 #15750 -- loss: 0.03470575353887398, acc: 0.99\n","Epoch 1 #15800 -- loss: 0.056809606781462206, acc: 0.9775\n","Epoch 1 #15850 -- loss: 0.04078614786965772, acc: 0.985\n","Epoch 1 #15900 -- loss: 0.028896099482080898, acc: 0.9875\n","Epoch 1 #15950 -- loss: 0.026116225977311842, acc: 0.99375\n","Epoch 1 #16000 -- loss: 0.04070382430334576, acc: 0.99\n","Epoch 1 #16050 -- loss: 0.03869585243635811, acc: 0.9875\n","Epoch 1 #16100 -- loss: 0.04094568683300168, acc: 0.9825\n","Epoch 1 #16150 -- loss: 0.0379853926243959, acc: 0.98375\n","Epoch 1 #16200 -- loss: 0.03540411519352347, acc: 0.98625\n","Epoch 1 #16250 -- loss: 0.03893177286547143, acc: 0.98875\n","Epoch 1 #16300 -- loss: 0.043515955403563567, acc: 0.9825\n","Epoch 1 #16350 -- loss: 0.032298620571382344, acc: 0.99\n","Epoch 1 #16400 -- loss: 0.027934440385433846, acc: 0.99375\n","Epoch 1 #16450 -- loss: 0.02797499508073088, acc: 0.99\n","Epoch 1 #16500 -- loss: 0.03779053964506602, acc: 0.98875\n","Epoch 1 #16550 -- loss: 0.02862752939108759, acc: 0.99125\n","Epoch 1 #16600 -- loss: 0.03704562658676878, acc: 0.98625\n","Epoch 1 #16650 -- loss: 0.059423262614291164, acc: 0.98375\n","Epoch 1 #16700 -- loss: 0.03004536347114481, acc: 0.98875\n","Epoch 1 #16750 -- loss: 0.04515685674501583, acc: 0.98375\n","Epoch 1 #16800 -- loss: 0.03302791721886024, acc: 0.99375\n","Epoch 1 #16850 -- loss: 0.04731835472281091, acc: 0.9875\n","Epoch 1 #16900 -- loss: 0.037661615666002034, acc: 0.98375\n","Epoch 1 #16950 -- loss: 0.029673296003602447, acc: 0.99125\n","Epoch 1 #17000 -- loss: 0.030484626356046648, acc: 0.9925\n","Epoch 1 #17050 -- loss: 0.03564874268660787, acc: 0.9875\n","Epoch 1 #17100 -- loss: 0.04874930012621917, acc: 0.98\n","Epoch 1 #17150 -- loss: 0.025465904411976225, acc: 0.99\n","Epoch 1 #17200 -- loss: 0.03208110961480998, acc: 0.9875\n","Epoch 1 #17250 -- loss: 0.029891616590321066, acc: 0.985\n","Epoch 1 #17300 -- loss: 0.03526096340909134, acc: 0.98625\n","Epoch 1 #17350 -- loss: 0.02018096472893376, acc: 0.995\n","Epoch 1 #17400 -- loss: 0.05097320910834242, acc: 0.9875\n","Epoch 1 #17450 -- loss: 0.041518688322976234, acc: 0.98625\n","Epoch 1 #17500 -- loss: 0.024428285593166947, acc: 0.99\n","Epoch 1 #17550 -- loss: 0.04947849911404774, acc: 0.98125\n","Epoch 1 #17600 -- loss: 0.0324501195945777, acc: 0.99\n","Epoch 1 #17650 -- loss: 0.047841091104783115, acc: 0.985\n","Epoch 1 #17700 -- loss: 0.042675652308389544, acc: 0.99125\n","Epoch 1 #17750 -- loss: 0.04357165202731267, acc: 0.98375\n","Epoch 1 #17800 -- loss: 0.034042957661440595, acc: 0.985\n","Epoch 1 #17850 -- loss: 0.03298970803502016, acc: 0.98625\n","Epoch 1 #17900 -- loss: 0.029180240152054466, acc: 0.9875\n","Epoch 1 #17950 -- loss: 0.03245600718597416, acc: 0.99\n","Epoch 1 #18000 -- loss: 0.04164386849734001, acc: 0.98875\n","Epoch 1 #18050 -- loss: 0.03448593210021499, acc: 0.99125\n","Epoch 1 #18100 -- loss: 0.030342340467614123, acc: 0.9875\n","Epoch 1 #18150 -- loss: 0.02462358533113729, acc: 0.99\n","Epoch 1 #18200 -- loss: 0.03406304982840083, acc: 0.99125\n","Epoch 1 #18250 -- loss: 0.033800181407714264, acc: 0.98375\n","Epoch 1 #18300 -- loss: 0.049473044211044905, acc: 0.98625\n","Epoch 1 #18350 -- loss: 0.033661801802227276, acc: 0.99\n","Epoch 1 #18400 -- loss: 0.020512212255271153, acc: 0.995\n","Epoch 1 #18450 -- loss: 0.02073144672322087, acc: 0.99125\n","Epoch 1 #18500 -- loss: 0.04577825803658925, acc: 0.9875\n","Epoch 1 #18550 -- loss: 0.019865591273410244, acc: 0.99375\n","Epoch 1 #18600 -- loss: 0.02094953514606459, acc: 0.99375\n","Epoch 1 #18650 -- loss: 0.052374058369314296, acc: 0.98125\n","Epoch 1 #18700 -- loss: 0.03828467964776792, acc: 0.985\n","Epoch 1 #18750 -- loss: 0.04433905311278068, acc: 0.9875\n","Epoch 1 #18800 -- loss: 0.019125092644826508, acc: 0.995\n","Epoch 1 #18850 -- loss: 0.04663711330620572, acc: 0.9875\n","Epoch 1 #18900 -- loss: 0.03526757738552987, acc: 0.985\n","Epoch 1 #18950 -- loss: 0.03528674397384748, acc: 0.9875\n","Epoch 1 #19000 -- loss: 0.03627695580769796, acc: 0.98625\n","Epoch 1 #19050 -- loss: 0.045265362539794296, acc: 0.98\n","Epoch 1 #19100 -- loss: 0.024261309202993287, acc: 0.9925\n","Epoch 1 #19150 -- loss: 0.06208563460444566, acc: 0.97875\n","Epoch 1 #19200 -- loss: 0.03728025298914872, acc: 0.99\n","Epoch 1 #19250 -- loss: 0.04302132854179945, acc: 0.9825\n","Epoch 1 #19300 -- loss: 0.022767775629763492, acc: 0.99375\n","Epoch 1 #19350 -- loss: 0.03781415597710293, acc: 0.9825\n","Epoch 1 #19400 -- loss: 0.033381252746330574, acc: 0.9875\n","Epoch 1 #19450 -- loss: 0.023378477886435576, acc: 0.99125\n","Epoch 1 #19500 -- loss: 0.029713812152913306, acc: 0.9875\n","Epoch 1 #19550 -- loss: 0.0524572304188041, acc: 0.98375\n","Epoch 1 #19600 -- loss: 0.02982754077529535, acc: 0.9875\n","Epoch 1 #19650 -- loss: 0.02173080695414683, acc: 0.99125\n","Epoch 1 #19700 -- loss: 0.032758266229357104, acc: 0.99\n","Epoch 1 #19750 -- loss: 0.0205355695146136, acc: 0.995\n","Epoch 1 #19800 -- loss: 0.04491391012910753, acc: 0.98625\n","Epoch 1 #19850 -- loss: 0.04494219216518104, acc: 0.98375\n","Epoch 1 #19900 -- loss: 0.04106821641442366, acc: 0.9875\n","Epoch 1 #19950 -- loss: 0.04171121785184369, acc: 0.98625\n","Epoch 1 #20000 -- loss: 0.04731295719044283, acc: 0.98125\n","Epoch 1 #20050 -- loss: 0.030011131103383378, acc: 0.99\n","Epoch 1 #20100 -- loss: 0.03727461580536328, acc: 0.98875\n","Epoch 1 #20150 -- loss: 0.05052918335073628, acc: 0.9825\n","Epoch 1 #20200 -- loss: 0.03796615499537438, acc: 0.98625\n","Epoch 1 #20250 -- loss: 0.025218621384119615, acc: 0.99125\n","Epoch 1 #20300 -- loss: 0.03985692522255704, acc: 0.985\n","Epoch 1 #20350 -- loss: 0.027418868268141522, acc: 0.9875\n","Epoch 1 #20400 -- loss: 0.02052454568532994, acc: 0.9925\n","Epoch 1 #20450 -- loss: 0.03347412603383418, acc: 0.99\n","Epoch 1 #20500 -- loss: 0.0225762335001491, acc: 0.995\n","Epoch 1 #20550 -- loss: 0.04235960575286299, acc: 0.98875\n","Epoch 1 #20600 -- loss: 0.021046037018531933, acc: 0.9925\n","Epoch 1 #20650 -- loss: 0.05096770309144631, acc: 0.985\n","Epoch 1 #20700 -- loss: 0.02890224502189085, acc: 0.99125\n","Epoch 1 #20750 -- loss: 0.03282839325489476, acc: 0.9875\n","Epoch 1 #20800 -- loss: 0.0190534856839804, acc: 0.995\n","Epoch 1 #20850 -- loss: 0.018628939594782422, acc: 0.9925\n","Epoch 1 #20900 -- loss: 0.03941879152262118, acc: 0.98375\n","Epoch 1 #20950 -- loss: 0.02865584207669599, acc: 0.99\n","Epoch 1 #21000 -- loss: 0.02032289544789819, acc: 0.9925\n","Epoch 1 #21050 -- loss: 0.02494179095781874, acc: 0.99125\n","Epoch 1 #21100 -- loss: 0.02550220367294969, acc: 0.9875\n","Epoch 1 #21150 -- loss: 0.031635699190956074, acc: 0.99375\n","Epoch 1 #21200 -- loss: 0.02436879881366622, acc: 0.99375\n","Epoch 1 #21250 -- loss: 0.024675506904604846, acc: 0.99125\n","Epoch 1 #21300 -- loss: 0.0332227072614478, acc: 0.98625\n","Epoch 1 #21350 -- loss: 0.022126824823208154, acc: 0.98875\n","Epoch 1 #21400 -- loss: 0.0262832192282076, acc: 0.99125\n","Epoch 1 #21450 -- loss: 0.04466963143437169, acc: 0.98875\n","Epoch 1 #21500 -- loss: 0.04106152122491039, acc: 0.985\n","Epoch 1 #21550 -- loss: 0.02772785585024394, acc: 0.98625\n","Epoch 1 #21600 -- loss: 0.018879230938327964, acc: 0.99625\n","Epoch 1 #21650 -- loss: 0.025811847026925534, acc: 0.99\n","Epoch 1 #21700 -- loss: 0.023211736408120485, acc: 0.99125\n","Epoch 1 #21750 -- loss: 0.018767894176125993, acc: 0.99\n","Epoch 1 #21800 -- loss: 0.02236898259317968, acc: 0.9925\n","Epoch 1 #21850 -- loss: 0.026079214467026757, acc: 0.98875\n","Epoch 1 #21900 -- loss: 0.032305857438477685, acc: 0.985\n","Epoch 1 #21950 -- loss: 0.040465690744458695, acc: 0.985\n","Epoch 1 #22000 -- loss: 0.036543961571296676, acc: 0.9875\n","Epoch 1 #22050 -- loss: 0.027996772372280248, acc: 0.99\n","Epoch 1 #22100 -- loss: 0.014742196594306733, acc: 0.995\n","Epoch 1 #22150 -- loss: 0.026299467005592304, acc: 0.995\n","Epoch 1 #22200 -- loss: 0.02475611766334623, acc: 0.99125\n","Epoch 1 #22250 -- loss: 0.03659703857410932, acc: 0.98875\n","Epoch 1 #22300 -- loss: 0.04975445969495922, acc: 0.98375\n","Epoch 1 #22350 -- loss: 0.028642278913175688, acc: 0.99\n","Epoch 1 #22400 -- loss: 0.01766539235773962, acc: 0.99375\n","Epoch 1 #22450 -- loss: 0.03754456539929379, acc: 0.98625\n","Epoch 1 #22500 -- loss: 0.054203799113165585, acc: 0.98625\n","Epoch 1 #22550 -- loss: 0.03852450319449417, acc: 0.98125\n","Epoch 1 #22600 -- loss: 0.01430356337397825, acc: 0.995\n","Epoch 1 #22650 -- loss: 0.04028553852578625, acc: 0.985\n","Epoch 1 #22700 -- loss: 0.01951426684623584, acc: 0.9925\n","Epoch 1 #22750 -- loss: 0.03480657089618035, acc: 0.99\n","Epoch 1 #22800 -- loss: 0.031130420153494924, acc: 0.99\n","Epoch 1 #22850 -- loss: 0.04147311595617793, acc: 0.9875\n","Epoch 1 #22900 -- loss: 0.034089388831052926, acc: 0.985\n","Epoch 1 #22950 -- loss: 0.06786499336827546, acc: 0.97375\n","Epoch 1 #23000 -- loss: 0.04226219361298718, acc: 0.99\n","Epoch 1 #23050 -- loss: 0.03554825745464768, acc: 0.98875\n","Epoch 1 #23100 -- loss: 0.029637518209638072, acc: 0.98875\n","Epoch 1 #23150 -- loss: 0.015871565135603304, acc: 0.995\n","Epoch 1 #23200 -- loss: 0.03640721050382126, acc: 0.98375\n","Epoch 1 #23250 -- loss: 0.032385379380430096, acc: 0.99\n","Epoch 1 #23300 -- loss: 0.024066941345226953, acc: 0.99625\n","Epoch 1 #23350 -- loss: 0.018478960687643847, acc: 0.9925\n","Epoch 1 #23400 -- loss: 0.04691290700691752, acc: 0.985\n","Epoch 1 #23450 -- loss: 0.02504221552342642, acc: 0.9925\n","Epoch 1 #23500 -- loss: 0.03879740651173051, acc: 0.98625\n","Epoch 1 #23550 -- loss: 0.03794836032029707, acc: 0.98125\n","Epoch 1 #23600 -- loss: 0.023791562452097424, acc: 0.99\n","Epoch 1 #23650 -- loss: 0.020442800534074195, acc: 0.99375\n","Epoch 1 #23700 -- loss: 0.02790564047259977, acc: 0.99125\n","Epoch 1 #23750 -- loss: 0.03693651021283586, acc: 0.9925\n","Epoch 1 #23800 -- loss: 0.027652077955426648, acc: 0.99\n","Epoch 1 #23850 -- loss: 0.02979083718295442, acc: 0.98875\n","Epoch 1 #23900 -- loss: 0.03400508053426165, acc: 0.98875\n","Epoch 1 #23950 -- loss: 0.023095139997894875, acc: 0.99\n","Epoch 1 #24000 -- loss: 0.02283156570600113, acc: 0.995\n","Epoch 1 #24050 -- loss: 0.018821688292955514, acc: 0.99125\n","Epoch 1 #24100 -- loss: 0.027338245286955498, acc: 0.9875\n","Epoch 1 #24150 -- loss: 0.016882965243712533, acc: 0.995\n","Epoch 1 #24200 -- loss: 0.040859750004601667, acc: 0.98125\n","Epoch 1 #24250 -- loss: 0.03018906036973931, acc: 0.99\n","Epoch 1 #24300 -- loss: 0.035435196947655644, acc: 0.9875\n","Epoch 1 #24350 -- loss: 0.034928610794595444, acc: 0.98875\n","Epoch 1 #24400 -- loss: 0.035273086045635865, acc: 0.98625\n","Epoch 1 #24450 -- loss: 0.03874789518187754, acc: 0.985\n","Epoch 1 #24500 -- loss: 0.022560490694013426, acc: 0.9925\n","Epoch 1 #24550 -- loss: 0.03162284234480467, acc: 0.98875\n","Epoch 1 #24600 -- loss: 0.02436109642498195, acc: 0.98875\n","Epoch 1 #24650 -- loss: 0.02897433656733483, acc: 0.9925\n","Epoch 1 #24700 -- loss: 0.01755491399584571, acc: 0.99125\n","Epoch 1 #24750 -- loss: 0.04093467319064075, acc: 0.99\n","Epoch 1 #24800 -- loss: 0.009124015889537986, acc: 0.99875\n","Epoch 1 #24850 -- loss: 0.015947975910676176, acc: 0.99625\n","Epoch 1 #24900 -- loss: 0.04011185651645064, acc: 0.98875\n","Epoch 1 #24950 -- loss: 0.015250626931083389, acc: 0.99625\n","Epoch 1 #25000 -- loss: 0.03297681075171568, acc: 0.98875\n","Epoch 1 #25050 -- loss: 0.04371239603788126, acc: 0.9825\n","Epoch 1 #25100 -- loss: 0.033080110811861234, acc: 0.99\n","Epoch 1 #25150 -- loss: 0.01407638993987348, acc: 0.99625\n","Epoch 1 #25200 -- loss: 0.030790428721229546, acc: 0.98875\n","Epoch 1 #25250 -- loss: 0.018102179484558292, acc: 0.995\n","Epoch 1 #25300 -- loss: 0.02960099572490435, acc: 0.99125\n","Epoch 1 #25350 -- loss: 0.030064390950428788, acc: 0.99\n","Epoch 1 #25400 -- loss: 0.040088384440750816, acc: 0.98125\n","Epoch 1 #25450 -- loss: 0.025498520034598186, acc: 0.99\n","Epoch 1 #25500 -- loss: 0.012363589771557599, acc: 0.9975\n","Epoch 1 #25550 -- loss: 0.013572525192867033, acc: 0.99625\n","Epoch 1 #25600 -- loss: 0.03235064346692525, acc: 0.99\n","Epoch 1 #25650 -- loss: 0.028234633214597123, acc: 0.9925\n","Epoch 1 #25700 -- loss: 0.0257828520151088, acc: 0.99\n","Epoch 1 #25750 -- loss: 0.028816715694847516, acc: 0.99125\n","Epoch 1 #25800 -- loss: 0.008440087005437817, acc: 0.9975\n","Epoch 1 #25850 -- loss: 0.025794433935952838, acc: 0.99125\n","Epoch 1 #25900 -- loss: 0.03323556380055379, acc: 0.9825\n","Epoch 1 #25950 -- loss: 0.02598665862402413, acc: 0.98875\n","Epoch 1 #26000 -- loss: 0.02354030816059094, acc: 0.9925\n","Epoch 1 #26050 -- loss: 0.03015001578751253, acc: 0.99375\n","Epoch 1 #26100 -- loss: 0.020783074441133066, acc: 0.9925\n","Epoch 1 #26150 -- loss: 0.028008507693884896, acc: 0.98875\n","Epoch 1 #26200 -- loss: 0.021822607446811162, acc: 0.99375\n","Epoch 1 #26250 -- loss: 0.017737176462251227, acc: 0.99375\n","Epoch 1 #26300 -- loss: 0.015529160491132643, acc: 0.99625\n","Epoch 1 #26350 -- loss: 0.024831193090649323, acc: 0.9925\n","Epoch 1 #26400 -- loss: 0.01923617957480019, acc: 0.9925\n","Epoch 1 #26450 -- loss: 0.019339509904093576, acc: 0.99375\n","Epoch 1 #26500 -- loss: 0.017957283973519225, acc: 0.995\n","Epoch 1 #26550 -- loss: 0.017001803892489988, acc: 0.9925\n","Epoch 1 #26600 -- loss: 0.028565090265183245, acc: 0.99375\n","Epoch 1 #26650 -- loss: 0.02413064402062446, acc: 0.99125\n","Epoch 1 #26700 -- loss: 0.012949290443502832, acc: 0.995\n","Epoch 1 #26750 -- loss: 0.03316253460507142, acc: 0.99\n","Epoch 1 #26800 -- loss: 0.03299695734167472, acc: 0.99125\n","Epoch 1 #26850 -- loss: 0.027667949908645822, acc: 0.99\n","Epoch 1 #26900 -- loss: 0.02039399259025231, acc: 0.9925\n","Epoch 1 #26950 -- loss: 0.027332875518186483, acc: 0.99\n","Epoch 1 #27000 -- loss: 0.030255704242445062, acc: 0.9875\n","Epoch 1 #27050 -- loss: 0.018125829643395264, acc: 0.99375\n","Epoch 1 #27100 -- loss: 0.016703072846576107, acc: 0.9925\n","Epoch 1 #27150 -- loss: 0.02898369463844574, acc: 0.985\n","Epoch 1 #27200 -- loss: 0.015138360652490518, acc: 0.99375\n","Epoch 1 #27250 -- loss: 0.04171421593928244, acc: 0.9875\n","Epoch 1 #27300 -- loss: 0.026406037544074935, acc: 0.98875\n","Epoch 1 #27350 -- loss: 0.011461258820490912, acc: 0.995\n","Epoch 1 #27400 -- loss: 0.014347167662490392, acc: 0.995\n","Epoch 1 #27450 -- loss: 0.04733532921789447, acc: 0.98625\n","Epoch 1 #27500 -- loss: 0.02573251595837064, acc: 0.995\n","Epoch 1 #27550 -- loss: 0.025715244277671447, acc: 0.99125\n","Epoch 1 #27600 -- loss: 0.00831785955640953, acc: 0.99625\n","Epoch 1 #27650 -- loss: 0.02609178397746291, acc: 0.99\n","Epoch 1 #27700 -- loss: 0.03854275595920626, acc: 0.9875\n","Epoch 1 #27750 -- loss: 0.03228376850427594, acc: 0.9875\n","Epoch 1 #27800 -- loss: 0.03721787009417312, acc: 0.98875\n","Epoch 1 #27850 -- loss: 0.012849930956144817, acc: 0.99625\n","Epoch 1 #27900 -- loss: 0.0165369280212326, acc: 0.995\n","Epoch 1 #27950 -- loss: 0.028537469811562913, acc: 0.99125\n","Epoch 1 #28000 -- loss: 0.022331653757137245, acc: 0.99125\n","Epoch 1 #28050 -- loss: 0.03149653299216879, acc: 0.98875\n","Epoch 1 #28100 -- loss: 0.01853278036171105, acc: 0.995\n","Epoch 1 #28150 -- loss: 0.038338083219714464, acc: 0.98875\n","Epoch 1 #28200 -- loss: 0.016667561103822663, acc: 0.99375\n","Epoch 1 #28250 -- loss: 0.021900108291301876, acc: 0.9875\n","Epoch 1 #28300 -- loss: 0.02181947152595967, acc: 0.98875\n","Epoch 1 #28350 -- loss: 0.025946233968425075, acc: 0.98875\n","Epoch 1 #28400 -- loss: 0.03466400819364935, acc: 0.98625\n","Epoch 1 #28450 -- loss: 0.01986644113319926, acc: 0.995\n","Epoch 1 #28500 -- loss: 0.03424396645510569, acc: 0.99\n","Epoch 1 #28550 -- loss: 0.018567277783877217, acc: 0.995\n","Epoch 1 #28600 -- loss: 0.03258736037329072, acc: 0.9925\n","Epoch 1 #28650 -- loss: 0.01737147678359179, acc: 0.9925\n","Epoch 1 #28700 -- loss: 0.023420413232815917, acc: 0.99\n","Epoch 1 #28750 -- loss: 0.017708506820490584, acc: 0.99\n","Epoch 1 #28800 -- loss: 0.0360722992348019, acc: 0.98625\n","Epoch 1 #28850 -- loss: 0.014242886590363924, acc: 0.995\n","Epoch 1 #28900 -- loss: 0.009853703117987606, acc: 0.99625\n","Epoch 1 #28950 -- loss: 0.018832883919822054, acc: 0.99375\n","Epoch 1 #29000 -- loss: 0.024515584040782416, acc: 0.98875\n","Epoch 1 #29050 -- loss: 0.011802538211632053, acc: 0.995\n","Epoch 1 #29100 -- loss: 0.03118322746740887, acc: 0.985\n","Epoch 1 #29150 -- loss: 0.03561353897617664, acc: 0.9825\n","Epoch 1 #29200 -- loss: 0.016159672048233917, acc: 0.99625\n","Epoch 1 #29250 -- loss: 0.012887339729059023, acc: 0.99625\n","Epoch 1 #29300 -- loss: 0.0321732813201379, acc: 0.98875\n","Epoch 1 #29350 -- loss: 0.024505409291305114, acc: 0.99\n","Epoch 1 #29400 -- loss: 0.03603922305104788, acc: 0.98625\n","Epoch 1 #29450 -- loss: 0.014875662928388919, acc: 0.99625\n","Epoch 1 #29500 -- loss: 0.01128224255735404, acc: 0.99625\n","Epoch 1 #29550 -- loss: 0.02473989778023679, acc: 0.99125\n","Epoch 1 #29600 -- loss: 0.02375257278632489, acc: 0.99125\n","Epoch 1 #29650 -- loss: 0.023757954647298903, acc: 0.99\n","Epoch 1 #29700 -- loss: 0.017637106984329874, acc: 0.99125\n","Epoch 1 #29750 -- loss: 0.021611538931028917, acc: 0.995\n","Epoch 1 #29800 -- loss: 0.023752148918283637, acc: 0.99375\n","Epoch 1 #29850 -- loss: 0.03489161583987879, acc: 0.98625\n","Epoch 1 #29900 -- loss: 0.02290904376684921, acc: 0.99125\n","Epoch 1 #29950 -- loss: 0.030970306856906972, acc: 0.9925\n","Epoch 1 #30000 -- loss: 0.017155665323662105, acc: 0.99375\n","Epoch 1 #30050 -- loss: 0.01548271523672156, acc: 0.9975\n","Epoch 1 #30100 -- loss: 0.025857944687013513, acc: 0.995\n","Epoch 1 #30150 -- loss: 0.01742493546218611, acc: 0.995\n","Epoch 1 #30200 -- loss: 0.029739408183086197, acc: 0.9875\n","Epoch 1 #30250 -- loss: 0.0235539999770117, acc: 0.9925\n","Epoch 1 #30300 -- loss: 0.04192242201184854, acc: 0.985\n","Epoch 1 #30350 -- loss: 0.01950577921816148, acc: 0.99125\n","Epoch 1 #30400 -- loss: 0.008835754070751135, acc: 0.9975\n","Epoch 1 #30450 -- loss: 0.015014938199310563, acc: 0.9975\n","Epoch 1 #30500 -- loss: 0.016035659410990773, acc: 0.995\n","Epoch 1 #30550 -- loss: 0.01741329050040804, acc: 0.99375\n","Epoch 1 #30600 -- loss: 0.015477772153535624, acc: 0.9925\n","Epoch 1 #30650 -- loss: 0.01681426709954394, acc: 0.9925\n","Epoch 1 #30700 -- loss: 0.017234111658035546, acc: 0.9925\n","Epoch 1 #30750 -- loss: 0.04383996497053886, acc: 0.9825\n","Epoch 1 #30800 -- loss: 0.0211727873570635, acc: 0.99\n","Epoch 1 #30850 -- loss: 0.056908563898759895, acc: 0.985\n","Epoch 1 #30900 -- loss: 0.026345748029416426, acc: 0.99125\n","Epoch 1 #30950 -- loss: 0.022312616863055156, acc: 0.995\n","Epoch 1 #31000 -- loss: 0.01977223191293888, acc: 0.99375\n","Epoch 1 #31050 -- loss: 0.03563943358662072, acc: 0.9925\n","Epoch 1 #31100 -- loss: 0.01796462702739518, acc: 0.99125\n","Epoch 1 #31150 -- loss: 0.022500958235759753, acc: 0.99375\n","Epoch 1 #31200 -- loss: 0.049549017221143, acc: 0.98375\n","Epoch 1 #31250 -- loss: 0.03535027911304496, acc: 0.99\n","Epoch 1 #31300 -- loss: 0.03702384121483192, acc: 0.98875\n","Epoch 1 #31350 -- loss: 0.0376667430420639, acc: 0.9875\n","Epoch 1 #31400 -- loss: 0.021854841517051683, acc: 0.99125\n","Epoch 1 #31450 -- loss: 0.01467360191163607, acc: 0.99375\n","Epoch 1 #31500 -- loss: 0.03113918112416286, acc: 0.9875\n","Epoch 1 #31550 -- loss: 0.029732399847707713, acc: 0.99125\n","Epoch 1 #31600 -- loss: 0.025466964264342095, acc: 0.9925\n","Epoch 1 #31650 -- loss: 0.026420206326292828, acc: 0.9875\n","Epoch 1 #31700 -- loss: 0.020751517443859484, acc: 0.995\n","Epoch 1 #31750 -- loss: 0.009265909269743133, acc: 0.99625\n","Epoch 1 #31800 -- loss: 0.02166121294401819, acc: 0.9925\n","Epoch 1 #31850 -- loss: 0.011119909330154769, acc: 0.99625\n","Epoch 1 #31900 -- loss: 0.01583205580012873, acc: 0.995\n","Epoch 1 #31950 -- loss: 0.03240203089342685, acc: 0.9875\n","Epoch 1 #32000 -- loss: 0.019336670859192964, acc: 0.995\n","Epoch 1 #32050 -- loss: 0.014777768754574936, acc: 0.995\n","Epoch 1 #32100 -- loss: 0.04143374641338596, acc: 0.9875\n","Epoch 1 #32150 -- loss: 0.031256247299024834, acc: 0.9875\n","Epoch 1 #32200 -- loss: 0.01794518107373733, acc: 0.9925\n","Epoch 1 #32250 -- loss: 0.025169330729404464, acc: 0.99\n","Epoch 1 #32300 -- loss: 0.032093915805453434, acc: 0.99\n","Epoch 1 #32350 -- loss: 0.02273878445063019, acc: 0.99125\n","Epoch 1 #32400 -- loss: 0.03321889820625074, acc: 0.99125\n","Epoch 1 #32450 -- loss: 0.016475611338973975, acc: 0.995\n","Epoch 1 #32500 -- loss: 0.019955219966650475, acc: 0.99125\n","Epoch 1 #32550 -- loss: 0.02539761215331964, acc: 0.9925\n","Epoch 1 #32600 -- loss: 0.022456458781671244, acc: 0.98875\n","Epoch 1 #32650 -- loss: 0.0182216536719352, acc: 0.995\n","Epoch 1 #32700 -- loss: 0.045658889395417644, acc: 0.98625\n","Epoch 1 #32750 -- loss: 0.02688892963575199, acc: 0.99125\n","Epoch 1 #32800 -- loss: 0.02341776808258146, acc: 0.99125\n","Epoch 1 #32850 -- loss: 0.010063465147977695, acc: 0.995\n","Epoch 1 #32900 -- loss: 0.008913280499982648, acc: 0.99625\n","Epoch 1 #32950 -- loss: 0.03088997207727516, acc: 0.99125\n","Epoch 1 #33000 -- loss: 0.00934559374814853, acc: 0.9975\n","\n","Epoch 1 loss: 0.05339405259155804, acc: 0.9797007575757576\n"]}],"source":["f = 2\n","e = 1\n","\n","print(f\"------------------------------ {f} fold {e} epoch------------------------------\")\n","\n","model.train()\n","epoch_perform, batch_perform = np.zeros(2), np.zeros(2)\n","print()\t\n","progress_bar = tqdm(enumerate(trainloader), total=len(trainloader), leave=True, position=0,)\n","for j, v in progress_bar:\n","  input_ids, attention_mask, labels = v['input_ids'].to(device), v['attention_mask'].to(device), v['labels'].to(device)\n","  \n","  optimizer.zero_grad()\n","  \n","  outputs = model(input_ids, attention_mask) ## label을 안 넣어서 logits값만 출력\n","  output = outputs.logits # The outputs object is a SequenceClassifierOutput\n","  loss = criterion(output, labels)\n","  loss.backward()\n","  optimizer.step()\n","  scheduler.step()\n","  for learning_rate in scheduler.get_lr():\n","    wandb.log({\"learning_rate\": learning_rate})\n","\n","  predict = output.argmax(dim=-1)\n","  predict = predict.detach().cpu().numpy()\n","  labels = labels.detach().cpu().numpy()\n","  acc = accuracy_score(labels, predict)\n","\n","  batch_perform += np.array([loss.item(), acc])\n","  epoch_perform += np.array([loss.item(), acc])\n","\n","  if (j + 1) % 50 == 0:\n","    print(\n","        f\"Epoch {e} #{j + 1} -- loss: {batch_perform[0] / 50}, acc: {batch_perform[1] / 50}\"\n","    )\n","    batch_perform = np.zeros(2)\n","print()\n","print(\n","    f\"Epoch {e} loss: {epoch_perform[0] / total_batch_}, acc: {epoch_perform[1] / total_batch_}\"\n","    )\n","wandb.log({\n","    \"epoch\": e,\n","    \"Train epoch Loss\": epoch_perform[0] / total_batch_,\n","    \"Train epoch Acc\": epoch_perform[1] / total_batch_}\n","    )\n","torch.save(model.state_dict(), f\"./models/{args.model_name}/{f}-fold/train.pt\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2270234,"status":"ok","timestamp":1654595446467,"user":{"displayName":"Lainie Kang","userId":"17932680864583243195"},"user_tz":-540},"id":"Qoiv_9CeO_fy","outputId":"9ad49393-26af-4a52-d8ee-be9a7cce33bf"},"outputs":[{"name":"stdout","output_type":"stream","text":["New best model for val accuracy : 0.9936969696969697! saving the best model..\n","=============== Fold2 Wrong DataFrame Saved ===============\n","\n",">>>> Validation loss: 0.019624535606069856, Acc: 0.9936969696969697\n","\n","==================================================\n","2fold best_val_acc_list : [0.9936969696969697]\n","=============== 2fold Final Score(ACC) : 0.9936969696969697 ===============\n"]}],"source":["f = 2\n","e = 1\n","best_val_loss, best_val_acc, = np.inf, 0\n","###### Validation\n","load_path = f'./models/{args.model_name}/{f}-fold/train.pt'\n","model.load_state_dict(torch.load(load_path,map_location=device))\n","model.to(device)\n","model.eval()\n","valid_perform = np.zeros(2)\n","\n","all_valid_predict_lst = []\n","all_valid_labels_lst = []\n","\n","# 틀린 데이터들을 wandb 기록하기 위함.\n","wrong_sample_dict = defaultdict(list)\n","\n","with torch.no_grad():\n","    for v in validloader:\n","      input_ids, attention_mask, valid_labels = v[\"input_ids\"].to(device), v[\"attention_mask\"].to(device), v[\"labels\"].to(device)\n","      \n","      valid_outputs = model(input_ids, attention_mask)\n","      valid_output = valid_outputs.logits\n","      valid_loss = criterion(valid_output, valid_labels)\n","      \n","      valid_predict = valid_output.argmax(dim=-1)\n","      valid_predict = valid_predict.detach().cpu().numpy()\n","      valid_labels = valid_labels.detach().cpu().numpy()\n","\n","      ###########################\n","      # valid eval 결과, 틀린 데이터들은 wandb에 Logging\n","      if args.logging_wrong_samples:\n","        wrong_sample_index = np.where(valid_labels!=valid_predict)[0]\n","        if len(wrong_sample_index)>0:\n","          wrong_sample_text, wrong_sample_label, wrong_sample_pred, entailment_prob, contradiction_prob = wrong_batch_for_wandb(tokenizer, wrong_sample_index, input_ids, valid_labels, valid_predict, valid_output)\n","\n","          wrong_sample_dict['입력 코드 Pair'] += wrong_sample_text\n","          wrong_sample_dict['실제값'] += wrong_sample_label\n","          wrong_sample_dict['예측값'] += wrong_sample_pred\n","          wrong_sample_dict['diff_logit'] += entailment_prob\n","          wrong_sample_dict['same_logit'] += contradiction_prob\n","      ###########################\n","\n","      valid_acc = accuracy_score(valid_labels, valid_predict)\n","      valid_perform += np.array([valid_loss.item(), valid_acc])\n","\n","      all_valid_predict_lst += list(valid_predict)\n","      all_valid_labels_lst += list(valid_labels)\n","  \n","###### Model save\n","val_total_loss = valid_perform[0] / valid_batch_\n","val_total_acc = valid_perform[1] / valid_batch_\n","best_val_loss = min(best_val_loss, val_total_loss)\n","\n","\n","if val_total_acc > best_val_acc:\n","    print(f\"New best model for val accuracy : {val_total_acc}! saving the best model..\")\n","    torch.save(model.state_dict(), f\"./models/{args.model_name}/{f}-fold/best.pt\")\n","\n","    # 참고 : Model 추가 재학습을 위한 모델을 저장하는 코드\n","    # https://tutorials.pytorch.kr/beginner/saving_loading_models.html#checkpoint\n","\n","    best_val_acc = val_total_acc\n","\n","    ### Confusion Matrix\n","    class_names = ['diff','same'] # (0,1,2)\n","    # https://wandb.ai/wandb/plots/reports/Confusion-Matrix--VmlldzozMDg1NTM\n","    wandb.log({f\"{e}_epoch_conf_mat\" : wandb.plot.confusion_matrix(probs=None,\n","                                                                      y_true=all_valid_labels_lst, preds=all_valid_predict_lst,\n","                                                                      class_names=class_names)})\n","      \n","    if args.logging_wrong_samples and val_total_acc > 0.91:\n","      ########### Logging Wrong Samples ##########\n","      # Save Wrong DataFrame\n","      wrong_sample_df = pd.DataFrame(wrong_sample_dict)\n","      wrong_sample_df.to_csv(f\"./models/{args.model_name}/{f}-fold/wrong_df.csv\",index=False)\n","      print('='*15,f'Fold{f} Wrong DataFrame Saved','='*15)\n","      # Loggin Wandb\n","      text_table = wandb.Table(data = wrong_sample_df)\n","      run.log({f\"{f}_fold_wrong_samples\" : text_table})\n","      ###########################\n","    \n","print()\n","print(\n","    f\">>>> Validation loss: {val_total_loss}, Acc: {val_total_acc}\"\n","    )\n","print()\n","wandb.log({\n","    \"epoch\": e,\n","    \"Last_Valid Loss\": val_total_loss,\n","    \"Last_Valid Acc\": val_total_acc,\n","    })\n","best_val_acc_list.append(best_val_acc)\n","print('='*50)\n","print(f\"{f}fold best_val_acc_list : {best_val_acc_list}\")\n","print('='*15, f'{f}fold Final Score(ACC) : {np.mean(best_val_acc_list)}', '='*15)\n","wandb.log({\n","f\"Total Mean ACC ({f}fold)\": np.mean(best_val_acc_list)}\n",")"]},{"cell_type":"markdown","metadata":{"id":"7YC3_0G3gD9J"},"source":["# 3 fold"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":104},"executionInfo":{"elapsed":6733,"status":"ok","timestamp":1654604114461,"user":{"displayName":"Lainie Kang","userId":"17932680864583243195"},"user_tz":-540},"id":"VLQm25TQgD9S","outputId":"df658033-47a7-4fe7-9dca-539ee2c144b1"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnahyeonkang\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"name":"stdout","output_type":"stream","text":["---------------------------------- 3 fold----------------------------------\n"]},{"data":{"text/html":["Tracking run with wandb version 0.12.17"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/drive/MyDrive/DACON/wandb/run-20220607_121507-8mbqvyn8</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href=\"https://wandb.ai/nahyeonkang/graphcodebert_Bs16_OptAdamW_ScduCosine_Sm0.0/runs/8mbqvyn8\" target=\"_blank\">happy-dawn-11</a></strong> to <a href=\"https://wandb.ai/nahyeonkang/graphcodebert_Bs16_OptAdamW_ScduCosine_Sm0.0\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["f = 3\n","\n","print(f\"---------------------------------- {f} fold----------------------------------\")\n","\n","run = wandb.init(project=args.project_name)\n","wandb.run.name = f'{args.model_name}/{f}-fold'\n","wandb.config.update(args)\n","os.makedirs(f'./models/{args.model_name}/{f}-fold', exist_ok=True)\n","\n","total_size = len(dataset)\n","total_ids = list(range(total_size))\n","del_ids = list(range((f-1)*gap, f*gap))\n","training_ids = set(total_ids) - set(del_ids)\n","\n","training_dset = dataset.select(list(training_ids))\n","eval_dset = dataset.select(del_ids)\n","\n","collator = DataCollatorWithPadding(tokenizer=tokenizer)\n","\n","trainloader = DataLoader(training_dset,\n","                          batch_size=16,\n","                          shuffle=True,\n","                          collate_fn = collator\n","                          )\n","\n","validloader = DataLoader(eval_dset,\n","                          batch_size=16,\n","                          shuffle=False,\n","                          collate_fn = collator\n","                          )\n","\n","total_batch_ = len(trainloader)\n","valid_batch_ = len(validloader)\n","\n","optimizer = get_optimizer(model, args)\n","scheduler = get_scheduler(optimizer, args, total_batch_)"]},{"cell_type":"markdown","metadata":{"id":"BAGRvxvSgD9T"},"source":["## 1 epoch"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27980880,"status":"ok","timestamp":1654632095333,"user":{"displayName":"Lainie Kang","userId":"17932680864583243195"},"user_tz":-540},"id":"UwgqDuxLgD9T","outputId":"5051b0de-b5f7-438f-be8d-6607af2fedcb"},"outputs":[{"name":"stdout","output_type":"stream","text":["------------------------------ 3 fold 1 epoch------------------------------\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"17ea01f1066240c6aee55be8b1a36a04","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/33000 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 1 #50 -- loss: 0.6944829165935517, acc: 0.485\n","Epoch 1 #100 -- loss: 0.6867254137992859, acc: 0.54875\n","Epoch 1 #150 -- loss: 0.682221246957779, acc: 0.55625\n","Epoch 1 #200 -- loss: 0.6456893861293793, acc: 0.63625\n","Epoch 1 #250 -- loss: 0.4734108594059944, acc: 0.78\n","Epoch 1 #300 -- loss: 0.3881120966374874, acc: 0.8375\n","Epoch 1 #350 -- loss: 0.3164524355530739, acc: 0.86375\n","Epoch 1 #400 -- loss: 0.23843293450772762, acc: 0.9\n","Epoch 1 #450 -- loss: 0.254080480709672, acc: 0.89625\n","Epoch 1 #500 -- loss: 0.22996790029108524, acc: 0.905\n","Epoch 1 #550 -- loss: 0.21558539021760226, acc: 0.9175\n","Epoch 1 #600 -- loss: 0.1737480340152979, acc: 0.93375\n","Epoch 1 #650 -- loss: 0.19372726561501621, acc: 0.92125\n","Epoch 1 #700 -- loss: 0.2150927236676216, acc: 0.91625\n","Epoch 1 #750 -- loss: 0.17217799790203572, acc: 0.9325\n","Epoch 1 #800 -- loss: 0.14376555467024446, acc: 0.945\n","Epoch 1 #850 -- loss: 0.19577322551980614, acc: 0.91875\n","Epoch 1 #900 -- loss: 0.14963770128786563, acc: 0.9425\n","Epoch 1 #950 -- loss: 0.16461819015443324, acc: 0.945\n","Epoch 1 #1000 -- loss: 0.13971316771581768, acc: 0.94875\n","Epoch 1 #1050 -- loss: 0.12785281852819025, acc: 0.955\n","Epoch 1 #1100 -- loss: 0.13372734727337957, acc: 0.95\n","Epoch 1 #1150 -- loss: 0.1418733375146985, acc: 0.955\n","Epoch 1 #1200 -- loss: 0.15926654003560542, acc: 0.93875\n","Epoch 1 #1250 -- loss: 0.13918875481933354, acc: 0.94875\n","Epoch 1 #1300 -- loss: 0.12549036975950004, acc: 0.9575\n","Epoch 1 #1350 -- loss: 0.15482230925932527, acc: 0.945\n","Epoch 1 #1400 -- loss: 0.12699068853631615, acc: 0.95875\n","Epoch 1 #1450 -- loss: 0.10953677103854716, acc: 0.95875\n","Epoch 1 #1500 -- loss: 0.14192127514630556, acc: 0.94625\n","Epoch 1 #1550 -- loss: 0.13244019052945077, acc: 0.95\n","Epoch 1 #1600 -- loss: 0.10912753546610475, acc: 0.96125\n","Epoch 1 #1650 -- loss: 0.11658540913835168, acc: 0.9575\n","Epoch 1 #1700 -- loss: 0.16208440687507392, acc: 0.9425\n","Epoch 1 #1750 -- loss: 0.13624586760066448, acc: 0.9475\n","Epoch 1 #1800 -- loss: 0.10245342135429382, acc: 0.95125\n","Epoch 1 #1850 -- loss: 0.13190599757246674, acc: 0.95625\n","Epoch 1 #1900 -- loss: 0.09273451783694327, acc: 0.965\n","Epoch 1 #1950 -- loss: 0.13232233349233866, acc: 0.9475\n","Epoch 1 #2000 -- loss: 0.0959620148036629, acc: 0.96375\n","Epoch 1 #2050 -- loss: 0.11890034299343824, acc: 0.95875\n","Epoch 1 #2100 -- loss: 0.12983358171768486, acc: 0.955\n","Epoch 1 #2150 -- loss: 0.10926608660258352, acc: 0.9575\n","Epoch 1 #2200 -- loss: 0.13059526037424804, acc: 0.95375\n","Epoch 1 #2250 -- loss: 0.10532730219885707, acc: 0.9625\n","Epoch 1 #2300 -- loss: 0.09847977174445986, acc: 0.9675\n","Epoch 1 #2350 -- loss: 0.10065995657816529, acc: 0.9575\n","Epoch 1 #2400 -- loss: 0.07678715351037681, acc: 0.97125\n","Epoch 1 #2450 -- loss: 0.12503348605707287, acc: 0.955\n","Epoch 1 #2500 -- loss: 0.06419052719138563, acc: 0.9775\n","Epoch 1 #2550 -- loss: 0.08839690154884011, acc: 0.97125\n","Epoch 1 #2600 -- loss: 0.0955918369954452, acc: 0.965\n","Epoch 1 #2650 -- loss: 0.11410063993185758, acc: 0.95375\n","Epoch 1 #2700 -- loss: 0.0954018901474774, acc: 0.9625\n","Epoch 1 #2750 -- loss: 0.09097351065371186, acc: 0.96375\n","Epoch 1 #2800 -- loss: 0.08755063251592218, acc: 0.96\n","Epoch 1 #2850 -- loss: 0.1221896100603044, acc: 0.955\n","Epoch 1 #2900 -- loss: 0.10550456277793273, acc: 0.96125\n","Epoch 1 #2950 -- loss: 0.09927355282008649, acc: 0.9625\n","Epoch 1 #3000 -- loss: 0.10687451749108731, acc: 0.955\n","Epoch 1 #3050 -- loss: 0.094020338030532, acc: 0.9675\n","Epoch 1 #3100 -- loss: 0.11286882712971419, acc: 0.95125\n","Epoch 1 #3150 -- loss: 0.07794488496147096, acc: 0.97125\n","Epoch 1 #3200 -- loss: 0.04694704588968307, acc: 0.98625\n","Epoch 1 #3250 -- loss: 0.08058562845923006, acc: 0.975\n","Epoch 1 #3300 -- loss: 0.10017442347481847, acc: 0.96\n","Epoch 1 #3350 -- loss: 0.1179043516376987, acc: 0.95625\n","Epoch 1 #3400 -- loss: 0.09940283216070384, acc: 0.9675\n","Epoch 1 #3450 -- loss: 0.11140634145820513, acc: 0.96\n","Epoch 1 #3500 -- loss: 0.0817600017087534, acc: 0.97\n","Epoch 1 #3550 -- loss: 0.06383899738080799, acc: 0.97625\n","Epoch 1 #3600 -- loss: 0.06648632645606994, acc: 0.9775\n","Epoch 1 #3650 -- loss: 0.09058427597396075, acc: 0.96875\n","Epoch 1 #3700 -- loss: 0.08713368092197925, acc: 0.9625\n","Epoch 1 #3750 -- loss: 0.10318597700446844, acc: 0.96\n","Epoch 1 #3800 -- loss: 0.09168092344421894, acc: 0.9675\n","Epoch 1 #3850 -- loss: 0.05148224542848766, acc: 0.9825\n","Epoch 1 #3900 -- loss: 0.0783783577918075, acc: 0.9725\n","Epoch 1 #3950 -- loss: 0.079078862471506, acc: 0.975\n","Epoch 1 #4000 -- loss: 0.07753468821756541, acc: 0.9675\n","Epoch 1 #4050 -- loss: 0.07532913668779656, acc: 0.9725\n","Epoch 1 #4100 -- loss: 0.09454689968377351, acc: 0.96875\n","Epoch 1 #4150 -- loss: 0.12070997949689627, acc: 0.9575\n","Epoch 1 #4200 -- loss: 0.08602280771825463, acc: 0.9675\n","Epoch 1 #4250 -- loss: 0.11287974475882948, acc: 0.95375\n","Epoch 1 #4300 -- loss: 0.05850471382495016, acc: 0.9775\n","Epoch 1 #4350 -- loss: 0.04291950676590204, acc: 0.97625\n","Epoch 1 #4400 -- loss: 0.058300084206275644, acc: 0.97625\n","Epoch 1 #4450 -- loss: 0.07916434613289311, acc: 0.975\n","Epoch 1 #4500 -- loss: 0.061753849829547104, acc: 0.9825\n","Epoch 1 #4550 -- loss: 0.06749244042672217, acc: 0.97625\n","Epoch 1 #4600 -- loss: 0.0911229861015454, acc: 0.9625\n","Epoch 1 #4650 -- loss: 0.06052983828820288, acc: 0.97625\n","Epoch 1 #4700 -- loss: 0.0829372567217797, acc: 0.96875\n","Epoch 1 #4750 -- loss: 0.06944780906196683, acc: 0.97625\n","Epoch 1 #4800 -- loss: 0.09132721413858234, acc: 0.965\n","Epoch 1 #4850 -- loss: 0.10463483826257289, acc: 0.95875\n","Epoch 1 #4900 -- loss: 0.08080030414275825, acc: 0.97\n","Epoch 1 #4950 -- loss: 0.07572262462694197, acc: 0.97\n","Epoch 1 #5000 -- loss: 0.0681351834628731, acc: 0.98125\n","Epoch 1 #5050 -- loss: 0.05745095730060711, acc: 0.97875\n","Epoch 1 #5100 -- loss: 0.07820097216870636, acc: 0.9725\n","Epoch 1 #5150 -- loss: 0.09247331480495631, acc: 0.96625\n","Epoch 1 #5200 -- loss: 0.10156546242535114, acc: 0.96625\n","Epoch 1 #5250 -- loss: 0.10811964651104063, acc: 0.96625\n","Epoch 1 #5300 -- loss: 0.07237729954533278, acc: 0.97875\n","Epoch 1 #5350 -- loss: 0.08736780639737844, acc: 0.965\n","Epoch 1 #5400 -- loss: 0.06430440383031964, acc: 0.97875\n","Epoch 1 #5450 -- loss: 0.09177994348108769, acc: 0.9725\n","Epoch 1 #5500 -- loss: 0.060909240853507074, acc: 0.9775\n","Epoch 1 #5550 -- loss: 0.06995913018472492, acc: 0.9775\n","Epoch 1 #5600 -- loss: 0.077566656190902, acc: 0.975\n","Epoch 1 #5650 -- loss: 0.049108598458115015, acc: 0.97875\n","Epoch 1 #5700 -- loss: 0.06546051159268246, acc: 0.9775\n","Epoch 1 #5750 -- loss: 0.07231395198963582, acc: 0.9775\n","Epoch 1 #5800 -- loss: 0.07157252331497148, acc: 0.97375\n","Epoch 1 #5850 -- loss: 0.05947857204009779, acc: 0.98125\n","Epoch 1 #5900 -- loss: 0.06739508272847161, acc: 0.98\n","Epoch 1 #5950 -- loss: 0.05767800039378926, acc: 0.9775\n","Epoch 1 #6000 -- loss: 0.0680308051011525, acc: 0.98125\n","Epoch 1 #6050 -- loss: 0.055096717479173093, acc: 0.975\n","Epoch 1 #6100 -- loss: 0.05250294040190056, acc: 0.98125\n","Epoch 1 #6150 -- loss: 0.06181521223857999, acc: 0.975\n","Epoch 1 #6200 -- loss: 0.08277859109453857, acc: 0.97125\n","Epoch 1 #6250 -- loss: 0.07586580171249807, acc: 0.97625\n","Epoch 1 #6300 -- loss: 0.06855321786832064, acc: 0.9775\n","Epoch 1 #6350 -- loss: 0.06850254582241178, acc: 0.9725\n","Epoch 1 #6400 -- loss: 0.05526977607049048, acc: 0.98125\n","Epoch 1 #6450 -- loss: 0.07227759781526402, acc: 0.975\n","Epoch 1 #6500 -- loss: 0.06364042210392654, acc: 0.98\n","Epoch 1 #6550 -- loss: 0.07136250477982685, acc: 0.98125\n","Epoch 1 #6600 -- loss: 0.06909887140616774, acc: 0.97125\n","Epoch 1 #6650 -- loss: 0.07631298813037574, acc: 0.975\n","Epoch 1 #6700 -- loss: 0.06610594415105879, acc: 0.975\n","Epoch 1 #6750 -- loss: 0.06587088714470156, acc: 0.9675\n","Epoch 1 #6800 -- loss: 0.05602171406149864, acc: 0.97875\n","Epoch 1 #6850 -- loss: 0.07179246393032372, acc: 0.9725\n","Epoch 1 #6900 -- loss: 0.06691064960323274, acc: 0.975\n","Epoch 1 #6950 -- loss: 0.056822167616337536, acc: 0.97875\n","Epoch 1 #7000 -- loss: 0.05393348900834098, acc: 0.98\n","Epoch 1 #7050 -- loss: 0.07624456909485161, acc: 0.9725\n","Epoch 1 #7100 -- loss: 0.06508637157734483, acc: 0.97\n","Epoch 1 #7150 -- loss: 0.09907992913853376, acc: 0.9625\n","Epoch 1 #7200 -- loss: 0.04732655123108998, acc: 0.98125\n","Epoch 1 #7250 -- loss: 0.0765950980479829, acc: 0.975\n","Epoch 1 #7300 -- loss: 0.040960018855985256, acc: 0.9825\n","Epoch 1 #7350 -- loss: 0.06000985903432593, acc: 0.98\n","Epoch 1 #7400 -- loss: 0.06027497541392222, acc: 0.97875\n","Epoch 1 #7450 -- loss: 0.06419601207133382, acc: 0.9825\n","Epoch 1 #7500 -- loss: 0.05661019584862515, acc: 0.98125\n","Epoch 1 #7550 -- loss: 0.04620021028094925, acc: 0.98375\n","Epoch 1 #7600 -- loss: 0.0736473878286779, acc: 0.96875\n","Epoch 1 #7650 -- loss: 0.058602963426383214, acc: 0.98375\n","Epoch 1 #7700 -- loss: 0.05178426631959155, acc: 0.97875\n","Epoch 1 #7750 -- loss: 0.06947387986350805, acc: 0.97875\n","Epoch 1 #7800 -- loss: 0.06110540774301626, acc: 0.97625\n","Epoch 1 #7850 -- loss: 0.029909843332134187, acc: 0.98625\n","Epoch 1 #7900 -- loss: 0.06077581876888871, acc: 0.98125\n","Epoch 1 #7950 -- loss: 0.05424454598687589, acc: 0.97875\n","Epoch 1 #8000 -- loss: 0.05238965696888045, acc: 0.98625\n","Epoch 1 #8050 -- loss: 0.05942678762366995, acc: 0.975\n","Epoch 1 #8100 -- loss: 0.061981276301667096, acc: 0.975\n","Epoch 1 #8150 -- loss: 0.06108769614715129, acc: 0.98125\n","Epoch 1 #8200 -- loss: 0.04186419932753779, acc: 0.98625\n","Epoch 1 #8250 -- loss: 0.07991098598111421, acc: 0.9775\n","Epoch 1 #8300 -- loss: 0.06071729366085492, acc: 0.97625\n","Epoch 1 #8350 -- loss: 0.05771789938095026, acc: 0.98375\n","Epoch 1 #8400 -- loss: 0.05064461209345609, acc: 0.9775\n","Epoch 1 #8450 -- loss: 0.07823168445029297, acc: 0.97625\n","Epoch 1 #8500 -- loss: 0.05630224272375926, acc: 0.98375\n","Epoch 1 #8550 -- loss: 0.03691558575956151, acc: 0.985\n","Epoch 1 #8600 -- loss: 0.05598960401723161, acc: 0.98375\n","Epoch 1 #8650 -- loss: 0.06206730551319197, acc: 0.97875\n","Epoch 1 #8700 -- loss: 0.06259984796168283, acc: 0.97625\n","Epoch 1 #8750 -- loss: 0.06334522939752787, acc: 0.9775\n","Epoch 1 #8800 -- loss: 0.06096284511964768, acc: 0.97625\n","Epoch 1 #8850 -- loss: 0.05490352056571282, acc: 0.98125\n","Epoch 1 #8900 -- loss: 0.02970319275278598, acc: 0.9875\n","Epoch 1 #8950 -- loss: 0.04868389847746585, acc: 0.98\n","Epoch 1 #9000 -- loss: 0.052320183069678027, acc: 0.98\n","Epoch 1 #9050 -- loss: 0.07152961763902567, acc: 0.975\n","Epoch 1 #9100 -- loss: 0.06512525772675871, acc: 0.9825\n","Epoch 1 #9150 -- loss: 0.04903063446516171, acc: 0.98\n","Epoch 1 #9200 -- loss: 0.06291902918601408, acc: 0.975\n","Epoch 1 #9250 -- loss: 0.06015507241245359, acc: 0.9775\n","Epoch 1 #9300 -- loss: 0.05984474473167211, acc: 0.97625\n","Epoch 1 #9350 -- loss: 0.041665637980913744, acc: 0.98625\n","Epoch 1 #9400 -- loss: 0.06541016803006641, acc: 0.9825\n","Epoch 1 #9450 -- loss: 0.058331584323896096, acc: 0.975\n","Epoch 1 #9500 -- loss: 0.06913918947684579, acc: 0.975\n","Epoch 1 #9550 -- loss: 0.07085412157233804, acc: 0.975\n","Epoch 1 #9600 -- loss: 0.06573928739177064, acc: 0.9725\n","Epoch 1 #9650 -- loss: 0.04110591508739162, acc: 0.98875\n","Epoch 1 #9700 -- loss: 0.05932436452480033, acc: 0.97875\n","Epoch 1 #9750 -- loss: 0.02801306501845829, acc: 0.9925\n","Epoch 1 #9800 -- loss: 0.051581300399266186, acc: 0.97875\n","Epoch 1 #9850 -- loss: 0.05322760473471135, acc: 0.97875\n","Epoch 1 #9900 -- loss: 0.04368343214155175, acc: 0.9825\n","Epoch 1 #9950 -- loss: 0.057129253880120814, acc: 0.9825\n","Epoch 1 #10000 -- loss: 0.04836844137869775, acc: 0.98375\n","Epoch 1 #10050 -- loss: 0.05916433751583099, acc: 0.9775\n","Epoch 1 #10100 -- loss: 0.05403359713731334, acc: 0.985\n","Epoch 1 #10150 -- loss: 0.04915935156168416, acc: 0.98\n","Epoch 1 #10200 -- loss: 0.07770968589931726, acc: 0.97\n","Epoch 1 #10250 -- loss: 0.05167373582487926, acc: 0.9825\n","Epoch 1 #10300 -- loss: 0.046587922805920244, acc: 0.9825\n","Epoch 1 #10350 -- loss: 0.040763917376752945, acc: 0.98625\n","Epoch 1 #10400 -- loss: 0.047191277800593526, acc: 0.985\n","Epoch 1 #10450 -- loss: 0.050452805133536456, acc: 0.9875\n","Epoch 1 #10500 -- loss: 0.042230551687534895, acc: 0.9875\n","Epoch 1 #10550 -- loss: 0.04481015665223822, acc: 0.98125\n","Epoch 1 #10600 -- loss: 0.04848327603307553, acc: 0.98375\n","Epoch 1 #10650 -- loss: 0.04633604809641838, acc: 0.9825\n","Epoch 1 #10700 -- loss: 0.05268089302873705, acc: 0.98125\n","Epoch 1 #10750 -- loss: 0.06524055101675913, acc: 0.97625\n","Epoch 1 #10800 -- loss: 0.08984493451658636, acc: 0.96\n","Epoch 1 #10850 -- loss: 0.04249192767310887, acc: 0.98\n","Epoch 1 #10900 -- loss: 0.06378228217363358, acc: 0.9775\n","Epoch 1 #10950 -- loss: 0.04701926613459364, acc: 0.985\n","Epoch 1 #11000 -- loss: 0.04821496018441394, acc: 0.9825\n","Epoch 1 #11050 -- loss: 0.036282737898873166, acc: 0.985\n","Epoch 1 #11100 -- loss: 0.038066736245527866, acc: 0.98125\n","Epoch 1 #11150 -- loss: 0.05469692491227761, acc: 0.98\n","Epoch 1 #11200 -- loss: 0.05285418036160991, acc: 0.985\n","Epoch 1 #11250 -- loss: 0.04604265498230234, acc: 0.98125\n","Epoch 1 #11300 -- loss: 0.036036814717808736, acc: 0.985\n","Epoch 1 #11350 -- loss: 0.058563524832716214, acc: 0.975\n","Epoch 1 #11400 -- loss: 0.05478070887504145, acc: 0.9875\n","Epoch 1 #11450 -- loss: 0.0455658129346557, acc: 0.9825\n","Epoch 1 #11500 -- loss: 0.05404999937629327, acc: 0.97875\n","Epoch 1 #11550 -- loss: 0.029489344600588083, acc: 0.99125\n","Epoch 1 #11600 -- loss: 0.1086342658731155, acc: 0.96125\n","Epoch 1 #11650 -- loss: 0.036622101376997306, acc: 0.98875\n","Epoch 1 #11700 -- loss: 0.07709853317821398, acc: 0.97875\n","Epoch 1 #11750 -- loss: 0.0427615381416399, acc: 0.97875\n","Epoch 1 #11800 -- loss: 0.06642837048973887, acc: 0.97875\n","Epoch 1 #11850 -- loss: 0.058328897913452235, acc: 0.9825\n","Epoch 1 #11900 -- loss: 0.04853524335892871, acc: 0.97625\n","Epoch 1 #11950 -- loss: 0.04434318273793906, acc: 0.985\n","Epoch 1 #12000 -- loss: 0.04001142291352153, acc: 0.98375\n","Epoch 1 #12050 -- loss: 0.05649804816115647, acc: 0.9825\n","Epoch 1 #12100 -- loss: 0.052929927746299656, acc: 0.98125\n","Epoch 1 #12150 -- loss: 0.03085500670131296, acc: 0.98875\n","Epoch 1 #12200 -- loss: 0.034547446868382396, acc: 0.99\n","Epoch 1 #12250 -- loss: 0.038543837810284455, acc: 0.98625\n","Epoch 1 #12300 -- loss: 0.045555189314763996, acc: 0.98375\n","Epoch 1 #12350 -- loss: 0.03496441518771462, acc: 0.99\n","Epoch 1 #12400 -- loss: 0.04161185926815961, acc: 0.98875\n","Epoch 1 #12450 -- loss: 0.038242090878775344, acc: 0.99125\n","Epoch 1 #12500 -- loss: 0.037334030751371754, acc: 0.9875\n","Epoch 1 #12550 -- loss: 0.05623887941706926, acc: 0.9825\n","Epoch 1 #12600 -- loss: 0.035223717669723556, acc: 0.98375\n","Epoch 1 #12650 -- loss: 0.04964278887724504, acc: 0.98625\n","Epoch 1 #12700 -- loss: 0.04681563885184005, acc: 0.98\n","Epoch 1 #12750 -- loss: 0.05122776166535914, acc: 0.98375\n","Epoch 1 #12800 -- loss: 0.035746015096083286, acc: 0.9875\n","Epoch 1 #12850 -- loss: 0.035991299930028614, acc: 0.9875\n","Epoch 1 #12900 -- loss: 0.06971868441905826, acc: 0.9725\n","Epoch 1 #12950 -- loss: 0.05513757625943981, acc: 0.98\n","Epoch 1 #13000 -- loss: 0.054696111662779004, acc: 0.97625\n","Epoch 1 #13050 -- loss: 0.02541437180072535, acc: 0.99\n","Epoch 1 #13100 -- loss: 0.038295621565193866, acc: 0.98625\n","Epoch 1 #13150 -- loss: 0.02868888769298792, acc: 0.99\n","Epoch 1 #13200 -- loss: 0.08325365781784058, acc: 0.97\n","Epoch 1 #13250 -- loss: 0.03208632882509846, acc: 0.98625\n","Epoch 1 #13300 -- loss: 0.03024232236086391, acc: 0.98875\n","Epoch 1 #13350 -- loss: 0.047660654908977446, acc: 0.98375\n","Epoch 1 #13400 -- loss: 0.028819037374341862, acc: 0.9875\n","Epoch 1 #13450 -- loss: 0.04546565528959036, acc: 0.98375\n","Epoch 1 #13500 -- loss: 0.05621334059978835, acc: 0.97875\n","Epoch 1 #13550 -- loss: 0.03472174661234021, acc: 0.9825\n","Epoch 1 #13600 -- loss: 0.05174716670066118, acc: 0.97875\n","Epoch 1 #13650 -- loss: 0.03406157155637629, acc: 0.99\n","Epoch 1 #13700 -- loss: 0.03874032986641396, acc: 0.985\n","Epoch 1 #13750 -- loss: 0.0353055231491453, acc: 0.99125\n","Epoch 1 #13800 -- loss: 0.047523353080032395, acc: 0.98\n","Epoch 1 #13850 -- loss: 0.05649445827351883, acc: 0.98125\n","Epoch 1 #13900 -- loss: 0.04505553772789426, acc: 0.97875\n","Epoch 1 #13950 -- loss: 0.031133960023289546, acc: 0.98625\n","Epoch 1 #14000 -- loss: 0.033597942835185676, acc: 0.985\n","Epoch 1 #14050 -- loss: 0.026371416085457896, acc: 0.9875\n","Epoch 1 #14100 -- loss: 0.048259561950690116, acc: 0.985\n","Epoch 1 #14150 -- loss: 0.04425672087294515, acc: 0.9875\n","Epoch 1 #14200 -- loss: 0.04756050271214917, acc: 0.98875\n","Epoch 1 #14250 -- loss: 0.02946645520394668, acc: 0.9925\n","Epoch 1 #14300 -- loss: 0.04322980543132871, acc: 0.98375\n","Epoch 1 #14350 -- loss: 0.05790579833439551, acc: 0.98125\n","Epoch 1 #14400 -- loss: 0.04666186631890014, acc: 0.9825\n","Epoch 1 #14450 -- loss: 0.0295389633520972, acc: 0.9875\n","Epoch 1 #14500 -- loss: 0.049579309021355586, acc: 0.98625\n","Epoch 1 #14550 -- loss: 0.028544377210200766, acc: 0.99\n","Epoch 1 #14600 -- loss: 0.043375315578305165, acc: 0.98625\n","Epoch 1 #14650 -- loss: 0.04174501299858093, acc: 0.98625\n","Epoch 1 #14700 -- loss: 0.07165062130778097, acc: 0.9725\n","Epoch 1 #14750 -- loss: 0.037238875722978265, acc: 0.9875\n","Epoch 1 #14800 -- loss: 0.042197693538619206, acc: 0.985\n","Epoch 1 #14850 -- loss: 0.020481490763486362, acc: 0.99625\n","Epoch 1 #14900 -- loss: 0.03396184271201491, acc: 0.98625\n","Epoch 1 #14950 -- loss: 0.0452355873642955, acc: 0.98\n","Epoch 1 #15000 -- loss: 0.030063334457809107, acc: 0.98875\n","Epoch 1 #15050 -- loss: 0.033350027160486205, acc: 0.99125\n","Epoch 1 #15100 -- loss: 0.04053733364853542, acc: 0.985\n","Epoch 1 #15150 -- loss: 0.06132954790489748, acc: 0.98125\n","Epoch 1 #15200 -- loss: 0.06732212894130499, acc: 0.97625\n","Epoch 1 #15250 -- loss: 0.03798586259130388, acc: 0.98375\n","Epoch 1 #15300 -- loss: 0.025642479145899413, acc: 0.9925\n","Epoch 1 #15350 -- loss: 0.05430236813437659, acc: 0.9775\n","Epoch 1 #15400 -- loss: 0.06727298310375772, acc: 0.97875\n","Epoch 1 #15450 -- loss: 0.03026251072762534, acc: 0.99\n","Epoch 1 #15500 -- loss: 0.03851096900762059, acc: 0.98875\n","Epoch 1 #15550 -- loss: 0.04248645964020398, acc: 0.98625\n","Epoch 1 #15600 -- loss: 0.02729516537277959, acc: 0.98875\n","Epoch 1 #15650 -- loss: 0.032177595556713644, acc: 0.9875\n","Epoch 1 #15700 -- loss: 0.03760305802919902, acc: 0.98625\n","Epoch 1 #15750 -- loss: 0.020988293408881874, acc: 0.9925\n","Epoch 1 #15800 -- loss: 0.053863008890184576, acc: 0.98625\n","Epoch 1 #15850 -- loss: 0.06387413243646733, acc: 0.98125\n","Epoch 1 #15900 -- loss: 0.049023452311521394, acc: 0.97875\n","Epoch 1 #15950 -- loss: 0.03199610179406591, acc: 0.98875\n","Epoch 1 #16000 -- loss: 0.0458696456043981, acc: 0.98625\n","Epoch 1 #16050 -- loss: 0.043828979660756884, acc: 0.98625\n","Epoch 1 #16100 -- loss: 0.029952169816242533, acc: 0.99125\n","Epoch 1 #16150 -- loss: 0.03597394716460258, acc: 0.98125\n","Epoch 1 #16200 -- loss: 0.03826211760751903, acc: 0.9875\n","Epoch 1 #16250 -- loss: 0.03783668972551823, acc: 0.98375\n","Epoch 1 #16300 -- loss: 0.04020507028035354, acc: 0.98375\n","Epoch 1 #16350 -- loss: 0.037186616666731426, acc: 0.99125\n","Epoch 1 #16400 -- loss: 0.03322894363780506, acc: 0.99\n","Epoch 1 #16450 -- loss: 0.049222521578194574, acc: 0.9825\n","Epoch 1 #16500 -- loss: 0.025700891976011917, acc: 0.9925\n","Epoch 1 #16550 -- loss: 0.033614937169477346, acc: 0.99125\n","Epoch 1 #16600 -- loss: 0.02665029758878518, acc: 0.99\n","Epoch 1 #16650 -- loss: 0.038085171596030705, acc: 0.99\n","Epoch 1 #16700 -- loss: 0.040335672708461064, acc: 0.985\n","Epoch 1 #16750 -- loss: 0.05271119146491401, acc: 0.98\n","Epoch 1 #16800 -- loss: 0.03320754735497758, acc: 0.99125\n","Epoch 1 #16850 -- loss: 0.04965185962617397, acc: 0.9825\n","Epoch 1 #16900 -- loss: 0.029209391619078814, acc: 0.9925\n","Epoch 1 #16950 -- loss: 0.033662046064273456, acc: 0.985\n","Epoch 1 #17000 -- loss: 0.054766708496026696, acc: 0.98375\n","Epoch 1 #17050 -- loss: 0.03370475632604211, acc: 0.9875\n","Epoch 1 #17100 -- loss: 0.0512007487914525, acc: 0.97875\n","Epoch 1 #17150 -- loss: 0.04385514322202653, acc: 0.985\n","Epoch 1 #17200 -- loss: 0.03086843634955585, acc: 0.99\n","Epoch 1 #17250 -- loss: 0.04515019007143564, acc: 0.98375\n","Epoch 1 #17300 -- loss: 0.03253266036917921, acc: 0.9875\n","Epoch 1 #17350 -- loss: 0.025948763630003667, acc: 0.99125\n","Epoch 1 #17400 -- loss: 0.0391116413709824, acc: 0.98875\n","Epoch 1 #17450 -- loss: 0.030751129580312408, acc: 0.9925\n","Epoch 1 #17500 -- loss: 0.040200561409583314, acc: 0.985\n","Epoch 1 #17550 -- loss: 0.05204340505646542, acc: 0.98625\n","Epoch 1 #17600 -- loss: 0.02713256452116184, acc: 0.99125\n","Epoch 1 #17650 -- loss: 0.05715555011003744, acc: 0.985\n","Epoch 1 #17700 -- loss: 0.03472683341940865, acc: 0.9875\n","Epoch 1 #17750 -- loss: 0.03989125219522975, acc: 0.9875\n","Epoch 1 #17800 -- loss: 0.038615976525470615, acc: 0.985\n","Epoch 1 #17850 -- loss: 0.02575993476784788, acc: 0.99\n","Epoch 1 #17900 -- loss: 0.039158137778867966, acc: 0.99\n","Epoch 1 #17950 -- loss: 0.032186828539706766, acc: 0.9875\n","Epoch 1 #18000 -- loss: 0.04352095185138751, acc: 0.985\n","Epoch 1 #18050 -- loss: 0.035378618161194024, acc: 0.98875\n","Epoch 1 #18100 -- loss: 0.020754358929116277, acc: 0.99125\n","Epoch 1 #18150 -- loss: 0.03399373663531151, acc: 0.98625\n","Epoch 1 #18200 -- loss: 0.03592157681647223, acc: 0.985\n","Epoch 1 #18250 -- loss: 0.04487967358814785, acc: 0.9875\n","Epoch 1 #18300 -- loss: 0.03154767916945275, acc: 0.98875\n","Epoch 1 #18350 -- loss: 0.04317214382113889, acc: 0.98625\n","Epoch 1 #18400 -- loss: 0.025375176499364896, acc: 0.99\n","Epoch 1 #18450 -- loss: 0.02412081653077621, acc: 0.9925\n","Epoch 1 #18500 -- loss: 0.046480995628517124, acc: 0.985\n","Epoch 1 #18550 -- loss: 0.03726268918835558, acc: 0.9875\n","Epoch 1 #18600 -- loss: 0.018966895198973363, acc: 0.9975\n","Epoch 1 #18650 -- loss: 0.030737240358430427, acc: 0.98875\n","Epoch 1 #18700 -- loss: 0.03206433098413981, acc: 0.985\n","Epoch 1 #18750 -- loss: 0.055406667027855294, acc: 0.98125\n","Epoch 1 #18800 -- loss: 0.023820015664678066, acc: 0.9925\n","Epoch 1 #18850 -- loss: 0.0372275014576735, acc: 0.985\n","Epoch 1 #18900 -- loss: 0.06776325255981647, acc: 0.97625\n","Epoch 1 #18950 -- loss: 0.04479464885080233, acc: 0.9875\n","Epoch 1 #19000 -- loss: 0.048198748360737224, acc: 0.985\n","Epoch 1 #19050 -- loss: 0.04685519468272105, acc: 0.985\n","Epoch 1 #19100 -- loss: 0.03531232598645147, acc: 0.9875\n","Epoch 1 #19150 -- loss: 0.04808643496246077, acc: 0.98\n","Epoch 1 #19200 -- loss: 0.042915790141560134, acc: 0.98875\n","Epoch 1 #19250 -- loss: 0.032568661004770544, acc: 0.9825\n","Epoch 1 #19300 -- loss: 0.036999736935831605, acc: 0.98625\n","Epoch 1 #19350 -- loss: 0.04335778048785869, acc: 0.98\n","Epoch 1 #19400 -- loss: 0.037919495904352514, acc: 0.98625\n","Epoch 1 #19450 -- loss: 0.028387349199038, acc: 0.99\n","Epoch 1 #19500 -- loss: 0.043422756650834345, acc: 0.98125\n","Epoch 1 #19550 -- loss: 0.0384236789518036, acc: 0.9875\n","Epoch 1 #19600 -- loss: 0.03293169861193746, acc: 0.9875\n","Epoch 1 #19650 -- loss: 0.03767957934702281, acc: 0.985\n","Epoch 1 #19700 -- loss: 0.028133896655053833, acc: 0.99\n","Epoch 1 #19750 -- loss: 0.024611285980790855, acc: 0.9925\n","Epoch 1 #19800 -- loss: 0.04886034778668545, acc: 0.985\n","Epoch 1 #19850 -- loss: 0.03774347860366106, acc: 0.985\n","Epoch 1 #19900 -- loss: 0.030357554420479573, acc: 0.98875\n","Epoch 1 #19950 -- loss: 0.03475647094252054, acc: 0.99\n","Epoch 1 #20000 -- loss: 0.0424637471238384, acc: 0.98\n","Epoch 1 #20050 -- loss: 0.04140371868619695, acc: 0.98125\n","Epoch 1 #20100 -- loss: 0.03350874174037017, acc: 0.98875\n","Epoch 1 #20150 -- loss: 0.05160941839567386, acc: 0.9825\n","Epoch 1 #20200 -- loss: 0.04946779023506678, acc: 0.98\n","Epoch 1 #20250 -- loss: 0.02918760783970356, acc: 0.98875\n","Epoch 1 #20300 -- loss: 0.037715125912800435, acc: 0.98625\n","Epoch 1 #20350 -- loss: 0.030210453484905885, acc: 0.9875\n","Epoch 1 #20400 -- loss: 0.022799918886157684, acc: 0.99125\n","Epoch 1 #20450 -- loss: 0.02359726202703314, acc: 0.99625\n","Epoch 1 #20500 -- loss: 0.03261547883972526, acc: 0.99125\n","Epoch 1 #20550 -- loss: 0.041405444189440456, acc: 0.985\n","Epoch 1 #20600 -- loss: 0.029412434687837958, acc: 0.9925\n","Epoch 1 #20650 -- loss: 0.048317924807779494, acc: 0.9825\n","Epoch 1 #20700 -- loss: 0.036332229030085726, acc: 0.98625\n","Epoch 1 #20750 -- loss: 0.032639310180675236, acc: 0.99125\n","Epoch 1 #20800 -- loss: 0.023375650213565677, acc: 0.99125\n","Epoch 1 #20850 -- loss: 0.04131217542570084, acc: 0.98375\n","Epoch 1 #20900 -- loss: 0.04740057764807716, acc: 0.9825\n","Epoch 1 #20950 -- loss: 0.03766861649113707, acc: 0.99125\n","Epoch 1 #21000 -- loss: 0.0207618816732429, acc: 0.9925\n","Epoch 1 #21050 -- loss: 0.016148907228780443, acc: 0.99375\n","Epoch 1 #21100 -- loss: 0.025163863811758346, acc: 0.99\n","Epoch 1 #21150 -- loss: 0.022687188883428463, acc: 0.9925\n","Epoch 1 #21200 -- loss: 0.029900384847423994, acc: 0.9875\n","Epoch 1 #21250 -- loss: 0.022867244976223448, acc: 0.98875\n","Epoch 1 #21300 -- loss: 0.02622366057417821, acc: 0.98875\n","Epoch 1 #21350 -- loss: 0.02213479729834944, acc: 0.99\n","Epoch 1 #21400 -- loss: 0.03052772937284317, acc: 0.98875\n","Epoch 1 #21450 -- loss: 0.032982959295623004, acc: 0.99\n","Epoch 1 #21500 -- loss: 0.036869001917075366, acc: 0.98875\n","Epoch 1 #21550 -- loss: 0.028953705191379412, acc: 0.99\n","Epoch 1 #21600 -- loss: 0.01680385564774042, acc: 0.99625\n","Epoch 1 #21650 -- loss: 0.029440184757113456, acc: 0.9875\n","Epoch 1 #21700 -- loss: 0.01915443313162541, acc: 0.99375\n","Epoch 1 #21750 -- loss: 0.03074577454768587, acc: 0.98625\n","Epoch 1 #21800 -- loss: 0.014095499080140144, acc: 0.995\n","Epoch 1 #21850 -- loss: 0.02845651883253595, acc: 0.98875\n","Epoch 1 #21900 -- loss: 0.025890741346229332, acc: 0.9875\n","Epoch 1 #21950 -- loss: 0.06784674568742048, acc: 0.97875\n","Epoch 1 #22000 -- loss: 0.03453142310492694, acc: 0.985\n","Epoch 1 #22050 -- loss: 0.03717432718956843, acc: 0.99\n","Epoch 1 #22100 -- loss: 0.021347874618368224, acc: 0.99375\n","Epoch 1 #22150 -- loss: 0.03786524091119645, acc: 0.98875\n","Epoch 1 #22200 -- loss: 0.03819573087617755, acc: 0.98625\n","Epoch 1 #22250 -- loss: 0.037926479504676536, acc: 0.98625\n","Epoch 1 #22300 -- loss: 0.03589627214707434, acc: 0.99125\n","Epoch 1 #22350 -- loss: 0.026220290269120598, acc: 0.985\n","Epoch 1 #22400 -- loss: 0.0357417171006091, acc: 0.99\n","Epoch 1 #22450 -- loss: 0.04752204108983278, acc: 0.9825\n","Epoch 1 #22500 -- loss: 0.05384396367240697, acc: 0.985\n","Epoch 1 #22550 -- loss: 0.03394602488144301, acc: 0.98625\n","Epoch 1 #22600 -- loss: 0.02426723818993196, acc: 0.99125\n","Epoch 1 #22650 -- loss: 0.030023498572700192, acc: 0.99\n","Epoch 1 #22700 -- loss: 0.023396742560435085, acc: 0.99125\n","Epoch 1 #22750 -- loss: 0.04593401810736395, acc: 0.98375\n","Epoch 1 #22800 -- loss: 0.029771977447671814, acc: 0.9925\n","Epoch 1 #22850 -- loss: 0.03413750293315388, acc: 0.985\n","Epoch 1 #22900 -- loss: 0.028700684231589547, acc: 0.99\n","Epoch 1 #22950 -- loss: 0.03703001995163504, acc: 0.9825\n","Epoch 1 #23000 -- loss: 0.057885343165835365, acc: 0.98375\n","Epoch 1 #23050 -- loss: 0.04377632623305544, acc: 0.98375\n","Epoch 1 #23100 -- loss: 0.028217636062181556, acc: 0.98875\n","Epoch 1 #23150 -- loss: 0.027033293128479272, acc: 0.9925\n","Epoch 1 #23200 -- loss: 0.02444150460883975, acc: 0.99125\n","Epoch 1 #23250 -- loss: 0.018465694645419715, acc: 0.995\n","Epoch 1 #23300 -- loss: 0.026559643298387527, acc: 0.99125\n","Epoch 1 #23350 -- loss: 0.01706402472074842, acc: 0.9925\n","Epoch 1 #23400 -- loss: 0.04215047242003493, acc: 0.9825\n","Epoch 1 #23450 -- loss: 0.038392624238040296, acc: 0.9825\n","Epoch 1 #23500 -- loss: 0.03600738706300035, acc: 0.98875\n","Epoch 1 #23550 -- loss: 0.043354870805051175, acc: 0.9825\n","Epoch 1 #23600 -- loss: 0.02753358476649737, acc: 0.99\n","Epoch 1 #23650 -- loss: 0.023501168500515632, acc: 0.99375\n","Epoch 1 #23700 -- loss: 0.018256196864822414, acc: 0.995\n","Epoch 1 #23750 -- loss: 0.027911000469175634, acc: 0.99125\n","Epoch 1 #23800 -- loss: 0.035562650058127476, acc: 0.9825\n","Epoch 1 #23850 -- loss: 0.03231068856461206, acc: 0.99\n","Epoch 1 #23900 -- loss: 0.035512306588934735, acc: 0.9875\n","Epoch 1 #23950 -- loss: 0.02642901521496242, acc: 0.98875\n","Epoch 1 #24000 -- loss: 0.024439284359687008, acc: 0.99\n","Epoch 1 #24050 -- loss: 0.020036710826389026, acc: 0.99125\n","Epoch 1 #24100 -- loss: 0.030540908618131652, acc: 0.99375\n","Epoch 1 #24150 -- loss: 0.015426808665215503, acc: 0.99375\n","Epoch 1 #24200 -- loss: 0.029608000890584664, acc: 0.98625\n","Epoch 1 #24250 -- loss: 0.036472669150098225, acc: 0.9875\n","Epoch 1 #24300 -- loss: 0.02684803173004184, acc: 0.9925\n","Epoch 1 #24350 -- loss: 0.054078973886789755, acc: 0.9825\n","Epoch 1 #24400 -- loss: 0.03540343570290133, acc: 0.98875\n","Epoch 1 #24450 -- loss: 0.024448436655220576, acc: 0.9925\n","Epoch 1 #24500 -- loss: 0.028004598979314323, acc: 0.99\n","Epoch 1 #24550 -- loss: 0.0440117814525729, acc: 0.99\n","Epoch 1 #24600 -- loss: 0.03257107288809493, acc: 0.99\n","Epoch 1 #24650 -- loss: 0.04130193074000999, acc: 0.98625\n","Epoch 1 #24700 -- loss: 0.04523372411029413, acc: 0.985\n","Epoch 1 #24750 -- loss: 0.026346500409417786, acc: 0.9925\n","Epoch 1 #24800 -- loss: 0.01420932487002574, acc: 0.99625\n","Epoch 1 #24850 -- loss: 0.024530729326070286, acc: 0.99375\n","Epoch 1 #24900 -- loss: 0.027699960125028157, acc: 0.99375\n","Epoch 1 #24950 -- loss: 0.022802337351022287, acc: 0.99375\n","Epoch 1 #25000 -- loss: 0.020522417874599342, acc: 0.99125\n","Epoch 1 #25050 -- loss: 0.042942821783653926, acc: 0.98625\n","Epoch 1 #25100 -- loss: 0.04190739833982662, acc: 0.98625\n","Epoch 1 #25150 -- loss: 0.024315466791158542, acc: 0.9925\n","Epoch 1 #25200 -- loss: 0.037154858813155445, acc: 0.98875\n","Epoch 1 #25250 -- loss: 0.025038166705635377, acc: 0.99\n","Epoch 1 #25300 -- loss: 0.03623114946531132, acc: 0.99\n","Epoch 1 #25350 -- loss: 0.04010331671161112, acc: 0.98875\n","Epoch 1 #25400 -- loss: 0.04212503861053847, acc: 0.98875\n","Epoch 1 #25450 -- loss: 0.018903765914728865, acc: 0.9925\n","Epoch 1 #25500 -- loss: 0.010745517262257635, acc: 0.99625\n","Epoch 1 #25550 -- loss: 0.017858144834754057, acc: 0.995\n","Epoch 1 #25600 -- loss: 0.03497137521742843, acc: 0.99\n","Epoch 1 #25650 -- loss: 0.02896146435959963, acc: 0.99375\n","Epoch 1 #25700 -- loss: 0.049028971466468646, acc: 0.98375\n","Epoch 1 #25750 -- loss: 0.043541384077398104, acc: 0.98375\n","Epoch 1 #25800 -- loss: 0.019020773617667144, acc: 0.99375\n","Epoch 1 #25850 -- loss: 0.02282829961826792, acc: 0.9925\n","Epoch 1 #25900 -- loss: 0.01512261553260032, acc: 0.99375\n","Epoch 1 #25950 -- loss: 0.02174274299206445, acc: 0.99\n","Epoch 1 #26000 -- loss: 0.026782773428130895, acc: 0.9925\n","Epoch 1 #26050 -- loss: 0.026368024631519802, acc: 0.98875\n","Epoch 1 #26100 -- loss: 0.023984211922506802, acc: 0.99375\n","Epoch 1 #26150 -- loss: 0.03147645837685559, acc: 0.98875\n","Epoch 1 #26200 -- loss: 0.028934994337614626, acc: 0.985\n","Epoch 1 #26250 -- loss: 0.02240951092680916, acc: 0.99125\n","Epoch 1 #26300 -- loss: 0.012043038007686847, acc: 0.99625\n","Epoch 1 #26350 -- loss: 0.031120365571696312, acc: 0.98875\n","Epoch 1 #26400 -- loss: 0.018424861276871526, acc: 0.9925\n","Epoch 1 #26450 -- loss: 0.02037868286934099, acc: 0.995\n","Epoch 1 #26500 -- loss: 0.03459714009251911, acc: 0.9875\n","Epoch 1 #26550 -- loss: 0.01135808513383381, acc: 0.99625\n","Epoch 1 #26600 -- loss: 0.03813839431677479, acc: 0.985\n","Epoch 1 #26650 -- loss: 0.024758631695294752, acc: 0.9925\n","Epoch 1 #26700 -- loss: 0.026231214588624426, acc: 0.9925\n","Epoch 1 #26750 -- loss: 0.026061063864035533, acc: 0.99125\n","Epoch 1 #26800 -- loss: 0.050503465719521044, acc: 0.98625\n","Epoch 1 #26850 -- loss: 0.030633262494811787, acc: 0.98875\n","Epoch 1 #26900 -- loss: 0.012835983826371376, acc: 0.9975\n","Epoch 1 #26950 -- loss: 0.027833810515294318, acc: 0.9875\n","Epoch 1 #27000 -- loss: 0.024715498086297884, acc: 0.99\n","Epoch 1 #27050 -- loss: 0.04145496737153735, acc: 0.99125\n","Epoch 1 #27100 -- loss: 0.029179020759183914, acc: 0.9875\n","Epoch 1 #27150 -- loss: 0.017226922025438397, acc: 0.99375\n","Epoch 1 #27200 -- loss: 0.03976648869283963, acc: 0.98875\n","Epoch 1 #27250 -- loss: 0.029633053750148974, acc: 0.99\n","Epoch 1 #27300 -- loss: 0.030089374046074226, acc: 0.9875\n","Epoch 1 #27350 -- loss: 0.029070808572578245, acc: 0.99125\n","Epoch 1 #27400 -- loss: 0.02888923164427979, acc: 0.98625\n","Epoch 1 #27450 -- loss: 0.03419628037197981, acc: 0.9875\n","Epoch 1 #27500 -- loss: 0.02216695214738138, acc: 0.99\n","Epoch 1 #27550 -- loss: 0.027811069999006576, acc: 0.9925\n","Epoch 1 #27600 -- loss: 0.00963101275410736, acc: 0.99875\n","Epoch 1 #27650 -- loss: 0.02891137461847393, acc: 0.99\n","Epoch 1 #27700 -- loss: 0.030755019759526478, acc: 0.9875\n","Epoch 1 #27750 -- loss: 0.02301258915278595, acc: 0.99375\n","Epoch 1 #27800 -- loss: 0.0318191214610124, acc: 0.99\n","Epoch 1 #27850 -- loss: 0.03235751082218485, acc: 0.99\n","Epoch 1 #27900 -- loss: 0.025445218408713118, acc: 0.99125\n","Epoch 1 #27950 -- loss: 0.020322633749456146, acc: 0.99375\n","Epoch 1 #28000 -- loss: 0.017980168380308897, acc: 0.9925\n","Epoch 1 #28050 -- loss: 0.02738359826034866, acc: 0.995\n","Epoch 1 #28100 -- loss: 0.022725054073962383, acc: 0.9975\n","Epoch 1 #28150 -- loss: 0.019614282302209175, acc: 0.9925\n","Epoch 1 #28200 -- loss: 0.015004825696523767, acc: 0.9975\n","Epoch 1 #28250 -- loss: 0.025303869586787188, acc: 0.99375\n","Epoch 1 #28300 -- loss: 0.04432255185616668, acc: 0.9825\n","Epoch 1 #28350 -- loss: 0.022671405870933085, acc: 0.99625\n","Epoch 1 #28400 -- loss: 0.023402734847331887, acc: 0.9925\n","Epoch 1 #28450 -- loss: 0.022561127193039283, acc: 0.99375\n","Epoch 1 #28500 -- loss: 0.04114059411513153, acc: 0.9925\n","Epoch 1 #28550 -- loss: 0.02019129698164761, acc: 0.99375\n","Epoch 1 #28600 -- loss: 0.02956617239542538, acc: 0.99\n","Epoch 1 #28650 -- loss: 0.024295042927842587, acc: 0.99\n","Epoch 1 #28700 -- loss: 0.022974165576160884, acc: 0.99375\n","Epoch 1 #28750 -- loss: 0.029933219164959154, acc: 0.985\n","Epoch 1 #28800 -- loss: 0.021555426893755794, acc: 0.995\n","Epoch 1 #28850 -- loss: 0.013056478902872187, acc: 0.995\n","Epoch 1 #28900 -- loss: 0.025845145013881847, acc: 0.995\n","Epoch 1 #28950 -- loss: 0.012922464815928833, acc: 0.99625\n","Epoch 1 #29000 -- loss: 0.03100710258819163, acc: 0.98875\n","Epoch 1 #29050 -- loss: 0.020701011416385882, acc: 0.9925\n","Epoch 1 #29100 -- loss: 0.03207386952533852, acc: 0.98875\n","Epoch 1 #29150 -- loss: 0.019323940367321484, acc: 0.99375\n","Epoch 1 #29200 -- loss: 0.021834964162844698, acc: 0.9925\n","Epoch 1 #29250 -- loss: 0.006709951948432717, acc: 0.9975\n","Epoch 1 #29300 -- loss: 0.019907821154629347, acc: 0.99375\n","Epoch 1 #29350 -- loss: 0.03542145687213633, acc: 0.98875\n","Epoch 1 #29400 -- loss: 0.04607985788024962, acc: 0.9875\n","Epoch 1 #29450 -- loss: 0.022719748322851955, acc: 0.99\n","Epoch 1 #29500 -- loss: 0.010756028286123183, acc: 0.99625\n","Epoch 1 #29550 -- loss: 0.02900372365867952, acc: 0.9875\n","Epoch 1 #29600 -- loss: 0.012426494068931789, acc: 0.99625\n","Epoch 1 #29650 -- loss: 0.02414487817353802, acc: 0.99125\n","Epoch 1 #29700 -- loss: 0.023520124027272687, acc: 0.99125\n","Epoch 1 #29750 -- loss: 0.02560733919381164, acc: 0.9925\n","Epoch 1 #29800 -- loss: 0.01818999166309368, acc: 0.99125\n","Epoch 1 #29850 -- loss: 0.028199505710508676, acc: 0.99125\n","Epoch 1 #29900 -- loss: 0.030235479473194573, acc: 0.98875\n","Epoch 1 #29950 -- loss: 0.03547657709743362, acc: 0.9875\n","Epoch 1 #30000 -- loss: 0.026596875675022603, acc: 0.9875\n","Epoch 1 #30050 -- loss: 0.03311118808283936, acc: 0.98875\n","Epoch 1 #30100 -- loss: 0.028670797810773366, acc: 0.99\n","Epoch 1 #30150 -- loss: 0.02141770044225268, acc: 0.9925\n","Epoch 1 #30200 -- loss: 0.0360155408969149, acc: 0.9925\n","Epoch 1 #30250 -- loss: 0.03965843684505671, acc: 0.98875\n","Epoch 1 #30300 -- loss: 0.033206161650596186, acc: 0.99\n","Epoch 1 #30350 -- loss: 0.021703133585397154, acc: 0.99\n","Epoch 1 #30400 -- loss: 0.022879827588621993, acc: 0.9925\n","Epoch 1 #30450 -- loss: 0.015537017791648395, acc: 0.99625\n","Epoch 1 #30500 -- loss: 0.030155149700294714, acc: 0.99125\n","Epoch 1 #30550 -- loss: 0.023043962004594506, acc: 0.99125\n","Epoch 1 #30600 -- loss: 0.018272722486581187, acc: 0.9925\n","Epoch 1 #30650 -- loss: 0.01282977805036353, acc: 0.99375\n","Epoch 1 #30700 -- loss: 0.014013639809272718, acc: 0.99375\n","Epoch 1 #30750 -- loss: 0.0333616476599127, acc: 0.99\n","Epoch 1 #30800 -- loss: 0.022785165248496924, acc: 0.99375\n","Epoch 1 #30850 -- loss: 0.02692059763488942, acc: 0.98625\n","Epoch 1 #30900 -- loss: 0.02515930163732264, acc: 0.98875\n","Epoch 1 #30950 -- loss: 0.029734564461396076, acc: 0.9875\n","Epoch 1 #31000 -- loss: 0.00909434986213455, acc: 0.99625\n","Epoch 1 #31050 -- loss: 0.037785568271065134, acc: 0.9875\n","Epoch 1 #31100 -- loss: 0.014905413422384299, acc: 0.995\n","Epoch 1 #31150 -- loss: 0.030703299067972693, acc: 0.98625\n","Epoch 1 #31200 -- loss: 0.04934073656593682, acc: 0.9775\n","Epoch 1 #31250 -- loss: 0.0291848603595281, acc: 0.99125\n","Epoch 1 #31300 -- loss: 0.04886326037812978, acc: 0.985\n","Epoch 1 #31350 -- loss: 0.03613517269375734, acc: 0.98625\n","Epoch 1 #31400 -- loss: 0.03496406781487167, acc: 0.98875\n","Epoch 1 #31450 -- loss: 0.020075337239541115, acc: 0.99125\n","Epoch 1 #31500 -- loss: 0.02611280294629978, acc: 0.99\n","Epoch 1 #31550 -- loss: 0.02438934392819647, acc: 0.99\n","Epoch 1 #31600 -- loss: 0.016754882494860793, acc: 0.99375\n","Epoch 1 #31650 -- loss: 0.030812438509310595, acc: 0.98875\n","Epoch 1 #31700 -- loss: 0.03344397053762805, acc: 0.99\n","Epoch 1 #31750 -- loss: 0.013915758590737824, acc: 0.99375\n","Epoch 1 #31800 -- loss: 0.02336228674976155, acc: 0.9925\n","Epoch 1 #31850 -- loss: 0.025092742553097194, acc: 0.9925\n","Epoch 1 #31900 -- loss: 0.0210729706089478, acc: 0.9925\n","Epoch 1 #31950 -- loss: 0.04862730900815222, acc: 0.9825\n","Epoch 1 #32000 -- loss: 0.019630073746666313, acc: 0.99125\n","Epoch 1 #32050 -- loss: 0.008773656084522373, acc: 0.99625\n","Epoch 1 #32100 -- loss: 0.029435902709665243, acc: 0.99125\n","Epoch 1 #32150 -- loss: 0.02317139055521693, acc: 0.99125\n","Epoch 1 #32200 -- loss: 0.023121302309446038, acc: 0.9925\n","Epoch 1 #32250 -- loss: 0.017830627245712095, acc: 0.9925\n","Epoch 1 #32300 -- loss: 0.019144403099198827, acc: 0.99\n","Epoch 1 #32350 -- loss: 0.02303045660548378, acc: 0.99125\n","Epoch 1 #32400 -- loss: 0.05091077434131876, acc: 0.98375\n","Epoch 1 #32450 -- loss: 0.0366215441969689, acc: 0.9875\n","Epoch 1 #32500 -- loss: 0.020546018526656554, acc: 0.99\n","Epoch 1 #32550 -- loss: 0.03557607972878032, acc: 0.9875\n","Epoch 1 #32600 -- loss: 0.027962409480824135, acc: 0.98875\n","Epoch 1 #32650 -- loss: 0.0163738797721453, acc: 0.995\n","Epoch 1 #32700 -- loss: 0.029946176438243127, acc: 0.9925\n","Epoch 1 #32750 -- loss: 0.02753857419535052, acc: 0.9925\n","Epoch 1 #32800 -- loss: 0.021698863506899216, acc: 0.98875\n","Epoch 1 #32850 -- loss: 0.009998924922838342, acc: 0.99625\n","Epoch 1 #32900 -- loss: 0.015609015552327037, acc: 0.9925\n","Epoch 1 #32950 -- loss: 0.01876546356041217, acc: 0.9925\n","Epoch 1 #33000 -- loss: 0.013580796688911505, acc: 0.9925\n","\n","Epoch 1 loss: 0.05524925967288569, acc: 0.9788295454545455\n"]}],"source":["f = 3\n","e = 1\n","\n","print(f\"------------------------------ {f} fold {e} epoch------------------------------\")\n","\n","model.train()\n","epoch_perform, batch_perform = np.zeros(2), np.zeros(2)\n","print()\t\n","progress_bar = tqdm(enumerate(trainloader), total=len(trainloader), leave=True, position=0,)\n","for j, v in progress_bar:\n","  input_ids, attention_mask, labels = v['input_ids'].to(device), v['attention_mask'].to(device), v['labels'].to(device)\n","  \n","  optimizer.zero_grad()\n","  \n","  outputs = model(input_ids, attention_mask) ## label을 안 넣어서 logits값만 출력\n","  output = outputs.logits # The outputs object is a SequenceClassifierOutput\n","  loss = criterion(output, labels)\n","  loss.backward()\n","  optimizer.step()\n","  scheduler.step()\n","  for learning_rate in scheduler.get_lr():\n","    wandb.log({\"learning_rate\": learning_rate})\n","\n","  predict = output.argmax(dim=-1)\n","  predict = predict.detach().cpu().numpy()\n","  labels = labels.detach().cpu().numpy()\n","  acc = accuracy_score(labels, predict)\n","\n","  batch_perform += np.array([loss.item(), acc])\n","  epoch_perform += np.array([loss.item(), acc])\n","\n","  if (j + 1) % 50 == 0:\n","    print(\n","        f\"Epoch {e} #{j + 1} -- loss: {batch_perform[0] / 50}, acc: {batch_perform[1] / 50}\"\n","    )\n","    batch_perform = np.zeros(2)\n","print()\n","print(\n","    f\"Epoch {e} loss: {epoch_perform[0] / total_batch_}, acc: {epoch_perform[1] / total_batch_}\"\n","    )\n","wandb.log({\n","    \"epoch\": e,\n","    \"Train epoch Loss\": epoch_perform[0] / total_batch_,\n","    \"Train epoch Acc\": epoch_perform[1] / total_batch_}\n","    )\n","torch.save(model.state_dict(), f\"./models/{args.model_name}/{f}-fold/train.pt\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2265959,"status":"ok","timestamp":1654634361288,"user":{"displayName":"Lainie Kang","userId":"17932680864583243195"},"user_tz":-540},"id":"3TUuxNumgD9T","outputId":"d0012247-a9e4-4754-e7ff-8d0e30d86531"},"outputs":[{"name":"stdout","output_type":"stream","text":["New best model for val accuracy : 0.9934772727272727! saving the best model..\n","=============== Fold3 Wrong DataFrame Saved ===============\n","\n",">>>> Validation loss: 0.019584552417655658, Acc: 0.9934772727272727\n","\n","==================================================\n","3fold best_val_acc_list : [0.9934772727272727]\n","=============== 3fold Final Score(ACC) : 0.9934772727272727 ===============\n"]}],"source":["f = 3\n","e = 1\n","best_val_loss, best_val_acc, = np.inf, 0\n","###### Validation\n","load_path = f'./models/{args.model_name}/{f}-fold/train.pt'\n","model.load_state_dict(torch.load(load_path,map_location=device))\n","model.to(device)\n","model.eval()\n","valid_perform = np.zeros(2)\n","\n","all_valid_predict_lst = []\n","all_valid_labels_lst = []\n","\n","# 틀린 데이터들을 wandb 기록하기 위함.\n","wrong_sample_dict = defaultdict(list)\n","\n","with torch.no_grad():\n","    for v in validloader:\n","      input_ids, attention_mask, valid_labels = v[\"input_ids\"].to(device), v[\"attention_mask\"].to(device), v[\"labels\"].to(device)\n","      \n","      valid_outputs = model(input_ids, attention_mask)\n","      valid_output = valid_outputs.logits\n","      valid_loss = criterion(valid_output, valid_labels)\n","      \n","      valid_predict = valid_output.argmax(dim=-1)\n","      valid_predict = valid_predict.detach().cpu().numpy()\n","      valid_labels = valid_labels.detach().cpu().numpy()\n","\n","      ###########################\n","      # valid eval 결과, 틀린 데이터들은 wandb에 Logging\n","      if args.logging_wrong_samples:\n","        wrong_sample_index = np.where(valid_labels!=valid_predict)[0]\n","        if len(wrong_sample_index)>0:\n","          wrong_sample_text, wrong_sample_label, wrong_sample_pred, entailment_prob, contradiction_prob = wrong_batch_for_wandb(tokenizer, wrong_sample_index, input_ids, valid_labels, valid_predict, valid_output)\n","\n","          wrong_sample_dict['입력 코드 Pair'] += wrong_sample_text\n","          wrong_sample_dict['실제값'] += wrong_sample_label\n","          wrong_sample_dict['예측값'] += wrong_sample_pred\n","          wrong_sample_dict['diff_logit'] += entailment_prob\n","          wrong_sample_dict['same_logit'] += contradiction_prob\n","      ###########################\n","\n","      valid_acc = accuracy_score(valid_labels, valid_predict)\n","      valid_perform += np.array([valid_loss.item(), valid_acc])\n","\n","      all_valid_predict_lst += list(valid_predict)\n","      all_valid_labels_lst += list(valid_labels)\n","  \n","###### Model save\n","val_total_loss = valid_perform[0] / valid_batch_\n","val_total_acc = valid_perform[1] / valid_batch_\n","best_val_loss = min(best_val_loss, val_total_loss)\n","\n","\n","if val_total_acc > best_val_acc:\n","    print(f\"New best model for val accuracy : {val_total_acc}! saving the best model..\")\n","    torch.save(model.state_dict(), f\"./models/{args.model_name}/{f}-fold/best.pt\")\n","\n","    # 참고 : Model 추가 재학습을 위한 모델을 저장하는 코드\n","    # https://tutorials.pytorch.kr/beginner/saving_loading_models.html#checkpoint\n","\n","    best_val_acc = val_total_acc\n","\n","    ### Confusion Matrix\n","    class_names = ['diff','same'] # (0,1,2)\n","    # https://wandb.ai/wandb/plots/reports/Confusion-Matrix--VmlldzozMDg1NTM\n","    wandb.log({f\"{e}_epoch_conf_mat\" : wandb.plot.confusion_matrix(probs=None,\n","                                                                      y_true=all_valid_labels_lst, preds=all_valid_predict_lst,\n","                                                                      class_names=class_names)})\n","      \n","    if args.logging_wrong_samples and val_total_acc > 0.91:\n","      ########### Logging Wrong Samples ##########\n","      # Save Wrong DataFrame\n","      wrong_sample_df = pd.DataFrame(wrong_sample_dict)\n","      wrong_sample_df.to_csv(f\"./models/{args.model_name}/{f}-fold/wrong_df.csv\",index=False)\n","      print('='*15,f'Fold{f} Wrong DataFrame Saved','='*15)\n","      # Loggin Wandb\n","      text_table = wandb.Table(data = wrong_sample_df)\n","      run.log({f\"{f}_fold_wrong_samples\" : text_table})\n","      ###########################\n","    \n","print()\n","print(\n","    f\">>>> Validation loss: {val_total_loss}, Acc: {val_total_acc}\"\n","    )\n","print()\n","wandb.log({\n","    \"epoch\": e,\n","    \"Last_Valid Loss\": val_total_loss,\n","    \"Last_Valid Acc\": val_total_acc,\n","    })\n","best_val_acc_list.append(best_val_acc)\n","print('='*50)\n","print(f\"{f}fold best_val_acc_list : {best_val_acc_list}\")\n","print('='*15, f'{f}fold Final Score(ACC) : {np.mean(best_val_acc_list)}', '='*15)\n","wandb.log({\n","f\"Total Mean ACC ({f}fold)\": np.mean(best_val_acc_list)}\n",")"]},{"cell_type":"markdown","metadata":{"id":"FEwM3PFigGUm"},"source":["# 4 fold"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":514},"executionInfo":{"elapsed":13080,"status":"ok","timestamp":1654634374343,"user":{"displayName":"Lainie Kang","userId":"17932680864583243195"},"user_tz":-540},"id":"G0PLl54qgGUn","outputId":"053d9caa-027b-49e5-8925-d8304144a9eb"},"outputs":[{"name":"stdout","output_type":"stream","text":["---------------------------------- 4 fold----------------------------------\n"]},{"data":{"text/html":["Finishing last run (ID:8mbqvyn8) before initializing another..."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"59659f33d4ad49bbabbf073b550879bf","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='1.349 MB of 2.696 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.500360…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Last_Valid Acc</td><td>▁</td></tr><tr><td>Last_Valid Loss</td><td>▁</td></tr><tr><td>Total Mean ACC (3fold)</td><td>▁</td></tr><tr><td>Train epoch Acc</td><td>▁</td></tr><tr><td>Train epoch Loss</td><td>▁</td></tr><tr><td>epoch</td><td>▁▁</td></tr><tr><td>learning_rate</td><td>████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Last_Valid Acc</td><td>0.99348</td></tr><tr><td>Last_Valid Loss</td><td>0.01958</td></tr><tr><td>Total Mean ACC (3fold)</td><td>0.99348</td></tr><tr><td>Train epoch Acc</td><td>0.97883</td></tr><tr><td>Train epoch Loss</td><td>0.05525</td></tr><tr><td>epoch</td><td>1</td></tr><tr><td>learning_rate</td><td>1e-05</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Synced <strong style=\"color:#cdcd00\">happy-dawn-11</strong>: <a href=\"https://wandb.ai/nahyeonkang/graphcodebert_Bs16_OptAdamW_ScduCosine_Sm0.0/runs/8mbqvyn8\" target=\"_blank\">https://wandb.ai/nahyeonkang/graphcodebert_Bs16_OptAdamW_ScduCosine_Sm0.0/runs/8mbqvyn8</a><br/>Synced 5 W&B file(s), 2 media file(s), 2 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20220607_121507-8mbqvyn8/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Successfully finished last run (ID:8mbqvyn8). Initializing new run:<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.12.17"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/drive/MyDrive/DACON/wandb/run-20220607_203921-18ra6gwk</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href=\"https://wandb.ai/nahyeonkang/graphcodebert_Bs16_OptAdamW_ScduCosine_Sm0.0/runs/18ra6gwk\" target=\"_blank\">major-yogurt-12</a></strong> to <a href=\"https://wandb.ai/nahyeonkang/graphcodebert_Bs16_OptAdamW_ScduCosine_Sm0.0\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["f = 4\n","\n","print(f\"---------------------------------- {f} fold----------------------------------\")\n","\n","run = wandb.init(project=args.project_name)\n","wandb.run.name = f'{args.model_name}/{f}-fold'\n","wandb.config.update(args)\n","os.makedirs(f'./models/{args.model_name}/{f}-fold', exist_ok=True)\n","\n","total_size = len(dataset)\n","total_ids = list(range(total_size))\n","del_ids = list(range((f-1)*gap, f*gap))\n","training_ids = set(total_ids) - set(del_ids)\n","\n","training_dset = dataset.select(list(training_ids))\n","eval_dset = dataset.select(del_ids)\n","\n","collator = DataCollatorWithPadding(tokenizer=tokenizer)\n","\n","trainloader = DataLoader(training_dset,\n","                          batch_size=16,\n","                          shuffle=True,\n","                          collate_fn = collator\n","                          )\n","\n","validloader = DataLoader(eval_dset,\n","                          batch_size=16,\n","                          shuffle=False,\n","                          collate_fn = collator\n","                          )\n","\n","total_batch_ = len(trainloader)\n","valid_batch_ = len(validloader)\n","\n","optimizer = get_optimizer(model, args)\n","scheduler = get_scheduler(optimizer, args, total_batch_)"]},{"cell_type":"markdown","metadata":{"id":"Tr8TDbdfgGUo"},"source":["## 1 epoch"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":27996947,"status":"ok","timestamp":1654662371262,"user":{"displayName":"Lainie Kang","userId":"17932680864583243195"},"user_tz":-540},"id":"qGFiMlLlgGUo","outputId":"e87c993f-b373-4046-993c-b841d5654e2f"},"outputs":[{"name":"stdout","output_type":"stream","text":["------------------------------ 4 fold 1 epoch------------------------------\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ecf44c6c53ba4d42bd710549a5c79432","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/33000 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 1 #50 -- loss: 0.02072806987504009, acc: 0.99375\n","Epoch 1 #100 -- loss: 0.00713290082901949, acc: 0.995\n","Epoch 1 #150 -- loss: 0.012821453771030064, acc: 0.99875\n","Epoch 1 #200 -- loss: 0.013446899642294738, acc: 0.99625\n","Epoch 1 #250 -- loss: 0.028035393965401455, acc: 0.99125\n","Epoch 1 #300 -- loss: 0.02047721901733894, acc: 0.99\n","Epoch 1 #350 -- loss: 0.021598954788350964, acc: 0.9975\n","Epoch 1 #400 -- loss: 0.02425752628099872, acc: 0.9925\n","Epoch 1 #450 -- loss: 0.007799174248211784, acc: 0.99625\n","Epoch 1 #500 -- loss: 0.011446078079170547, acc: 0.9975\n","Epoch 1 #550 -- loss: 0.03521750810556114, acc: 0.98875\n","Epoch 1 #600 -- loss: 0.011926271446282045, acc: 0.99625\n","Epoch 1 #650 -- loss: 0.02152895774808712, acc: 0.99625\n","Epoch 1 #700 -- loss: 0.036120347534306346, acc: 0.99\n","Epoch 1 #750 -- loss: 0.008400429477915168, acc: 0.99875\n","Epoch 1 #800 -- loss: 0.026048845781479032, acc: 0.99375\n","Epoch 1 #850 -- loss: 0.02314829966693651, acc: 0.99\n","Epoch 1 #900 -- loss: 0.02232085084397113, acc: 0.9925\n","Epoch 1 #950 -- loss: 0.03300743205472827, acc: 0.99\n","Epoch 1 #1000 -- loss: 0.017984105372452177, acc: 0.995\n","Epoch 1 #1050 -- loss: 0.03411048272973858, acc: 0.98875\n","Epoch 1 #1100 -- loss: 0.021840338628098834, acc: 0.995\n","Epoch 1 #1150 -- loss: 0.029722251616767607, acc: 0.9925\n","Epoch 1 #1200 -- loss: 0.02603398542327341, acc: 0.99\n","Epoch 1 #1250 -- loss: 0.028299202371854335, acc: 0.99125\n","Epoch 1 #1300 -- loss: 0.023284607966197655, acc: 0.98875\n","Epoch 1 #1350 -- loss: 0.040215245379367846, acc: 0.98625\n","Epoch 1 #1400 -- loss: 0.03705908255011309, acc: 0.98875\n","Epoch 1 #1450 -- loss: 0.03692152891977457, acc: 0.99\n","Epoch 1 #1500 -- loss: 0.03468923368724063, acc: 0.9875\n","Epoch 1 #1550 -- loss: 0.023458593045943416, acc: 0.9925\n","Epoch 1 #1600 -- loss: 0.020942334566498175, acc: 0.99125\n","Epoch 1 #1650 -- loss: 0.02767390225228155, acc: 0.99\n","Epoch 1 #1700 -- loss: 0.020950771558855195, acc: 0.99375\n","Epoch 1 #1750 -- loss: 0.02077049011917552, acc: 0.99375\n","Epoch 1 #1800 -- loss: 0.009745003167772666, acc: 0.9975\n","Epoch 1 #1850 -- loss: 0.02260753541777376, acc: 0.9925\n","Epoch 1 #1900 -- loss: 0.033968183297256475, acc: 0.98625\n","Epoch 1 #1950 -- loss: 0.023335741375340148, acc: 0.99\n","Epoch 1 #2000 -- loss: 0.008176787657430396, acc: 0.9975\n","Epoch 1 #2050 -- loss: 0.0258423354869592, acc: 0.9875\n","Epoch 1 #2100 -- loss: 0.030294280033558607, acc: 0.99\n","Epoch 1 #2150 -- loss: 0.027452419710461983, acc: 0.9875\n","Epoch 1 #2200 -- loss: 0.027864080206200015, acc: 0.99375\n","Epoch 1 #2250 -- loss: 0.03523048518167343, acc: 0.98875\n","Epoch 1 #2300 -- loss: 0.015107768716698047, acc: 0.995\n","Epoch 1 #2350 -- loss: 0.017235774779110216, acc: 0.995\n","Epoch 1 #2400 -- loss: 0.030437021519755945, acc: 0.99\n","Epoch 1 #2450 -- loss: 0.022699919592705554, acc: 0.9925\n","Epoch 1 #2500 -- loss: 0.014276461250847205, acc: 0.995\n","Epoch 1 #2550 -- loss: 0.014206067188933958, acc: 0.99375\n","Epoch 1 #2600 -- loss: 0.03847274050873239, acc: 0.9875\n","Epoch 1 #2650 -- loss: 0.027883335314691067, acc: 0.99125\n","Epoch 1 #2700 -- loss: 0.030219241278246045, acc: 0.98875\n","Epoch 1 #2750 -- loss: 0.0164378386863973, acc: 0.9975\n","Epoch 1 #2800 -- loss: 0.03124587021913612, acc: 0.98875\n","Epoch 1 #2850 -- loss: 0.02399194129742682, acc: 0.99125\n","Epoch 1 #2900 -- loss: 0.0231591221850249, acc: 0.99375\n","Epoch 1 #2950 -- loss: 0.01672149437945336, acc: 0.99125\n","Epoch 1 #3000 -- loss: 0.023190533935994607, acc: 0.99125\n","Epoch 1 #3050 -- loss: 0.019061831317812902, acc: 0.99375\n","Epoch 1 #3100 -- loss: 0.030214937098207884, acc: 0.99125\n","Epoch 1 #3150 -- loss: 0.026743854727828874, acc: 0.99375\n","Epoch 1 #3200 -- loss: 0.02655581338563934, acc: 0.99375\n","Epoch 1 #3250 -- loss: 0.015692269210121595, acc: 0.99625\n","Epoch 1 #3300 -- loss: 0.02674167037504958, acc: 0.99375\n","Epoch 1 #3350 -- loss: 0.020800939562614074, acc: 0.99125\n","Epoch 1 #3400 -- loss: 0.018424583835003432, acc: 0.995\n","Epoch 1 #3450 -- loss: 0.01884135104046436, acc: 0.99125\n","Epoch 1 #3500 -- loss: 0.02972796116635436, acc: 0.9875\n","Epoch 1 #3550 -- loss: 0.02820952232606942, acc: 0.9925\n","Epoch 1 #3600 -- loss: 0.019347966939676553, acc: 0.995\n","Epoch 1 #3650 -- loss: 0.008599993888929021, acc: 0.99875\n","Epoch 1 #3700 -- loss: 0.03938521036179736, acc: 0.98875\n","Epoch 1 #3750 -- loss: 0.021400231202133, acc: 0.9925\n","Epoch 1 #3800 -- loss: 0.02810980011650827, acc: 0.99375\n","Epoch 1 #3850 -- loss: 0.023014652770361865, acc: 0.99\n","Epoch 1 #3900 -- loss: 0.009451773905311711, acc: 0.995\n","Epoch 1 #3950 -- loss: 0.03356396485178266, acc: 0.99\n","Epoch 1 #4000 -- loss: 0.018673257967457176, acc: 0.99\n","Epoch 1 #4050 -- loss: 0.034742277641198596, acc: 0.99\n","Epoch 1 #4100 -- loss: 0.023613246625754983, acc: 0.99125\n","Epoch 1 #4150 -- loss: 0.019756415777956136, acc: 0.99375\n","Epoch 1 #4200 -- loss: 0.025338157779478933, acc: 0.99125\n","Epoch 1 #4250 -- loss: 0.022101781117380596, acc: 0.995\n","Epoch 1 #4300 -- loss: 0.025900100521394052, acc: 0.99\n","Epoch 1 #4350 -- loss: 0.018206524185370655, acc: 0.99375\n","Epoch 1 #4400 -- loss: 0.029386417656060076, acc: 0.9925\n","Epoch 1 #4450 -- loss: 0.019341410090128193, acc: 0.9925\n","Epoch 1 #4500 -- loss: 0.033891696953505746, acc: 0.99\n","Epoch 1 #4550 -- loss: 0.015754169295541944, acc: 0.99375\n","Epoch 1 #4600 -- loss: 0.027303009174356702, acc: 0.98875\n","Epoch 1 #4650 -- loss: 0.019348045927472413, acc: 0.995\n","Epoch 1 #4700 -- loss: 0.029408440652186982, acc: 0.9925\n","Epoch 1 #4750 -- loss: 0.013575805933214724, acc: 0.995\n","Epoch 1 #4800 -- loss: 0.032585962771554476, acc: 0.99\n","Epoch 1 #4850 -- loss: 0.03104555685946252, acc: 0.98625\n","Epoch 1 #4900 -- loss: 0.037000070413341746, acc: 0.9875\n","Epoch 1 #4950 -- loss: 0.030368703148560598, acc: 0.99\n","Epoch 1 #5000 -- loss: 0.0171522888407344, acc: 0.995\n","Epoch 1 #5050 -- loss: 0.017057516976637998, acc: 0.99375\n","Epoch 1 #5100 -- loss: 0.01959235855290899, acc: 0.9925\n","Epoch 1 #5150 -- loss: 0.021169481652614196, acc: 0.995\n","Epoch 1 #5200 -- loss: 0.02649020204669796, acc: 0.99125\n","Epoch 1 #5250 -- loss: 0.020273880270542576, acc: 0.99375\n","Epoch 1 #5300 -- loss: 0.040067638052860274, acc: 0.9875\n","Epoch 1 #5350 -- loss: 0.03092277085292153, acc: 0.98625\n","Epoch 1 #5400 -- loss: 0.014781118238461203, acc: 0.99125\n","Epoch 1 #5450 -- loss: 0.02551453716645483, acc: 0.98875\n","Epoch 1 #5500 -- loss: 0.01869154655491002, acc: 0.995\n","Epoch 1 #5550 -- loss: 0.018796721746621187, acc: 0.99375\n","Epoch 1 #5600 -- loss: 0.01766512026777491, acc: 0.9925\n","Epoch 1 #5650 -- loss: 0.02158659501292277, acc: 0.995\n","Epoch 1 #5700 -- loss: 0.011712572512042243, acc: 0.99625\n","Epoch 1 #5750 -- loss: 0.009436220369825605, acc: 0.99875\n","Epoch 1 #5800 -- loss: 0.016530146115837852, acc: 0.99625\n","Epoch 1 #5850 -- loss: 0.018825659697031368, acc: 0.99375\n","Epoch 1 #5900 -- loss: 0.035134259840997405, acc: 0.99125\n","Epoch 1 #5950 -- loss: 0.007484064013988245, acc: 0.9975\n","Epoch 1 #6000 -- loss: 0.017496316583710723, acc: 0.99375\n","Epoch 1 #6050 -- loss: 0.01857273044792237, acc: 0.99625\n","Epoch 1 #6100 -- loss: 0.020213399369822582, acc: 0.99375\n","Epoch 1 #6150 -- loss: 0.019176222493406385, acc: 0.9925\n","Epoch 1 #6200 -- loss: 0.025637028212950098, acc: 0.9925\n","Epoch 1 #6250 -- loss: 0.02223690796556184, acc: 0.98875\n","Epoch 1 #6300 -- loss: 0.016158928728837053, acc: 0.99125\n","Epoch 1 #6350 -- loss: 0.02569549079227727, acc: 0.9925\n","Epoch 1 #6400 -- loss: 0.0267441626751679, acc: 0.99\n","Epoch 1 #6450 -- loss: 0.021736771552241407, acc: 0.99375\n","Epoch 1 #6500 -- loss: 0.01975328304688446, acc: 0.9925\n","Epoch 1 #6550 -- loss: 0.016156175745418295, acc: 0.9975\n","Epoch 1 #6600 -- loss: 0.02593547325464897, acc: 0.98875\n","Epoch 1 #6650 -- loss: 0.006998774786770809, acc: 0.99875\n","Epoch 1 #6700 -- loss: 0.012847998395882314, acc: 0.99375\n","Epoch 1 #6750 -- loss: 0.03259861082944553, acc: 0.99375\n","Epoch 1 #6800 -- loss: 0.018289618881535716, acc: 0.995\n","Epoch 1 #6850 -- loss: 0.020623009640403325, acc: 0.995\n","Epoch 1 #6900 -- loss: 0.014480648266908248, acc: 0.99375\n","Epoch 1 #6950 -- loss: 0.027282208303222432, acc: 0.99125\n","Epoch 1 #7000 -- loss: 0.013648667851812206, acc: 0.995\n","Epoch 1 #7050 -- loss: 0.024405243772780524, acc: 0.99125\n","Epoch 1 #7100 -- loss: 0.019179969983524642, acc: 0.99375\n","Epoch 1 #7150 -- loss: 0.02242422229843214, acc: 0.99125\n","Epoch 1 #7200 -- loss: 0.010501874729379778, acc: 0.99625\n","Epoch 1 #7250 -- loss: 0.025809616159967845, acc: 0.9925\n","Epoch 1 #7300 -- loss: 0.033847407642169855, acc: 0.99125\n","Epoch 1 #7350 -- loss: 0.020302026392018887, acc: 0.99\n","Epoch 1 #7400 -- loss: 0.03649011853616685, acc: 0.9925\n","Epoch 1 #7450 -- loss: 0.016729285454493946, acc: 0.995\n","Epoch 1 #7500 -- loss: 0.01639202105172444, acc: 0.9925\n","Epoch 1 #7550 -- loss: 0.024740313548245466, acc: 0.99\n","Epoch 1 #7600 -- loss: 0.04047267050424125, acc: 0.98625\n","Epoch 1 #7650 -- loss: 0.01598113189684227, acc: 0.99375\n","Epoch 1 #7700 -- loss: 0.025015480490401386, acc: 0.99125\n","Epoch 1 #7750 -- loss: 0.021414325475925578, acc: 0.9925\n","Epoch 1 #7800 -- loss: 0.03141004711185815, acc: 0.9925\n","Epoch 1 #7850 -- loss: 0.02033261036791373, acc: 0.99375\n","Epoch 1 #7900 -- loss: 0.013617090245825239, acc: 0.9925\n","Epoch 1 #7950 -- loss: 0.015606960718287155, acc: 0.995\n","Epoch 1 #8000 -- loss: 0.030052142361528242, acc: 0.99375\n","Epoch 1 #8050 -- loss: 0.014950074833468534, acc: 0.99375\n","Epoch 1 #8100 -- loss: 0.04416431186371483, acc: 0.985\n","Epoch 1 #8150 -- loss: 0.027679889786522836, acc: 0.99\n","Epoch 1 #8200 -- loss: 0.02011660682677757, acc: 0.99375\n","Epoch 1 #8250 -- loss: 0.017305833202553914, acc: 0.99375\n","Epoch 1 #8300 -- loss: 0.020878015919297468, acc: 0.99375\n","Epoch 1 #8350 -- loss: 0.01090924514370272, acc: 0.99875\n","Epoch 1 #8400 -- loss: 0.014649301698082127, acc: 0.99375\n","Epoch 1 #8450 -- loss: 0.0281935148924822, acc: 0.99125\n","Epoch 1 #8500 -- loss: 0.013860646678076592, acc: 0.995\n","Epoch 1 #8550 -- loss: 0.027023278839769772, acc: 0.98875\n","Epoch 1 #8600 -- loss: 0.013001815403695218, acc: 0.99625\n","Epoch 1 #8650 -- loss: 0.02167456458322704, acc: 0.99375\n","Epoch 1 #8700 -- loss: 0.03026906391198281, acc: 0.99\n","Epoch 1 #8750 -- loss: 0.01836829563311767, acc: 0.995\n","Epoch 1 #8800 -- loss: 0.026958111911080777, acc: 0.99125\n","Epoch 1 #8850 -- loss: 0.021226779529242776, acc: 0.9925\n","Epoch 1 #8900 -- loss: 0.01949653338815551, acc: 0.99375\n","Epoch 1 #8950 -- loss: 0.026840344290831125, acc: 0.99\n","Epoch 1 #9000 -- loss: 0.03513103348639561, acc: 0.98375\n","Epoch 1 #9050 -- loss: 0.030867695778142662, acc: 0.9875\n","Epoch 1 #9100 -- loss: 0.02578951207862701, acc: 0.99625\n","Epoch 1 #9150 -- loss: 0.006652653794153593, acc: 0.99875\n","Epoch 1 #9200 -- loss: 0.04064314205606934, acc: 0.99\n","Epoch 1 #9250 -- loss: 0.017607361012487673, acc: 0.99375\n","Epoch 1 #9300 -- loss: 0.006265239407657646, acc: 1.0\n","Epoch 1 #9350 -- loss: 0.03136039493852877, acc: 0.99125\n","Epoch 1 #9400 -- loss: 0.03986699631554075, acc: 0.98625\n","Epoch 1 #9450 -- loss: 0.0356313095142832, acc: 0.98625\n","Epoch 1 #9500 -- loss: 0.016287574182497336, acc: 0.995\n","Epoch 1 #9550 -- loss: 0.021163890210882528, acc: 0.99625\n","Epoch 1 #9600 -- loss: 0.025704938197450247, acc: 0.99125\n","Epoch 1 #9650 -- loss: 0.025634831915667747, acc: 0.98875\n","Epoch 1 #9700 -- loss: 0.017808536728844047, acc: 0.99625\n","Epoch 1 #9750 -- loss: 0.021055832000565714, acc: 0.995\n","Epoch 1 #9800 -- loss: 0.016967095393338242, acc: 0.995\n","Epoch 1 #9850 -- loss: 0.022060513541218824, acc: 0.99\n","Epoch 1 #9900 -- loss: 0.023759262134553864, acc: 0.99375\n","Epoch 1 #9950 -- loss: 0.017897837139316836, acc: 0.9925\n","Epoch 1 #10000 -- loss: 0.02220866864576237, acc: 0.9925\n","Epoch 1 #10050 -- loss: 0.021178590016788804, acc: 0.9925\n","Epoch 1 #10100 -- loss: 0.028795016625372226, acc: 0.99125\n","Epoch 1 #10150 -- loss: 0.034896231269813144, acc: 0.99\n","Epoch 1 #10200 -- loss: 0.020400181366712785, acc: 0.99125\n","Epoch 1 #10250 -- loss: 0.03651071337342728, acc: 0.99125\n","Epoch 1 #10300 -- loss: 0.036438212971261236, acc: 0.985\n","Epoch 1 #10350 -- loss: 0.01688086396170547, acc: 0.9975\n","Epoch 1 #10400 -- loss: 0.009594681092130486, acc: 0.995\n","Epoch 1 #10450 -- loss: 0.015255512760777492, acc: 0.99375\n","Epoch 1 #10500 -- loss: 0.025067253594170325, acc: 0.99\n","Epoch 1 #10550 -- loss: 0.008281937962747178, acc: 0.99625\n","Epoch 1 #10600 -- loss: 0.016446584654186153, acc: 0.99625\n","Epoch 1 #10650 -- loss: 0.014640444375108927, acc: 0.99625\n","Epoch 1 #10700 -- loss: 0.03596454456826905, acc: 0.98875\n","Epoch 1 #10750 -- loss: 0.032211936417734253, acc: 0.98875\n","Epoch 1 #10800 -- loss: 0.0249629895738326, acc: 0.9925\n","Epoch 1 #10850 -- loss: 0.015736415991559626, acc: 0.9975\n","Epoch 1 #10900 -- loss: 0.01756683360086754, acc: 0.9925\n","Epoch 1 #10950 -- loss: 0.014817267124017234, acc: 0.995\n","Epoch 1 #11000 -- loss: 0.019198261758720036, acc: 0.99\n","Epoch 1 #11050 -- loss: 0.01894011214200873, acc: 0.99375\n","Epoch 1 #11100 -- loss: 0.023803680556302425, acc: 0.99125\n","Epoch 1 #11150 -- loss: 0.023046111993608065, acc: 0.99375\n","Epoch 1 #11200 -- loss: 0.01396838083048351, acc: 0.99625\n","Epoch 1 #11250 -- loss: 0.02119145605392987, acc: 0.99375\n","Epoch 1 #11300 -- loss: 0.01805296333011938, acc: 0.99\n","Epoch 1 #11350 -- loss: 0.033818088003899904, acc: 0.98875\n","Epoch 1 #11400 -- loss: 0.02430392444686731, acc: 0.99\n","Epoch 1 #11450 -- loss: 0.021453268632030814, acc: 0.99\n","Epoch 1 #11500 -- loss: 0.017120410806383005, acc: 0.99375\n","Epoch 1 #11550 -- loss: 0.016417531273618807, acc: 0.99375\n","Epoch 1 #11600 -- loss: 0.014876609774946701, acc: 0.995\n","Epoch 1 #11650 -- loss: 0.027673969027237035, acc: 0.99\n","Epoch 1 #11700 -- loss: 0.015401270933507476, acc: 0.995\n","Epoch 1 #11750 -- loss: 0.020947450301609934, acc: 0.99\n","Epoch 1 #11800 -- loss: 0.02553939080651617, acc: 0.98625\n","Epoch 1 #11850 -- loss: 0.022175719882070552, acc: 0.995\n","Epoch 1 #11900 -- loss: 0.011119890192494495, acc: 0.99625\n","Epoch 1 #11950 -- loss: 0.010746914915071102, acc: 0.995\n","Epoch 1 #12000 -- loss: 0.023510730292327933, acc: 0.99125\n","Epoch 1 #12050 -- loss: 0.024552299057249913, acc: 0.99\n","Epoch 1 #12100 -- loss: 0.014186293868697249, acc: 0.99625\n","Epoch 1 #12150 -- loss: 0.010399044780497206, acc: 0.995\n","Epoch 1 #12200 -- loss: 0.009352882022067206, acc: 0.99625\n","Epoch 1 #12250 -- loss: 0.03617311886904645, acc: 0.99\n","Epoch 1 #12300 -- loss: 0.027711711188894695, acc: 0.9925\n","Epoch 1 #12350 -- loss: 0.007938997983001173, acc: 0.9975\n","Epoch 1 #12400 -- loss: 0.015888507347699487, acc: 0.995\n","Epoch 1 #12450 -- loss: 0.012326479265611852, acc: 0.99625\n","Epoch 1 #12500 -- loss: 0.016596253693860488, acc: 0.9925\n","Epoch 1 #12550 -- loss: 0.012845711222180398, acc: 0.995\n","Epoch 1 #12600 -- loss: 0.010517933370138052, acc: 0.99375\n","Epoch 1 #12650 -- loss: 0.015630805759428767, acc: 0.99375\n","Epoch 1 #12700 -- loss: 0.006859445879381382, acc: 0.99875\n","Epoch 1 #12750 -- loss: 0.012757156375300838, acc: 0.99625\n","Epoch 1 #12800 -- loss: 0.02701662394887535, acc: 0.99125\n","Epoch 1 #12850 -- loss: 0.01372684231493622, acc: 0.995\n","Epoch 1 #12900 -- loss: 0.017393338132533246, acc: 0.9925\n","Epoch 1 #12950 -- loss: 0.029355682493769564, acc: 0.98875\n","Epoch 1 #13000 -- loss: 0.03286167106125504, acc: 0.9925\n","Epoch 1 #13050 -- loss: 0.023393071151222102, acc: 0.99\n","Epoch 1 #13100 -- loss: 0.017925425817957148, acc: 0.99125\n","Epoch 1 #13150 -- loss: 0.024390221194480546, acc: 0.9925\n","Epoch 1 #13200 -- loss: 0.021786236562475095, acc: 0.98875\n","Epoch 1 #13250 -- loss: 0.02021187373175053, acc: 0.995\n","Epoch 1 #13300 -- loss: 0.016272110956779214, acc: 0.99375\n","Epoch 1 #13350 -- loss: 0.026303071613365318, acc: 0.9875\n","Epoch 1 #13400 -- loss: 0.02362133223039564, acc: 0.99125\n","Epoch 1 #13450 -- loss: 0.019774564119579736, acc: 0.99\n","Epoch 1 #13500 -- loss: 0.02779783689242322, acc: 0.9925\n","Epoch 1 #13550 -- loss: 0.02919018248328939, acc: 0.98875\n","Epoch 1 #13600 -- loss: 0.040247722226195035, acc: 0.985\n","Epoch 1 #13650 -- loss: 0.0147047582938103, acc: 0.995\n","Epoch 1 #13700 -- loss: 0.010739900652552023, acc: 0.99625\n","Epoch 1 #13750 -- loss: 0.009180093521717936, acc: 0.9975\n","Epoch 1 #13800 -- loss: 0.03172293965413701, acc: 0.9875\n","Epoch 1 #13850 -- loss: 0.0423051066879998, acc: 0.985\n","Epoch 1 #13900 -- loss: 0.034243227035040034, acc: 0.99\n","Epoch 1 #13950 -- loss: 0.015656502317870035, acc: 0.995\n","Epoch 1 #14000 -- loss: 0.014444063771516085, acc: 0.995\n","Epoch 1 #14050 -- loss: 0.020720082852931226, acc: 0.9925\n","Epoch 1 #14100 -- loss: 0.023800839453178922, acc: 0.98875\n","Epoch 1 #14150 -- loss: 0.02666648699057987, acc: 0.9925\n","Epoch 1 #14200 -- loss: 0.027824658359750173, acc: 0.99125\n","Epoch 1 #14250 -- loss: 0.01834522896533599, acc: 0.99375\n","Epoch 1 #14300 -- loss: 0.022097818093607204, acc: 0.9925\n","Epoch 1 #14350 -- loss: 0.032684480531315785, acc: 0.99\n","Epoch 1 #14400 -- loss: 0.013043149979203007, acc: 0.99625\n","Epoch 1 #14450 -- loss: 0.011104292389936744, acc: 0.995\n","Epoch 1 #14500 -- loss: 0.028524020982731598, acc: 0.99125\n","Epoch 1 #14550 -- loss: 0.015442192678165156, acc: 0.9975\n","Epoch 1 #14600 -- loss: 0.03771762901626061, acc: 0.98875\n","Epoch 1 #14650 -- loss: 0.02434629242052324, acc: 0.99125\n","Epoch 1 #14700 -- loss: 0.021774516744480932, acc: 0.99\n","Epoch 1 #14750 -- loss: 0.020453235847089673, acc: 0.9925\n","Epoch 1 #14800 -- loss: 0.029347713603638113, acc: 0.9875\n","Epoch 1 #14850 -- loss: 0.012301698485098314, acc: 0.99625\n","Epoch 1 #14900 -- loss: 0.015883876656735085, acc: 0.99625\n","Epoch 1 #14950 -- loss: 0.041992172953032425, acc: 0.99\n","Epoch 1 #15000 -- loss: 0.026991609978140332, acc: 0.99375\n","Epoch 1 #15050 -- loss: 0.006724997512064874, acc: 0.99875\n","Epoch 1 #15100 -- loss: 0.016183135971950834, acc: 0.9925\n","Epoch 1 #15150 -- loss: 0.025720873001846487, acc: 0.99375\n","Epoch 1 #15200 -- loss: 0.018949415170936845, acc: 0.995\n","Epoch 1 #15250 -- loss: 0.015117161560629028, acc: 0.9925\n","Epoch 1 #15300 -- loss: 0.03127121095603798, acc: 0.99\n","Epoch 1 #15350 -- loss: 0.01639567454229109, acc: 0.9925\n","Epoch 1 #15400 -- loss: 0.014517936199554242, acc: 0.9975\n","Epoch 1 #15450 -- loss: 0.008160707378119697, acc: 0.9975\n","Epoch 1 #15500 -- loss: 0.025015873472148085, acc: 0.9925\n","Epoch 1 #15550 -- loss: 0.016383998103265185, acc: 0.99125\n","Epoch 1 #15600 -- loss: 0.01903089104016544, acc: 0.9925\n","Epoch 1 #15650 -- loss: 0.04277741942729335, acc: 0.98875\n","Epoch 1 #15700 -- loss: 0.01532665958162397, acc: 0.99625\n","Epoch 1 #15750 -- loss: 0.025759277820470744, acc: 0.99125\n","Epoch 1 #15800 -- loss: 0.028016437840124128, acc: 0.9875\n","Epoch 1 #15850 -- loss: 0.0185743454110343, acc: 0.995\n","Epoch 1 #15900 -- loss: 0.02693347643769812, acc: 0.9925\n","Epoch 1 #15950 -- loss: 0.014743975634337403, acc: 0.99625\n","Epoch 1 #16000 -- loss: 0.014384354021749458, acc: 0.995\n","Epoch 1 #16050 -- loss: 0.01169664691464277, acc: 0.9975\n","Epoch 1 #16100 -- loss: 0.011502336410921998, acc: 0.9975\n","Epoch 1 #16150 -- loss: 0.022466431687935256, acc: 0.99375\n","Epoch 1 #16200 -- loss: 0.02418248738220427, acc: 0.9925\n","Epoch 1 #16250 -- loss: 0.030384560318198056, acc: 0.985\n","Epoch 1 #16300 -- loss: 0.03107542054145597, acc: 0.99\n","Epoch 1 #16350 -- loss: 0.017523299974855036, acc: 0.9925\n","Epoch 1 #16400 -- loss: 0.0156565742395469, acc: 0.99625\n","Epoch 1 #16450 -- loss: 0.020295428427052686, acc: 0.9925\n","Epoch 1 #16500 -- loss: 0.025003098644665444, acc: 0.99125\n","Epoch 1 #16550 -- loss: 0.021021696342213545, acc: 0.995\n","Epoch 1 #16600 -- loss: 0.026176983305776957, acc: 0.99375\n","Epoch 1 #16650 -- loss: 0.013032319268095307, acc: 0.99375\n","Epoch 1 #16700 -- loss: 0.017914385779877192, acc: 0.9925\n","Epoch 1 #16750 -- loss: 0.02741801339259837, acc: 0.99125\n","Epoch 1 #16800 -- loss: 0.01223987924749963, acc: 0.995\n","Epoch 1 #16850 -- loss: 0.022998749096586835, acc: 0.99125\n","Epoch 1 #16900 -- loss: 0.014752827790507581, acc: 0.99625\n","Epoch 1 #16950 -- loss: 0.03240318060066784, acc: 0.98375\n","Epoch 1 #17000 -- loss: 0.02653096109017497, acc: 0.99125\n","Epoch 1 #17050 -- loss: 0.014632515380217228, acc: 0.99625\n","Epoch 1 #17100 -- loss: 0.020764506823034025, acc: 0.995\n","Epoch 1 #17150 -- loss: 0.0101047310361173, acc: 0.9975\n","Epoch 1 #17200 -- loss: 0.015619780903798529, acc: 0.9925\n","Epoch 1 #17250 -- loss: 0.02128867488616379, acc: 0.99375\n","Epoch 1 #17300 -- loss: 0.025715869002160618, acc: 0.9925\n","Epoch 1 #17350 -- loss: 0.00951434880902525, acc: 0.9975\n","Epoch 1 #17400 -- loss: 0.015308204378234222, acc: 0.99125\n","Epoch 1 #17450 -- loss: 0.02454037397605134, acc: 0.99125\n","Epoch 1 #17500 -- loss: 0.0056968880567001175, acc: 0.99875\n","Epoch 1 #17550 -- loss: 0.028674290825729257, acc: 0.995\n","Epoch 1 #17600 -- loss: 0.02505823261628393, acc: 0.99\n","Epoch 1 #17650 -- loss: 0.008660712408891413, acc: 0.99625\n","Epoch 1 #17700 -- loss: 0.022452593971102032, acc: 0.9925\n","Epoch 1 #17750 -- loss: 0.02088751093542669, acc: 0.9925\n","Epoch 1 #17800 -- loss: 0.007593356664729072, acc: 0.99875\n","Epoch 1 #17850 -- loss: 0.01757508970273193, acc: 0.99375\n","Epoch 1 #17900 -- loss: 0.017425143747532276, acc: 0.9925\n","Epoch 1 #17950 -- loss: 0.017466456606343855, acc: 0.9925\n","Epoch 1 #18000 -- loss: 0.012633876389882061, acc: 0.995\n","Epoch 1 #18050 -- loss: 0.011613251470698742, acc: 0.9925\n","Epoch 1 #18100 -- loss: 0.025780252945260144, acc: 0.99\n","Epoch 1 #18150 -- loss: 0.016305119408061727, acc: 0.99125\n","Epoch 1 #18200 -- loss: 0.04810657534631901, acc: 0.9825\n","Epoch 1 #18250 -- loss: 0.021849970136245248, acc: 0.995\n","Epoch 1 #18300 -- loss: 0.016157773188315332, acc: 0.995\n","Epoch 1 #18350 -- loss: 0.017659993241541088, acc: 0.995\n","Epoch 1 #18400 -- loss: 0.014885152469796594, acc: 0.995\n","Epoch 1 #18450 -- loss: 0.013956102365336847, acc: 0.995\n","Epoch 1 #18500 -- loss: 0.018055810406804085, acc: 0.995\n","Epoch 1 #18550 -- loss: 0.05042491343061556, acc: 0.98625\n","Epoch 1 #18600 -- loss: 0.017384004219202324, acc: 0.9925\n","Epoch 1 #18650 -- loss: 0.009788961570011452, acc: 0.99875\n","Epoch 1 #18700 -- loss: 0.023143355177890044, acc: 0.99375\n","Epoch 1 #18750 -- loss: 0.01293947976344498, acc: 0.9975\n","Epoch 1 #18800 -- loss: 0.01733267119998345, acc: 0.995\n","Epoch 1 #18850 -- loss: 0.003962694998335792, acc: 1.0\n","Epoch 1 #18900 -- loss: 0.025537873699940972, acc: 0.99375\n","Epoch 1 #18950 -- loss: 0.03370464611769421, acc: 0.9875\n","Epoch 1 #19000 -- loss: 0.014908138957398478, acc: 0.995\n","Epoch 1 #19050 -- loss: 0.03570644328428898, acc: 0.98125\n","Epoch 1 #19100 -- loss: 0.017980990923242644, acc: 0.99375\n","Epoch 1 #19150 -- loss: 0.014389772114227525, acc: 0.9925\n","Epoch 1 #19200 -- loss: 0.028689384762838017, acc: 0.99125\n","Epoch 1 #19250 -- loss: 0.013478845860518049, acc: 0.99625\n","Epoch 1 #19300 -- loss: 0.02374816232739249, acc: 0.99\n","Epoch 1 #19350 -- loss: 0.01017551225872012, acc: 0.99625\n","Epoch 1 #19400 -- loss: 0.015234663882438326, acc: 0.995\n","Epoch 1 #19450 -- loss: 0.023145380928181112, acc: 0.9925\n","Epoch 1 #19500 -- loss: 0.018272246717097006, acc: 0.99125\n","Epoch 1 #19550 -- loss: 0.033500092968461105, acc: 0.9925\n","Epoch 1 #19600 -- loss: 0.015806148110423236, acc: 0.995\n","Epoch 1 #19650 -- loss: 0.012808747004601172, acc: 0.9975\n","Epoch 1 #19700 -- loss: 0.005129137409530813, acc: 0.99875\n","Epoch 1 #19750 -- loss: 0.02087342954124324, acc: 0.99375\n","Epoch 1 #19800 -- loss: 0.011811722546990495, acc: 0.995\n","Epoch 1 #19850 -- loss: 0.00833540962805273, acc: 0.99875\n","Epoch 1 #19900 -- loss: 0.01514329397556139, acc: 0.995\n","Epoch 1 #19950 -- loss: 0.014498416762362467, acc: 0.9925\n","Epoch 1 #20000 -- loss: 0.01993190411332762, acc: 0.99625\n","Epoch 1 #20050 -- loss: 0.012817782475613057, acc: 0.99625\n","Epoch 1 #20100 -- loss: 0.02920513895151089, acc: 0.9925\n","Epoch 1 #20150 -- loss: 0.023300419494044034, acc: 0.99\n","Epoch 1 #20200 -- loss: 0.009981311645533423, acc: 0.9975\n","Epoch 1 #20250 -- loss: 0.013844802136300132, acc: 0.9975\n","Epoch 1 #20300 -- loss: 0.03253619894094299, acc: 0.99125\n","Epoch 1 #20350 -- loss: 0.018544585367490072, acc: 0.99375\n","Epoch 1 #20400 -- loss: 0.013556661536276805, acc: 0.99375\n","Epoch 1 #20450 -- loss: 0.020082543829630595, acc: 0.995\n","Epoch 1 #20500 -- loss: 0.01591504657699261, acc: 0.99375\n","Epoch 1 #20550 -- loss: 0.011096592034300556, acc: 0.99625\n","Epoch 1 #20600 -- loss: 0.020229148567595986, acc: 0.995\n","Epoch 1 #20650 -- loss: 0.011757365535886492, acc: 0.995\n","Epoch 1 #20700 -- loss: 0.011778699324058834, acc: 0.99875\n","Epoch 1 #20750 -- loss: 0.020848275645112154, acc: 0.9925\n","Epoch 1 #20800 -- loss: 0.034049304414365905, acc: 0.98875\n","Epoch 1 #20850 -- loss: 0.00898841911839554, acc: 0.9975\n","Epoch 1 #20900 -- loss: 0.01838863024604507, acc: 0.9925\n","Epoch 1 #20950 -- loss: 0.011746930274530314, acc: 0.9975\n","Epoch 1 #21000 -- loss: 0.017279499691794625, acc: 0.99375\n","Epoch 1 #21050 -- loss: 0.026114333411969712, acc: 0.995\n","Epoch 1 #21100 -- loss: 0.009319611171376892, acc: 0.9975\n","Epoch 1 #21150 -- loss: 0.007903075350914151, acc: 0.9975\n","Epoch 1 #21200 -- loss: 0.020466660135716665, acc: 0.995\n","Epoch 1 #21250 -- loss: 0.01638634802729939, acc: 0.99375\n","Epoch 1 #21300 -- loss: 0.02129397483804496, acc: 0.9925\n","Epoch 1 #21350 -- loss: 0.023647233476513065, acc: 0.995\n","Epoch 1 #21400 -- loss: 0.008970695413590874, acc: 0.99625\n","Epoch 1 #21450 -- loss: 0.02143808765569702, acc: 0.9925\n","Epoch 1 #21500 -- loss: 0.011684481010888703, acc: 0.995\n","Epoch 1 #21550 -- loss: 0.017406089552969205, acc: 0.99375\n","Epoch 1 #21600 -- loss: 0.014901031204499305, acc: 0.99375\n","Epoch 1 #21650 -- loss: 0.010648236321285367, acc: 0.9975\n","Epoch 1 #21700 -- loss: 0.016067256113456097, acc: 0.9925\n","Epoch 1 #21750 -- loss: 0.020772338662354742, acc: 0.99625\n","Epoch 1 #21800 -- loss: 0.02574238844856154, acc: 0.99375\n","Epoch 1 #21850 -- loss: 0.0077350811293581505, acc: 0.9975\n","Epoch 1 #21900 -- loss: 0.026267078148084693, acc: 0.98875\n","Epoch 1 #21950 -- loss: 0.04474822653573938, acc: 0.985\n","Epoch 1 #22000 -- loss: 0.033577044791309164, acc: 0.99125\n","Epoch 1 #22050 -- loss: 0.02148038036946673, acc: 0.99375\n","Epoch 1 #22100 -- loss: 0.020698020082199946, acc: 0.99\n","Epoch 1 #22150 -- loss: 0.026044190367683767, acc: 0.99\n","Epoch 1 #22200 -- loss: 0.019521459989482536, acc: 0.99375\n","Epoch 1 #22250 -- loss: 0.020048081832646857, acc: 0.99125\n","Epoch 1 #22300 -- loss: 0.03559772377251647, acc: 0.98625\n","Epoch 1 #22350 -- loss: 0.018516273277637083, acc: 0.995\n","Epoch 1 #22400 -- loss: 0.017018643004848854, acc: 0.99375\n","Epoch 1 #22450 -- loss: 0.016125833197002067, acc: 0.99625\n","Epoch 1 #22500 -- loss: 0.02304407907067798, acc: 0.99125\n","Epoch 1 #22550 -- loss: 0.026181590746855363, acc: 0.99\n","Epoch 1 #22600 -- loss: 0.026759276616212448, acc: 0.99125\n","Epoch 1 #22650 -- loss: 0.010402266014571069, acc: 0.9975\n","Epoch 1 #22700 -- loss: 0.027333627110201632, acc: 0.99125\n","Epoch 1 #22750 -- loss: 0.009526415709988214, acc: 0.9975\n","Epoch 1 #22800 -- loss: 0.016926116275135426, acc: 0.995\n","Epoch 1 #22850 -- loss: 0.012416365265962667, acc: 0.9975\n","Epoch 1 #22900 -- loss: 0.02033595693996176, acc: 0.995\n","Epoch 1 #22950 -- loss: 0.020539632701547815, acc: 0.99375\n","Epoch 1 #23000 -- loss: 0.011370055576553567, acc: 0.99625\n","Epoch 1 #23050 -- loss: 0.014216022407345008, acc: 0.99625\n","Epoch 1 #23100 -- loss: 0.01325631314291968, acc: 0.9925\n","Epoch 1 #23150 -- loss: 0.03752060354338028, acc: 0.9925\n","Epoch 1 #23200 -- loss: 0.012186684936168604, acc: 0.99375\n","Epoch 1 #23250 -- loss: 0.022671159392339178, acc: 0.99125\n","Epoch 1 #23300 -- loss: 0.025041616577655076, acc: 0.99\n","Epoch 1 #23350 -- loss: 0.007274889803666156, acc: 0.99625\n","Epoch 1 #23400 -- loss: 0.024654551965068095, acc: 0.99125\n","Epoch 1 #23450 -- loss: 0.011550881038710941, acc: 0.9975\n","Epoch 1 #23500 -- loss: 0.01442907929798821, acc: 0.99375\n","Epoch 1 #23550 -- loss: 0.04346210068935761, acc: 0.99\n","Epoch 1 #23600 -- loss: 0.027227016593096776, acc: 0.99125\n","Epoch 1 #23650 -- loss: 0.00567494311457267, acc: 0.99875\n","Epoch 1 #23700 -- loss: 0.002713576305686729, acc: 1.0\n","Epoch 1 #23750 -- loss: 0.02854216477891896, acc: 0.99125\n","Epoch 1 #23800 -- loss: 0.014691719098918839, acc: 0.99375\n","Epoch 1 #23850 -- loss: 0.027724224983830936, acc: 0.9925\n","Epoch 1 #23900 -- loss: 0.015922075762064197, acc: 0.995\n","Epoch 1 #23950 -- loss: 0.013672171207872452, acc: 0.99625\n","Epoch 1 #24000 -- loss: 0.008016062484821306, acc: 0.9975\n","Epoch 1 #24050 -- loss: 0.017747427036229054, acc: 0.99125\n","Epoch 1 #24100 -- loss: 0.014414281455683521, acc: 0.99625\n","Epoch 1 #24150 -- loss: 0.012784270361153175, acc: 0.99875\n","Epoch 1 #24200 -- loss: 0.006152821290306747, acc: 0.99875\n","Epoch 1 #24250 -- loss: 0.01049104278543382, acc: 0.9975\n","Epoch 1 #24300 -- loss: 0.010357322188647232, acc: 0.99375\n","Epoch 1 #24350 -- loss: 0.00682347830152139, acc: 0.99625\n","Epoch 1 #24400 -- loss: 0.03136457579603302, acc: 0.995\n","Epoch 1 #24450 -- loss: 0.017760873544903008, acc: 0.98875\n","Epoch 1 #24500 -- loss: 0.013595472101005725, acc: 0.995\n","Epoch 1 #24550 -- loss: 0.0075158918745000846, acc: 0.9975\n","Epoch 1 #24600 -- loss: 0.020858349708287278, acc: 0.99375\n","Epoch 1 #24650 -- loss: 0.026341912068310193, acc: 0.99125\n","Epoch 1 #24700 -- loss: 0.021598492853227073, acc: 0.995\n","Epoch 1 #24750 -- loss: 0.023435239139362237, acc: 0.99375\n","Epoch 1 #24800 -- loss: 0.017056326872552745, acc: 0.99375\n","Epoch 1 #24850 -- loss: 0.01773184053541627, acc: 0.99375\n","Epoch 1 #24900 -- loss: 0.022331261044600977, acc: 0.99125\n","Epoch 1 #24950 -- loss: 0.014871383127465379, acc: 0.995\n","Epoch 1 #25000 -- loss: 0.008385719998768764, acc: 0.99625\n","Epoch 1 #25050 -- loss: 0.018689796701946763, acc: 0.9925\n","Epoch 1 #25100 -- loss: 0.012462001016101567, acc: 0.99625\n","Epoch 1 #25150 -- loss: 0.022133775326801698, acc: 0.9925\n","Epoch 1 #25200 -- loss: 0.010423853514075744, acc: 0.99625\n","Epoch 1 #25250 -- loss: 0.01575900846539298, acc: 0.9925\n","Epoch 1 #25300 -- loss: 0.017535250810760773, acc: 0.99375\n","Epoch 1 #25350 -- loss: 0.011478793223504908, acc: 0.99625\n","Epoch 1 #25400 -- loss: 0.02612618861021474, acc: 0.99125\n","Epoch 1 #25450 -- loss: 0.007950932292733342, acc: 0.99875\n","Epoch 1 #25500 -- loss: 0.007758054944570176, acc: 0.9975\n","Epoch 1 #25550 -- loss: 0.016594044431112707, acc: 0.99625\n","Epoch 1 #25600 -- loss: 0.011425593241874595, acc: 0.9975\n","Epoch 1 #25650 -- loss: 0.007685564882995095, acc: 0.99875\n","Epoch 1 #25700 -- loss: 0.016885671675845516, acc: 0.99125\n","Epoch 1 #25750 -- loss: 0.04145641235969379, acc: 0.9875\n","Epoch 1 #25800 -- loss: 0.01997303607757203, acc: 0.9925\n","Epoch 1 #25850 -- loss: 0.012920959136099554, acc: 0.9925\n","Epoch 1 #25900 -- loss: 0.011741657930833753, acc: 0.995\n","Epoch 1 #25950 -- loss: 0.005684988419961883, acc: 0.9975\n","Epoch 1 #26000 -- loss: 0.007396990362758515, acc: 0.9975\n","Epoch 1 #26050 -- loss: 0.02600885050793295, acc: 0.99\n","Epoch 1 #26100 -- loss: 0.014524828292633175, acc: 0.9925\n","Epoch 1 #26150 -- loss: 0.013709270956023829, acc: 0.99375\n","Epoch 1 #26200 -- loss: 0.009905115872679743, acc: 0.995\n","Epoch 1 #26250 -- loss: 0.01602805313799763, acc: 0.995\n","Epoch 1 #26300 -- loss: 0.027185197179496755, acc: 0.9925\n","Epoch 1 #26350 -- loss: 0.02262346092655207, acc: 0.99375\n","Epoch 1 #26400 -- loss: 0.011713630311714952, acc: 0.99625\n","Epoch 1 #26450 -- loss: 0.024617943999473937, acc: 0.99\n","Epoch 1 #26500 -- loss: 0.018985915855446366, acc: 0.99\n","Epoch 1 #26550 -- loss: 0.0067421265144366775, acc: 0.99875\n","Epoch 1 #26600 -- loss: 0.009090695073391544, acc: 0.995\n","Epoch 1 #26650 -- loss: 0.015883028133248444, acc: 0.99375\n","Epoch 1 #26700 -- loss: 0.02654761458019493, acc: 0.9925\n","Epoch 1 #26750 -- loss: 0.012731127318693325, acc: 0.995\n","Epoch 1 #26800 -- loss: 0.014596824115724303, acc: 0.995\n","Epoch 1 #26850 -- loss: 0.009021466261910973, acc: 0.99375\n","Epoch 1 #26900 -- loss: 0.016363267131964676, acc: 0.99125\n","Epoch 1 #26950 -- loss: 0.015974738118238747, acc: 0.99375\n","Epoch 1 #27000 -- loss: 0.0044997263928235045, acc: 0.99875\n","Epoch 1 #27050 -- loss: 0.006913733848341508, acc: 0.9975\n","Epoch 1 #27100 -- loss: 0.029953310374112335, acc: 0.99375\n","Epoch 1 #27150 -- loss: 0.017496080143610017, acc: 0.995\n","Epoch 1 #27200 -- loss: 0.013194571996282321, acc: 0.99625\n","Epoch 1 #27250 -- loss: 0.010279688764712773, acc: 0.99875\n","Epoch 1 #27300 -- loss: 0.01072666380656301, acc: 0.995\n","Epoch 1 #27350 -- loss: 0.01854549260257045, acc: 0.9975\n","Epoch 1 #27400 -- loss: 0.00869003332569264, acc: 0.99625\n","Epoch 1 #27450 -- loss: 0.021372697563492693, acc: 0.99125\n","Epoch 1 #27500 -- loss: 0.008642798842483899, acc: 0.99625\n","Epoch 1 #27550 -- loss: 0.015136702525196596, acc: 0.99375\n","Epoch 1 #27600 -- loss: 0.027260551694780588, acc: 0.99125\n","Epoch 1 #27650 -- loss: 0.015442285219905897, acc: 0.9925\n","Epoch 1 #27700 -- loss: 0.014761304512067, acc: 0.99625\n","Epoch 1 #27750 -- loss: 0.017688731723756065, acc: 0.9925\n","Epoch 1 #27800 -- loss: 0.02407937563577434, acc: 0.995\n","Epoch 1 #27850 -- loss: 0.008388562088366597, acc: 0.99625\n","Epoch 1 #27900 -- loss: 0.01922837989550317, acc: 0.995\n","Epoch 1 #27950 -- loss: 0.027358885437715797, acc: 0.9925\n","Epoch 1 #28000 -- loss: 0.019977349056862295, acc: 0.99125\n","Epoch 1 #28050 -- loss: 0.014436993940034882, acc: 0.99625\n","Epoch 1 #28100 -- loss: 0.01195557423197897, acc: 0.99375\n","Epoch 1 #28150 -- loss: 0.02116394219410722, acc: 0.9925\n","Epoch 1 #28200 -- loss: 0.0064141069070319644, acc: 0.99875\n","Epoch 1 #28250 -- loss: 0.017604496783169454, acc: 0.995\n","Epoch 1 #28300 -- loss: 0.03555572811252205, acc: 0.99\n","Epoch 1 #28350 -- loss: 0.008674619924277068, acc: 0.9975\n","Epoch 1 #28400 -- loss: 0.01962234776088735, acc: 0.9925\n","Epoch 1 #28450 -- loss: 0.03412739213614259, acc: 0.9875\n","Epoch 1 #28500 -- loss: 0.011742122685245705, acc: 0.995\n","Epoch 1 #28550 -- loss: 0.012196724326640833, acc: 0.99625\n","Epoch 1 #28600 -- loss: 0.009410328717203811, acc: 0.995\n","Epoch 1 #28650 -- loss: 0.021940169636218344, acc: 0.995\n","Epoch 1 #28700 -- loss: 0.008945520330162254, acc: 0.99625\n","Epoch 1 #28750 -- loss: 0.02122613746469142, acc: 0.99125\n","Epoch 1 #28800 -- loss: 0.01820345168118365, acc: 0.995\n","Epoch 1 #28850 -- loss: 0.015611643227457535, acc: 0.995\n","Epoch 1 #28900 -- loss: 0.008790030759410001, acc: 0.99625\n","Epoch 1 #28950 -- loss: 0.028867374890251086, acc: 0.99375\n","Epoch 1 #29000 -- loss: 0.01648914696124848, acc: 0.99375\n","Epoch 1 #29050 -- loss: 0.012809107264911291, acc: 0.995\n","Epoch 1 #29100 -- loss: 0.00820153915658011, acc: 0.9975\n","Epoch 1 #29150 -- loss: 0.01225306689972058, acc: 0.9975\n","Epoch 1 #29200 -- loss: 0.014465339623129694, acc: 0.99625\n","Epoch 1 #29250 -- loss: 0.00733781821152661, acc: 0.99625\n","Epoch 1 #29300 -- loss: 0.005569615852145944, acc: 0.99875\n","Epoch 1 #29350 -- loss: 0.022622309128782946, acc: 0.995\n","Epoch 1 #29400 -- loss: 0.016158768577879526, acc: 0.9925\n","Epoch 1 #29450 -- loss: 0.022723138277651742, acc: 0.99375\n","Epoch 1 #29500 -- loss: 0.006334784449718427, acc: 0.9975\n","Epoch 1 #29550 -- loss: 0.008234014433983248, acc: 0.9975\n","Epoch 1 #29600 -- loss: 0.010679920152615523, acc: 0.995\n","Epoch 1 #29650 -- loss: 0.014852943015284836, acc: 0.9975\n","Epoch 1 #29700 -- loss: 0.019877980838064104, acc: 0.98875\n","Epoch 1 #29750 -- loss: 0.012644396565156058, acc: 0.99375\n","Epoch 1 #29800 -- loss: 0.02734912337444257, acc: 0.99375\n","Epoch 1 #29850 -- loss: 0.00962509598262841, acc: 0.99625\n","Epoch 1 #29900 -- loss: 0.009155704225122463, acc: 0.99625\n","Epoch 1 #29950 -- loss: 0.016163311704876834, acc: 0.99375\n","Epoch 1 #30000 -- loss: 0.008912271236767992, acc: 0.9975\n","Epoch 1 #30050 -- loss: 0.022676438692142257, acc: 0.99125\n","Epoch 1 #30100 -- loss: 0.02430724939244101, acc: 0.99125\n","Epoch 1 #30150 -- loss: 0.02899436907551717, acc: 0.98875\n","Epoch 1 #30200 -- loss: 0.015001751820382197, acc: 0.99125\n","Epoch 1 #30250 -- loss: 0.024915488084370736, acc: 0.99125\n","Epoch 1 #30300 -- loss: 0.010633981387363746, acc: 0.99375\n","Epoch 1 #30350 -- loss: 0.02455225916171912, acc: 0.99125\n","Epoch 1 #30400 -- loss: 0.015487192587461323, acc: 0.99375\n","Epoch 1 #30450 -- loss: 0.02518653040548088, acc: 0.99125\n","Epoch 1 #30500 -- loss: 0.02730572517088149, acc: 0.99\n","Epoch 1 #30550 -- loss: 0.014061346461239736, acc: 0.995\n","Epoch 1 #30600 -- loss: 0.015309311542077922, acc: 0.99375\n","Epoch 1 #30650 -- loss: 0.009194916147534968, acc: 0.995\n","Epoch 1 #30700 -- loss: 0.024943748105288252, acc: 0.99625\n","Epoch 1 #30750 -- loss: 0.022321915007196366, acc: 0.99125\n","Epoch 1 #30800 -- loss: 0.02155982488679001, acc: 0.99625\n","Epoch 1 #30850 -- loss: 0.005382815389020834, acc: 0.9975\n","Epoch 1 #30900 -- loss: 0.010146835735358763, acc: 0.99625\n","Epoch 1 #30950 -- loss: 0.005478895532432943, acc: 0.9975\n","Epoch 1 #31000 -- loss: 0.012650870059151203, acc: 0.9975\n","Epoch 1 #31050 -- loss: 0.02410261613607872, acc: 0.9925\n","Epoch 1 #31100 -- loss: 0.020308079315873327, acc: 0.99375\n","Epoch 1 #31150 -- loss: 0.019907764889649116, acc: 0.99625\n","Epoch 1 #31200 -- loss: 0.016324508329853417, acc: 0.99125\n","Epoch 1 #31250 -- loss: 0.022247115967329593, acc: 0.9925\n","Epoch 1 #31300 -- loss: 0.003775796081754379, acc: 0.99875\n","Epoch 1 #31350 -- loss: 0.006633797666290775, acc: 0.99625\n","Epoch 1 #31400 -- loss: 0.027590389303222763, acc: 0.99125\n","Epoch 1 #31450 -- loss: 0.024704146230069456, acc: 0.99\n","Epoch 1 #31500 -- loss: 0.02190032202779548, acc: 0.9925\n","Epoch 1 #31550 -- loss: 0.020233085741638207, acc: 0.99375\n","Epoch 1 #31600 -- loss: 0.010183319155767095, acc: 0.99625\n","Epoch 1 #31650 -- loss: 0.017761851316026877, acc: 0.99125\n","Epoch 1 #31700 -- loss: 0.02388789182092296, acc: 0.995\n","Epoch 1 #31750 -- loss: 0.011936759667587466, acc: 0.99625\n","Epoch 1 #31800 -- loss: 0.017830896168597975, acc: 0.99125\n","Epoch 1 #31850 -- loss: 0.019292148764361628, acc: 0.9925\n","Epoch 1 #31900 -- loss: 0.016401239926053676, acc: 0.99375\n","Epoch 1 #31950 -- loss: 0.010868866003293079, acc: 0.9975\n","Epoch 1 #32000 -- loss: 0.011053753335145302, acc: 0.995\n","Epoch 1 #32050 -- loss: 0.00649019784599659, acc: 0.9975\n","Epoch 1 #32100 -- loss: 0.02042056645033881, acc: 0.99125\n","Epoch 1 #32150 -- loss: 0.03288761529605835, acc: 0.99125\n","Epoch 1 #32200 -- loss: 0.017042287469375878, acc: 0.995\n","Epoch 1 #32250 -- loss: 0.026946898801252245, acc: 0.9925\n","Epoch 1 #32300 -- loss: 0.012685064942343161, acc: 0.99625\n","Epoch 1 #32350 -- loss: 0.00988382602838101, acc: 0.9975\n","Epoch 1 #32400 -- loss: 0.007440983399283141, acc: 0.99875\n","Epoch 1 #32450 -- loss: 0.006917204146739095, acc: 0.9975\n","Epoch 1 #32500 -- loss: 0.008631645021378063, acc: 0.99625\n","Epoch 1 #32550 -- loss: 0.0133895131025929, acc: 0.99625\n","Epoch 1 #32600 -- loss: 0.0055275742695084775, acc: 0.99625\n","Epoch 1 #32650 -- loss: 0.014342582731042058, acc: 0.9925\n","Epoch 1 #32700 -- loss: 0.00441915152448928, acc: 0.99875\n","Epoch 1 #32750 -- loss: 0.017472862065769732, acc: 0.99375\n","Epoch 1 #32800 -- loss: 0.008086195808864431, acc: 0.99875\n","Epoch 1 #32850 -- loss: 0.019567145920445908, acc: 0.99375\n","Epoch 1 #32900 -- loss: 0.01239037823455874, acc: 0.99625\n","Epoch 1 #32950 -- loss: 0.008449894084915286, acc: 0.99625\n","Epoch 1 #33000 -- loss: 0.00837530602599145, acc: 0.9975\n","\n","Epoch 1 loss: 0.0197343217650566, acc: 0.9933787878787879\n"]}],"source":["f = 4\n","e = 1\n","\n","print(f\"------------------------------ {f} fold {e} epoch------------------------------\")\n","\n","model.train()\n","epoch_perform, batch_perform = np.zeros(2), np.zeros(2)\n","print()\t\n","progress_bar = tqdm(enumerate(trainloader), total=len(trainloader), leave=True, position=0,)\n","for j, v in progress_bar:\n","  input_ids, attention_mask, labels = v['input_ids'].to(device), v['attention_mask'].to(device), v['labels'].to(device)\n","  \n","  optimizer.zero_grad()\n","  \n","  outputs = model(input_ids, attention_mask) ## label을 안 넣어서 logits값만 출력\n","  output = outputs.logits # The outputs object is a SequenceClassifierOutput\n","  loss = criterion(output, labels)\n","  loss.backward()\n","  optimizer.step()\n","  scheduler.step()\n","  for learning_rate in scheduler.get_lr():\n","    wandb.log({\"learning_rate\": learning_rate})\n","\n","  predict = output.argmax(dim=-1)\n","  predict = predict.detach().cpu().numpy()\n","  labels = labels.detach().cpu().numpy()\n","  acc = accuracy_score(labels, predict)\n","\n","  batch_perform += np.array([loss.item(), acc])\n","  epoch_perform += np.array([loss.item(), acc])\n","\n","  if (j + 1) % 50 == 0:\n","    print(\n","        f\"Epoch {e} #{j + 1} -- loss: {batch_perform[0] / 50}, acc: {batch_perform[1] / 50}\"\n","    )\n","    batch_perform = np.zeros(2)\n","print()\n","print(\n","    f\"Epoch {e} loss: {epoch_perform[0] / total_batch_}, acc: {epoch_perform[1] / total_batch_}\"\n","    )\n","wandb.log({\n","    \"epoch\": e,\n","    \"Train epoch Loss\": epoch_perform[0] / total_batch_,\n","    \"Train epoch Acc\": epoch_perform[1] / total_batch_}\n","    )\n","torch.save(model.state_dict(), f\"./models/{args.model_name}/{f}-fold/train.pt\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2264815,"status":"ok","timestamp":1654664636073,"user":{"displayName":"Lainie Kang","userId":"17932680864583243195"},"user_tz":-540},"id":"dVc8wiougGUp","outputId":"6f885863-6453-428f-e50f-5be32e110088"},"outputs":[{"name":"stdout","output_type":"stream","text":["New best model for val accuracy : 0.9961212121212121! saving the best model..\n","=============== Fold4 Wrong DataFrame Saved ===============\n","\n",">>>> Validation loss: 0.01259141871224953, Acc: 0.9961212121212121\n","\n","==================================================\n","4fold best_val_acc_list : [0.9934772727272727, 0.9961212121212121]\n","=============== 4fold Final Score(ACC) : 0.9947992424242424 ===============\n"]}],"source":["f = 4\n","e = 1\n","best_val_loss, best_val_acc, = np.inf, 0\n","###### Validation\n","load_path = f'./models/{args.model_name}/{f}-fold/train.pt'\n","model.load_state_dict(torch.load(load_path,map_location=device))\n","model.to(device)\n","model.eval()\n","valid_perform = np.zeros(2)\n","\n","all_valid_predict_lst = []\n","all_valid_labels_lst = []\n","\n","# 틀린 데이터들을 wandb 기록하기 위함.\n","wrong_sample_dict = defaultdict(list)\n","\n","with torch.no_grad():\n","    for v in validloader:\n","      input_ids, attention_mask, valid_labels = v[\"input_ids\"].to(device), v[\"attention_mask\"].to(device), v[\"labels\"].to(device)\n","      \n","      valid_outputs = model(input_ids, attention_mask)\n","      valid_output = valid_outputs.logits\n","      valid_loss = criterion(valid_output, valid_labels)\n","      \n","      valid_predict = valid_output.argmax(dim=-1)\n","      valid_predict = valid_predict.detach().cpu().numpy()\n","      valid_labels = valid_labels.detach().cpu().numpy()\n","\n","      ###########################\n","      # valid eval 결과, 틀린 데이터들은 wandb에 Logging\n","      if args.logging_wrong_samples:\n","        wrong_sample_index = np.where(valid_labels!=valid_predict)[0]\n","        if len(wrong_sample_index)>0:\n","          wrong_sample_text, wrong_sample_label, wrong_sample_pred, entailment_prob, contradiction_prob = wrong_batch_for_wandb(tokenizer, wrong_sample_index, input_ids, valid_labels, valid_predict, valid_output)\n","\n","          wrong_sample_dict['입력 코드 Pair'] += wrong_sample_text\n","          wrong_sample_dict['실제값'] += wrong_sample_label\n","          wrong_sample_dict['예측값'] += wrong_sample_pred\n","          wrong_sample_dict['diff_logit'] += entailment_prob\n","          wrong_sample_dict['same_logit'] += contradiction_prob\n","      ###########################\n","\n","      valid_acc = accuracy_score(valid_labels, valid_predict)\n","      valid_perform += np.array([valid_loss.item(), valid_acc])\n","\n","      all_valid_predict_lst += list(valid_predict)\n","      all_valid_labels_lst += list(valid_labels)\n","  \n","###### Model save\n","val_total_loss = valid_perform[0] / valid_batch_\n","val_total_acc = valid_perform[1] / valid_batch_\n","best_val_loss = min(best_val_loss, val_total_loss)\n","\n","\n","if val_total_acc > best_val_acc:\n","    print(f\"New best model for val accuracy : {val_total_acc}! saving the best model..\")\n","    torch.save(model.state_dict(), f\"./models/{args.model_name}/{f}-fold/best.pt\")\n","\n","    # 참고 : Model 추가 재학습을 위한 모델을 저장하는 코드\n","    # https://tutorials.pytorch.kr/beginner/saving_loading_models.html#checkpoint\n","\n","    best_val_acc = val_total_acc\n","\n","    ### Confusion Matrix\n","    class_names = ['diff','same'] # (0,1,2)\n","    # https://wandb.ai/wandb/plots/reports/Confusion-Matrix--VmlldzozMDg1NTM\n","    wandb.log({f\"{e}_epoch_conf_mat\" : wandb.plot.confusion_matrix(probs=None,\n","                                                                      y_true=all_valid_labels_lst, preds=all_valid_predict_lst,\n","                                                                      class_names=class_names)})\n","      \n","    if args.logging_wrong_samples and val_total_acc > 0.91:\n","      ########### Logging Wrong Samples ##########\n","      # Save Wrong DataFrame\n","      wrong_sample_df = pd.DataFrame(wrong_sample_dict)\n","      wrong_sample_df.to_csv(f\"./models/{args.model_name}/{f}-fold/wrong_df.csv\",index=False)\n","      print('='*15,f'Fold{f} Wrong DataFrame Saved','='*15)\n","      # Loggin Wandb\n","      text_table = wandb.Table(data = wrong_sample_df)\n","      run.log({f\"{f}_fold_wrong_samples\" : text_table})\n","      ###########################\n","    \n","print()\n","print(\n","    f\">>>> Validation loss: {val_total_loss}, Acc: {val_total_acc}\"\n","    )\n","print()\n","wandb.log({\n","    \"epoch\": e,\n","    \"Last_Valid Loss\": val_total_loss,\n","    \"Last_Valid Acc\": val_total_acc,\n","    })\n","best_val_acc_list.append(best_val_acc)\n","print('='*50)\n","print(f\"{f}fold best_val_acc_list : {best_val_acc_list}\")\n","print('='*15, f'{f}fold Final Score(ACC) : {np.mean(best_val_acc_list)}', '='*15)\n","wandb.log({\n","f\"Total Mean ACC ({f}fold)\": np.mean(best_val_acc_list)}\n",")"]},{"cell_type":"markdown","metadata":{"id":"HyxTFWTWgHOH"},"source":["# 5 fold"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":104},"executionInfo":{"elapsed":6436,"status":"ok","timestamp":1654738566989,"user":{"displayName":"Lainie Kang","userId":"17932680864583243195"},"user_tz":-540},"id":"e8Xqq_M2gHOH","outputId":"b8e3b48c-f564-47d2-c352-5986783f8809"},"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnahyeonkang\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"stream","name":"stdout","text":["---------------------------------- 5 fold----------------------------------\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.12.17"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/drive/MyDrive/DACON/wandb/run-20220609_013600-18hr0pia</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/nahyeonkang/graphcodebert_Bs16_OptAdamW_ScduCosine_Sm0.0/runs/18hr0pia\" target=\"_blank\">lemon-puddle-15</a></strong> to <a href=\"https://wandb.ai/nahyeonkang/graphcodebert_Bs16_OptAdamW_ScduCosine_Sm0.0\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"]},"metadata":{}}],"source":["f = 5\n","\n","print(f\"---------------------------------- {f} fold----------------------------------\")\n","\n","run = wandb.init(project=args.project_name)\n","wandb.run.name = f'{args.model_name}/{f}-fold'\n","wandb.config.update(args)\n","os.makedirs(f'./models/{args.model_name}/{f}-fold', exist_ok=True)\n","\n","total_size = len(dataset)\n","total_ids = list(range(total_size))\n","del_ids = list(range((f-1)*gap, f*gap))\n","training_ids = set(total_ids) - set(del_ids)\n","\n","training_dset = dataset.select(list(training_ids))\n","eval_dset = dataset.select(del_ids)\n","\n","collator = DataCollatorWithPadding(tokenizer=tokenizer)\n","\n","trainloader = DataLoader(training_dset,\n","                          batch_size=16,\n","                          shuffle=True,\n","                          collate_fn = collator\n","                          )\n","\n","validloader = DataLoader(eval_dset,\n","                          batch_size=16,\n","                          shuffle=False,\n","                          collate_fn = collator\n","                          )\n","\n","total_batch_ = len(trainloader)\n","valid_batch_ = len(validloader)\n","\n","optimizer = get_optimizer(model, args)\n","scheduler = get_scheduler(optimizer, args, total_batch_)"]},{"cell_type":"markdown","metadata":{"id":"Sj-30lYpgHOI"},"source":["## 1 epoch"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["91aa2129d54e452eb4f2bd8345d7855a","f3ced7d7e17e495a83f8b27517b3dbae","02036367186b49d88b8f930e7f740393","df8badfdb8c04a34ae8b17fe011a1b4e","f6b92706841148a5be9d30fee4b3d074","a267825d847e46baa4116337210125bd","7fcd77c7d14a430c983b8661b4217286","8e71e1ad48884f8d8292846920440086","16ce2c9b25b94d9b80c9c16aa84a47dc","77145c92d6cf419a9cfc409a0b7284eb","41c2d7055e2d4da4aabc827cfe0c9893"]},"executionInfo":{"elapsed":4896465,"status":"ok","timestamp":1654714245461,"user":{"displayName":"Lainie Kang","userId":"17932680864583243195"},"user_tz":-540},"id":"XhgYBtj7gHOJ","outputId":"411caa78-309a-45e2-b927-57b8db0ceefb"},"outputs":[{"name":"stdout","output_type":"stream","text":["------------------------------ 5 fold 1 epoch------------------------------\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"91aa2129d54e452eb4f2bd8345d7855a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/33000 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 1 #50 -- loss: 0.6967503786087036, acc: 0.495\n","Epoch 1 #100 -- loss: 0.6932619571685791, acc: 0.51875\n","Epoch 1 #150 -- loss: 0.6782697117328644, acc: 0.59375\n","Epoch 1 #200 -- loss: 0.6539136481285095, acc: 0.59375\n","Epoch 1 #250 -- loss: 0.45253886699676515, acc: 0.7975\n","Epoch 1 #300 -- loss: 0.3676878722012043, acc: 0.83375\n","Epoch 1 #350 -- loss: 0.29423546597361566, acc: 0.88375\n","Epoch 1 #400 -- loss: 0.2576303370296955, acc: 0.8925\n","Epoch 1 #450 -- loss: 0.25329060837626455, acc: 0.89\n","Epoch 1 #500 -- loss: 0.21139218602329493, acc: 0.91\n","Epoch 1 #550 -- loss: 0.19943900473415851, acc: 0.915\n","Epoch 1 #600 -- loss: 0.14964510945603252, acc: 0.94\n","Epoch 1 #650 -- loss: 0.20588469017297029, acc: 0.91625\n","Epoch 1 #700 -- loss: 0.17614690754562617, acc: 0.92875\n","Epoch 1 #750 -- loss: 0.19389984548091888, acc: 0.9225\n","Epoch 1 #800 -- loss: 0.1566071960143745, acc: 0.93875\n","Epoch 1 #850 -- loss: 0.1790329297631979, acc: 0.92625\n","Epoch 1 #900 -- loss: 0.14826076440513133, acc: 0.94\n","Epoch 1 #950 -- loss: 0.12577670268714428, acc: 0.95\n","Epoch 1 #1000 -- loss: 0.1770302756410092, acc: 0.92875\n","Epoch 1 #1050 -- loss: 0.1569113580137491, acc: 0.93875\n","Epoch 1 #1100 -- loss: 0.1548928567953408, acc: 0.95\n","Epoch 1 #1150 -- loss: 0.13973197227343917, acc: 0.94\n","Epoch 1 #1200 -- loss: 0.1370659974217415, acc: 0.945\n","Epoch 1 #1250 -- loss: 0.1372946097329259, acc: 0.945\n","Epoch 1 #1300 -- loss: 0.16973266107030213, acc: 0.9275\n","Epoch 1 #1350 -- loss: 0.1112542104255408, acc: 0.95875\n","Epoch 1 #1400 -- loss: 0.11958235467784106, acc: 0.95875\n","Epoch 1 #1450 -- loss: 0.16262591721490025, acc: 0.94125\n","Epoch 1 #1500 -- loss: 0.14380938939750196, acc: 0.95125\n","Epoch 1 #1550 -- loss: 0.1304843840189278, acc: 0.95625\n","Epoch 1 #1600 -- loss: 0.13017548497766257, acc: 0.9525\n","Epoch 1 #1650 -- loss: 0.12698836253024637, acc: 0.9475\n","Epoch 1 #1700 -- loss: 0.12089849842712283, acc: 0.9575\n","Epoch 1 #1750 -- loss: 0.1161180207459256, acc: 0.95375\n","Epoch 1 #1800 -- loss: 0.09258006395772099, acc: 0.9625\n","Epoch 1 #1850 -- loss: 0.10814644779544323, acc: 0.965\n","Epoch 1 #1900 -- loss: 0.09400305951014161, acc: 0.96875\n","Epoch 1 #1950 -- loss: 0.11778675782494247, acc: 0.9475\n","Epoch 1 #2000 -- loss: 0.09642321135383099, acc: 0.965\n","Epoch 1 #2050 -- loss: 0.13142580595798792, acc: 0.94625\n","Epoch 1 #2100 -- loss: 0.12362220710143447, acc: 0.96\n","Epoch 1 #2150 -- loss: 0.0777889896184206, acc: 0.96875\n","Epoch 1 #2200 -- loss: 0.11285196133889258, acc: 0.96125\n","Epoch 1 #2250 -- loss: 0.08372561667114496, acc: 0.9725\n","Epoch 1 #2300 -- loss: 0.11669609257020057, acc: 0.95875\n","Epoch 1 #2350 -- loss: 0.08345732294023037, acc: 0.97\n","Epoch 1 #2400 -- loss: 0.09306573373265564, acc: 0.97125\n","Epoch 1 #2450 -- loss: 0.11674254244193434, acc: 0.96125\n","Epoch 1 #2500 -- loss: 0.07797854313626885, acc: 0.975\n","Epoch 1 #2550 -- loss: 0.08436235040426254, acc: 0.9675\n","Epoch 1 #2600 -- loss: 0.0659497678745538, acc: 0.9775\n","Epoch 1 #2650 -- loss: 0.11512090798001737, acc: 0.9575\n","Epoch 1 #2700 -- loss: 0.09484376376494766, acc: 0.96375\n","Epoch 1 #2750 -- loss: 0.09477598545141518, acc: 0.97\n","Epoch 1 #2800 -- loss: 0.09265591287054122, acc: 0.9625\n","Epoch 1 #2850 -- loss: 0.11471915599890053, acc: 0.9575\n","Epoch 1 #2900 -- loss: 0.08831922735087573, acc: 0.97125\n","Epoch 1 #2950 -- loss: 0.08805530784651637, acc: 0.97125\n","Epoch 1 #3000 -- loss: 0.10686610225588083, acc: 0.95875\n","Epoch 1 #3050 -- loss: 0.08367905620951205, acc: 0.9675\n","Epoch 1 #3100 -- loss: 0.10814465437084436, acc: 0.96\n","Epoch 1 #3150 -- loss: 0.09909137958660721, acc: 0.9625\n","Epoch 1 #3200 -- loss: 0.07999902608804405, acc: 0.97\n","Epoch 1 #3250 -- loss: 0.10900853111874312, acc: 0.95625\n","Epoch 1 #3300 -- loss: 0.09059208317659795, acc: 0.96375\n","Epoch 1 #3350 -- loss: 0.07762552831321955, acc: 0.9675\n","Epoch 1 #3400 -- loss: 0.09514909544028342, acc: 0.97\n","Epoch 1 #3450 -- loss: 0.10250803436152638, acc: 0.9625\n","Epoch 1 #3500 -- loss: 0.08322921804152429, acc: 0.9725\n","Epoch 1 #3550 -- loss: 0.09618630384095013, acc: 0.96125\n","Epoch 1 #3600 -- loss: 0.08006365456152707, acc: 0.9675\n","Epoch 1 #3650 -- loss: 0.10600259228143841, acc: 0.96125\n","Epoch 1 #3700 -- loss: 0.1027193271741271, acc: 0.96125\n","Epoch 1 #3750 -- loss: 0.07939216503873467, acc: 0.96875\n","Epoch 1 #3800 -- loss: 0.07300160009413957, acc: 0.97375\n","Epoch 1 #3850 -- loss: 0.0555257240193896, acc: 0.97875\n","Epoch 1 #3900 -- loss: 0.05863694916595705, acc: 0.97625\n","Epoch 1 #3950 -- loss: 0.0840801181923598, acc: 0.9675\n","Epoch 1 #4000 -- loss: 0.08616490206681192, acc: 0.97125\n","Epoch 1 #4050 -- loss: 0.07103375353384762, acc: 0.97875\n","Epoch 1 #4100 -- loss: 0.07934891393175349, acc: 0.97\n","Epoch 1 #4150 -- loss: 0.08144953283015638, acc: 0.975\n","Epoch 1 #4200 -- loss: 0.07694089314900339, acc: 0.9725\n","Epoch 1 #4250 -- loss: 0.07839236981701106, acc: 0.975\n","Epoch 1 #4300 -- loss: 0.07890381050296127, acc: 0.9725\n","Epoch 1 #4350 -- loss: 0.056478863090742376, acc: 0.975\n","Epoch 1 #4400 -- loss: 0.09774169376119972, acc: 0.97125\n","Epoch 1 #4450 -- loss: 0.06854508668184281, acc: 0.97625\n","Epoch 1 #4500 -- loss: 0.0559887981810607, acc: 0.97875\n","Epoch 1 #4550 -- loss: 0.0469465351710096, acc: 0.98625\n","Epoch 1 #4600 -- loss: 0.07897709192475304, acc: 0.9675\n","Epoch 1 #4650 -- loss: 0.061845412810798736, acc: 0.97875\n","Epoch 1 #4700 -- loss: 0.0806717751105316, acc: 0.97\n","Epoch 1 #4750 -- loss: 0.06752881533931941, acc: 0.98125\n","Epoch 1 #4800 -- loss: 0.06912326961290091, acc: 0.97375\n","Epoch 1 #4850 -- loss: 0.07807410844834521, acc: 0.975\n","Epoch 1 #4900 -- loss: 0.0944869156833738, acc: 0.97\n","Epoch 1 #4950 -- loss: 0.09481778736226261, acc: 0.97125\n","Epoch 1 #5000 -- loss: 0.07874711007578299, acc: 0.975\n","Epoch 1 #5050 -- loss: 0.05744591913418844, acc: 0.9775\n","Epoch 1 #5100 -- loss: 0.06655880348291249, acc: 0.97375\n","Epoch 1 #5150 -- loss: 0.06142192177707329, acc: 0.98125\n","Epoch 1 #5200 -- loss: 0.059709947174414996, acc: 0.97625\n","Epoch 1 #5250 -- loss: 0.08111407240387053, acc: 0.97\n","Epoch 1 #5300 -- loss: 0.08873634024988859, acc: 0.96625\n","Epoch 1 #5350 -- loss: 0.05976023674942553, acc: 0.97875\n","Epoch 1 #5400 -- loss: 0.08243400094332173, acc: 0.9675\n","Epoch 1 #5450 -- loss: 0.0775499940244481, acc: 0.9725\n","Epoch 1 #5500 -- loss: 0.0844430479570292, acc: 0.9725\n","Epoch 1 #5550 -- loss: 0.058683746154420076, acc: 0.975\n","Epoch 1 #5600 -- loss: 0.0644683617609553, acc: 0.98\n","Epoch 1 #5650 -- loss: 0.06337402740027756, acc: 0.975\n","Epoch 1 #5700 -- loss: 0.06498483845731244, acc: 0.97875\n","Epoch 1 #5750 -- loss: 0.06880982449743897, acc: 0.9725\n","Epoch 1 #5800 -- loss: 0.05284959658049047, acc: 0.98\n","Epoch 1 #5850 -- loss: 0.07318655288254376, acc: 0.97375\n","Epoch 1 #5900 -- loss: 0.0689326631068252, acc: 0.975\n","Epoch 1 #5950 -- loss: 0.05700441696215421, acc: 0.98625\n","Epoch 1 #6000 -- loss: 0.06523024385329336, acc: 0.9775\n","Epoch 1 #6050 -- loss: 0.08350782146677375, acc: 0.97\n","Epoch 1 #6100 -- loss: 0.06422997390618548, acc: 0.98125\n","Epoch 1 #6150 -- loss: 0.0853770627756603, acc: 0.97125\n","Epoch 1 #6200 -- loss: 0.07231923559913411, acc: 0.96625\n","Epoch 1 #6250 -- loss: 0.07346397881396115, acc: 0.97375\n","Epoch 1 #6300 -- loss: 0.0703323560487479, acc: 0.97125\n","Epoch 1 #6350 -- loss: 0.09926489233970642, acc: 0.97\n","Epoch 1 #6400 -- loss: 0.07907632714603097, acc: 0.9675\n","Epoch 1 #6450 -- loss: 0.058545222138054666, acc: 0.97875\n","Epoch 1 #6500 -- loss: 0.052042433724272995, acc: 0.98\n","Epoch 1 #6550 -- loss: 0.09633762624813244, acc: 0.96375\n","Epoch 1 #6600 -- loss: 0.04465776174212806, acc: 0.98375\n","Epoch 1 #6650 -- loss: 0.07739021205808967, acc: 0.97625\n","Epoch 1 #6700 -- loss: 0.06410155853256583, acc: 0.97375\n","Epoch 1 #6750 -- loss: 0.058592229057103394, acc: 0.97375\n","Epoch 1 #6800 -- loss: 0.06499529508757405, acc: 0.97625\n","Epoch 1 #6850 -- loss: 0.06392232458572834, acc: 0.97625\n","Epoch 1 #6900 -- loss: 0.05954597549047321, acc: 0.98\n","Epoch 1 #6950 -- loss: 0.07038630291586742, acc: 0.97375\n","Epoch 1 #7000 -- loss: 0.04355309264501557, acc: 0.98375\n","Epoch 1 #7050 -- loss: 0.06960276702651753, acc: 0.9725\n","Epoch 1 #7100 -- loss: 0.06700144627131521, acc: 0.97375\n","Epoch 1 #7150 -- loss: 0.07819395075784996, acc: 0.9675\n","Epoch 1 #7200 -- loss: 0.06917741138255223, acc: 0.9775\n","Epoch 1 #7250 -- loss: 0.035827563831117, acc: 0.9875\n","Epoch 1 #7300 -- loss: 0.053040791761595756, acc: 0.98375\n","Epoch 1 #7350 -- loss: 0.06282221868517808, acc: 0.9775\n","Epoch 1 #7400 -- loss: 0.06926255287835374, acc: 0.98\n","Epoch 1 #7450 -- loss: 0.056765932640992105, acc: 0.98375\n","Epoch 1 #7500 -- loss: 0.05351248583057895, acc: 0.9825\n","Epoch 1 #7550 -- loss: 0.04933012124849483, acc: 0.9825\n","Epoch 1 #7600 -- loss: 0.05657181318616494, acc: 0.97625\n","Epoch 1 #7650 -- loss: 0.06165963304927573, acc: 0.9825\n","Epoch 1 #7700 -- loss: 0.049977324786596, acc: 0.985\n","Epoch 1 #7750 -- loss: 0.051460980563424526, acc: 0.98125\n","Epoch 1 #7800 -- loss: 0.041102762748487294, acc: 0.98625\n","Epoch 1 #7850 -- loss: 0.04390285821515136, acc: 0.98625\n","Epoch 1 #7900 -- loss: 0.06197952263290062, acc: 0.975\n","Epoch 1 #7950 -- loss: 0.04501509757945314, acc: 0.98125\n","Epoch 1 #8000 -- loss: 0.06097432727343403, acc: 0.97625\n","Epoch 1 #8050 -- loss: 0.04747171902796254, acc: 0.985\n","Epoch 1 #8100 -- loss: 0.05284689134685323, acc: 0.98125\n","Epoch 1 #8150 -- loss: 0.07312183415750041, acc: 0.9775\n","Epoch 1 #8200 -- loss: 0.03642905850196257, acc: 0.9875\n","Epoch 1 #8250 -- loss: 0.07247878219466657, acc: 0.98125\n","Epoch 1 #8300 -- loss: 0.05867440769448876, acc: 0.98\n","Epoch 1 #8350 -- loss: 0.05968125270446763, acc: 0.9775\n","Epoch 1 #8400 -- loss: 0.049690693222219126, acc: 0.98\n","Epoch 1 #8450 -- loss: 0.08751829131040723, acc: 0.97375\n","Epoch 1 #8500 -- loss: 0.0602284666383639, acc: 0.98\n","Epoch 1 #8550 -- loss: 0.04594860326615162, acc: 0.98125\n","Epoch 1 #8600 -- loss: 0.051886433316394684, acc: 0.98375\n","Epoch 1 #8650 -- loss: 0.04375190276419744, acc: 0.98125\n","Epoch 1 #8700 -- loss: 0.07052159014856443, acc: 0.98\n","Epoch 1 #8750 -- loss: 0.07500757581088692, acc: 0.97625\n","Epoch 1 #8800 -- loss: 0.047663767869817096, acc: 0.985\n","Epoch 1 #8850 -- loss: 0.04163710360822734, acc: 0.985\n","Epoch 1 #8900 -- loss: 0.05925353173282929, acc: 0.975\n","Epoch 1 #8950 -- loss: 0.06765503762289882, acc: 0.9775\n","Epoch 1 #9000 -- loss: 0.048314876370131966, acc: 0.9825\n","Epoch 1 #9050 -- loss: 0.03716875395388342, acc: 0.98875\n","Epoch 1 #9100 -- loss: 0.041434609005227684, acc: 0.98875\n","Epoch 1 #9150 -- loss: 0.04012409542337991, acc: 0.985\n","Epoch 1 #9200 -- loss: 0.057685506069101396, acc: 0.9775\n","Epoch 1 #9250 -- loss: 0.05662379779852927, acc: 0.97625\n","Epoch 1 #9300 -- loss: 0.06870386324473657, acc: 0.975\n","Epoch 1 #9350 -- loss: 0.037750354140880515, acc: 0.9875\n","Epoch 1 #9400 -- loss: 0.07210047363420018, acc: 0.97375\n","Epoch 1 #9450 -- loss: 0.05262636931147426, acc: 0.97875\n","Epoch 1 #9500 -- loss: 0.04808030563173816, acc: 0.985\n","Epoch 1 #9550 -- loss: 0.055251229098066686, acc: 0.98\n","Epoch 1 #9600 -- loss: 0.050447559668682515, acc: 0.98375\n","Epoch 1 #9650 -- loss: 0.04806119423592463, acc: 0.98125\n","Epoch 1 #9700 -- loss: 0.05192478431155905, acc: 0.98875\n","Epoch 1 #9750 -- loss: 0.03688377006212249, acc: 0.985\n","Epoch 1 #9800 -- loss: 0.056998250733595344, acc: 0.975\n","Epoch 1 #9850 -- loss: 0.030971328852465375, acc: 0.9925\n","Epoch 1 #9900 -- loss: 0.06252898192731664, acc: 0.985\n","Epoch 1 #9950 -- loss: 0.053311869790777566, acc: 0.98125\n","Epoch 1 #10000 -- loss: 0.04071323088835925, acc: 0.98875\n","Epoch 1 #10050 -- loss: 0.06761227163369768, acc: 0.9775\n","Epoch 1 #10100 -- loss: 0.051385149331763386, acc: 0.98\n","Epoch 1 #10150 -- loss: 0.05811985094565898, acc: 0.98\n","Epoch 1 #10200 -- loss: 0.08032211771700531, acc: 0.9725\n","Epoch 1 #10250 -- loss: 0.05407943496480584, acc: 0.9775\n","Epoch 1 #10300 -- loss: 0.03260298731154762, acc: 0.98625\n","Epoch 1 #10350 -- loss: 0.05039162819972262, acc: 0.98375\n","Epoch 1 #10400 -- loss: 0.04648971625836566, acc: 0.98375\n","Epoch 1 #10450 -- loss: 0.05510342312976718, acc: 0.98\n","Epoch 1 #10500 -- loss: 0.050949072992661965, acc: 0.98\n","Epoch 1 #10550 -- loss: 0.032841303806053476, acc: 0.98625\n","Epoch 1 #10600 -- loss: 0.045984973369631914, acc: 0.9825\n","Epoch 1 #10650 -- loss: 0.052241402622312305, acc: 0.98\n","Epoch 1 #10700 -- loss: 0.06659531435929239, acc: 0.97375\n","Epoch 1 #10750 -- loss: 0.05123340055870358, acc: 0.9825\n","Epoch 1 #10800 -- loss: 0.06786882084328681, acc: 0.9775\n","Epoch 1 #10850 -- loss: 0.036484916670015084, acc: 0.98125\n","Epoch 1 #10900 -- loss: 0.042274305053288115, acc: 0.98\n","Epoch 1 #10950 -- loss: 0.05767821932095103, acc: 0.98375\n","Epoch 1 #11000 -- loss: 0.0566816962370649, acc: 0.98375\n","Epoch 1 #11050 -- loss: 0.035971235998440536, acc: 0.98625\n","Epoch 1 #11100 -- loss: 0.0353938170557376, acc: 0.9875\n","Epoch 1 #11150 -- loss: 0.04884870180510916, acc: 0.9875\n","Epoch 1 #11200 -- loss: 0.04556304243393242, acc: 0.98125\n","Epoch 1 #11250 -- loss: 0.04074206378078088, acc: 0.9825\n","Epoch 1 #11300 -- loss: 0.04264955365215428, acc: 0.98375\n","Epoch 1 #11350 -- loss: 0.05958517777267844, acc: 0.9775\n","Epoch 1 #11400 -- loss: 0.04411414772970602, acc: 0.98375\n","Epoch 1 #11450 -- loss: 0.05572029848350212, acc: 0.98125\n","Epoch 1 #11500 -- loss: 0.05429712331388146, acc: 0.9825\n","Epoch 1 #11550 -- loss: 0.04855242728255689, acc: 0.98125\n","Epoch 1 #11600 -- loss: 0.047337694065645336, acc: 0.98125\n","Epoch 1 #11650 -- loss: 0.04342868959472981, acc: 0.98\n","Epoch 1 #11700 -- loss: 0.08740059203468263, acc: 0.97625\n","Epoch 1 #11750 -- loss: 0.03891025507589802, acc: 0.9875\n","Epoch 1 #11800 -- loss: 0.06258908831514418, acc: 0.97625\n","Epoch 1 #11850 -- loss: 0.056601575724780556, acc: 0.98125\n","Epoch 1 #11900 -- loss: 0.04617899381206371, acc: 0.985\n","Epoch 1 #11950 -- loss: 0.045231021771905945, acc: 0.98375\n","Epoch 1 #12000 -- loss: 0.05008894261904061, acc: 0.98\n","Epoch 1 #12050 -- loss: 0.05733354260097258, acc: 0.98\n","Epoch 1 #12100 -- loss: 0.03738605879480019, acc: 0.98625\n","Epoch 1 #12150 -- loss: 0.04649708682554774, acc: 0.98\n","Epoch 1 #12200 -- loss: 0.07660490842536091, acc: 0.9775\n","Epoch 1 #12250 -- loss: 0.04636650234926492, acc: 0.985\n","Epoch 1 #12300 -- loss: 0.04259383672382683, acc: 0.9875\n","Epoch 1 #12350 -- loss: 0.04361604321282357, acc: 0.98375\n","Epoch 1 #12400 -- loss: 0.037305191978230144, acc: 0.98875\n","Epoch 1 #12450 -- loss: 0.03732104818336666, acc: 0.99\n","Epoch 1 #12500 -- loss: 0.033983621728839356, acc: 0.98875\n","Epoch 1 #12550 -- loss: 0.056352663801517336, acc: 0.98125\n","Epoch 1 #12600 -- loss: 0.033058994414750485, acc: 0.9825\n","Epoch 1 #12650 -- loss: 0.04086942427384201, acc: 0.98875\n","Epoch 1 #12700 -- loss: 0.047277164357365106, acc: 0.97875\n","Epoch 1 #12750 -- loss: 0.05685134010389447, acc: 0.97625\n","Epoch 1 #12800 -- loss: 0.03659592612530105, acc: 0.99125\n","Epoch 1 #12850 -- loss: 0.015924561911961062, acc: 0.995\n","Epoch 1 #12900 -- loss: 0.05321550281252712, acc: 0.98375\n","Epoch 1 #12950 -- loss: 0.04254445030470379, acc: 0.9875\n","Epoch 1 #13000 -- loss: 0.029417744957027026, acc: 0.99\n","Epoch 1 #13050 -- loss: 0.044760218646842986, acc: 0.985\n","Epoch 1 #13100 -- loss: 0.03259554597898386, acc: 0.99\n","Epoch 1 #13150 -- loss: 0.02023277503438294, acc: 0.99375\n","Epoch 1 #13200 -- loss: 0.020881266276119276, acc: 0.99375\n","Epoch 1 #13250 -- loss: 0.047023483923403546, acc: 0.985\n","Epoch 1 #13300 -- loss: 0.02787118206906598, acc: 0.98875\n","Epoch 1 #13350 -- loss: 0.0447793424554402, acc: 0.9825\n","Epoch 1 #13400 -- loss: 0.04722631867043674, acc: 0.98125\n","Epoch 1 #13450 -- loss: 0.06551919759716839, acc: 0.97375\n","Epoch 1 #13500 -- loss: 0.04599676484765951, acc: 0.98\n","Epoch 1 #13550 -- loss: 0.043985497712274085, acc: 0.98375\n","Epoch 1 #13600 -- loss: 0.03753055305103772, acc: 0.985\n","Epoch 1 #13650 -- loss: 0.04098342682642397, acc: 0.99125\n","Epoch 1 #13700 -- loss: 0.04862971385475248, acc: 0.985\n","Epoch 1 #13750 -- loss: 0.05102484398055822, acc: 0.98\n","Epoch 1 #13800 -- loss: 0.04124681335873902, acc: 0.98625\n","Epoch 1 #13850 -- loss: 0.029498875514836983, acc: 0.9925\n","Epoch 1 #13900 -- loss: 0.03725080159958452, acc: 0.98625\n","Epoch 1 #13950 -- loss: 0.040861632207524964, acc: 0.98625\n","Epoch 1 #14000 -- loss: 0.041966441308613864, acc: 0.9825\n","Epoch 1 #14050 -- loss: 0.02582552419276908, acc: 0.9925\n","Epoch 1 #14100 -- loss: 0.0385848586197244, acc: 0.98875\n","Epoch 1 #14150 -- loss: 0.044214379808399824, acc: 0.98625\n","Epoch 1 #14200 -- loss: 0.020521273650228978, acc: 0.99375\n","Epoch 1 #14250 -- loss: 0.042303274410660376, acc: 0.98375\n","Epoch 1 #14300 -- loss: 0.03702508590416983, acc: 0.98875\n","Epoch 1 #14350 -- loss: 0.04812163015885744, acc: 0.9875\n","Epoch 1 #14400 -- loss: 0.041843929837923496, acc: 0.98125\n","Epoch 1 #14450 -- loss: 0.03356249236618169, acc: 0.985\n","Epoch 1 #14500 -- loss: 0.05049173141887877, acc: 0.98375\n","Epoch 1 #14550 -- loss: 0.025179341435432434, acc: 0.9925\n","Epoch 1 #14600 -- loss: 0.04014799195458181, acc: 0.98375\n","Epoch 1 #14650 -- loss: 0.028647839462500997, acc: 0.9925\n","Epoch 1 #14700 -- loss: 0.03500087431282736, acc: 0.99\n","Epoch 1 #14750 -- loss: 0.07058906225021928, acc: 0.9725\n","Epoch 1 #14800 -- loss: 0.06624663080903702, acc: 0.9725\n","Epoch 1 #14850 -- loss: 0.024829204363049938, acc: 0.99\n","Epoch 1 #14900 -- loss: 0.030606519965804182, acc: 0.98875\n","Epoch 1 #14950 -- loss: 0.06464152825705241, acc: 0.98125\n","Epoch 1 #15000 -- loss: 0.03775131165981293, acc: 0.9875\n","Epoch 1 #15050 -- loss: 0.04309974488103762, acc: 0.98375\n","Epoch 1 #15100 -- loss: 0.04350892567890696, acc: 0.985\n","Epoch 1 #15150 -- loss: 0.053200207726331425, acc: 0.98625\n","Epoch 1 #15200 -- loss: 0.04004226415068843, acc: 0.985\n","Epoch 1 #15250 -- loss: 0.04136538555147126, acc: 0.985\n","Epoch 1 #15300 -- loss: 0.05223539121681824, acc: 0.98\n","Epoch 1 #15350 -- loss: 0.05136733683000785, acc: 0.98375\n","Epoch 1 #15400 -- loss: 0.05430221929680556, acc: 0.97625\n","Epoch 1 #15450 -- loss: 0.0340336289210245, acc: 0.98375\n","Epoch 1 #15500 -- loss: 0.026770955817773938, acc: 0.98875\n","Epoch 1 #15550 -- loss: 0.06281276958761736, acc: 0.98125\n","Epoch 1 #15600 -- loss: 0.04487398147350177, acc: 0.9825\n","Epoch 1 #15650 -- loss: 0.03972197546390817, acc: 0.98375\n","Epoch 1 #15700 -- loss: 0.03595398955512792, acc: 0.98375\n","Epoch 1 #15750 -- loss: 0.0434674594172975, acc: 0.98625\n","Epoch 1 #15800 -- loss: 0.026851474832510575, acc: 0.99\n","Epoch 1 #15850 -- loss: 0.04416526112880092, acc: 0.9825\n","Epoch 1 #15900 -- loss: 0.03420831325056497, acc: 0.985\n","Epoch 1 #15950 -- loss: 0.04968615953228436, acc: 0.98\n","Epoch 1 #16000 -- loss: 0.0608654421265237, acc: 0.97875\n","Epoch 1 #16050 -- loss: 0.02798101452062838, acc: 0.99\n","Epoch 1 #16100 -- loss: 0.04379449047613889, acc: 0.98375\n","Epoch 1 #16150 -- loss: 0.024301317675272004, acc: 0.99\n","Epoch 1 #16200 -- loss: 0.06613449912809301, acc: 0.9775\n","Epoch 1 #16250 -- loss: 0.027038520561764017, acc: 0.9925\n","Epoch 1 #16300 -- loss: 0.02721543441992253, acc: 0.9925\n","Epoch 1 #16350 -- loss: 0.041558754497673364, acc: 0.98375\n","Epoch 1 #16400 -- loss: 0.047873846474685705, acc: 0.98625\n","Epoch 1 #16450 -- loss: 0.03172624244063627, acc: 0.98875\n","Epoch 1 #16500 -- loss: 0.024808948891586625, acc: 0.99\n","Epoch 1 #16550 -- loss: 0.04717880452342797, acc: 0.98\n","Epoch 1 #16600 -- loss: 0.024869042377686126, acc: 0.9875\n","Epoch 1 #16650 -- loss: 0.02028220084379427, acc: 0.99125\n","Epoch 1 #16700 -- loss: 0.023817598404129968, acc: 0.99\n","Epoch 1 #16750 -- loss: 0.05285054951440543, acc: 0.9825\n","Epoch 1 #16800 -- loss: 0.01882442535716109, acc: 0.995\n","Epoch 1 #16850 -- loss: 0.02091814565821551, acc: 0.99125\n","Epoch 1 #16900 -- loss: 0.04333622912759893, acc: 0.9825\n","Epoch 1 #16950 -- loss: 0.02836971818411257, acc: 0.98875\n","Epoch 1 #17000 -- loss: 0.04187877182906959, acc: 0.985\n","Epoch 1 #17050 -- loss: 0.04110810389509425, acc: 0.985\n","Epoch 1 #17100 -- loss: 0.04042134073213674, acc: 0.985\n","Epoch 1 #17150 -- loss: 0.03322054628515616, acc: 0.98625\n","Epoch 1 #17200 -- loss: 0.03842022504890338, acc: 0.98375\n","Epoch 1 #17250 -- loss: 0.03868276224588044, acc: 0.9875\n","Epoch 1 #17300 -- loss: 0.030132531910203396, acc: 0.98875\n","Epoch 1 #17350 -- loss: 0.039887955723679626, acc: 0.98625\n","Epoch 1 #17400 -- loss: 0.04711457809433341, acc: 0.98375\n","Epoch 1 #17450 -- loss: 0.035796188780805094, acc: 0.99\n","Epoch 1 #17500 -- loss: 0.02613730326120276, acc: 0.99\n","Epoch 1 #17550 -- loss: 0.03781077698804438, acc: 0.9875\n","Epoch 1 #17600 -- loss: 0.030458090275060384, acc: 0.99\n","Epoch 1 #17650 -- loss: 0.0488306889636442, acc: 0.9825\n","Epoch 1 #17700 -- loss: 0.03001573614310473, acc: 0.9925\n","Epoch 1 #17750 -- loss: 0.0491651745303534, acc: 0.98\n","Epoch 1 #17800 -- loss: 0.054720228404621596, acc: 0.98\n","Epoch 1 #17850 -- loss: 0.014660878196591511, acc: 0.9975\n","Epoch 1 #17900 -- loss: 0.047407826303387995, acc: 0.9825\n","Epoch 1 #17950 -- loss: 0.02921470661996864, acc: 0.9925\n","Epoch 1 #18000 -- loss: 0.05036725374753587, acc: 0.9825\n","Epoch 1 #18050 -- loss: 0.03742542403982952, acc: 0.98625\n","Epoch 1 #18100 -- loss: 0.030390954581089317, acc: 0.98375\n","Epoch 1 #18150 -- loss: 0.03003292034554761, acc: 0.9925\n","Epoch 1 #18200 -- loss: 0.037334596704458815, acc: 0.9875\n","Epoch 1 #18250 -- loss: 0.04161962768062949, acc: 0.99125\n","Epoch 1 #18300 -- loss: 0.05286901394603774, acc: 0.985\n","Epoch 1 #18350 -- loss: 0.03984866812708788, acc: 0.98375\n","Epoch 1 #18400 -- loss: 0.024461320021655412, acc: 0.99\n","Epoch 1 #18450 -- loss: 0.027344940250040962, acc: 0.99125\n","Epoch 1 #18500 -- loss: 0.02637089279363863, acc: 0.99375\n","Epoch 1 #18550 -- loss: 0.02372854701068718, acc: 0.99125\n","Epoch 1 #18600 -- loss: 0.03617353998648468, acc: 0.98625\n","Epoch 1 #18650 -- loss: 0.03472347009985242, acc: 0.98625\n","Epoch 1 #18700 -- loss: 0.021434082300402224, acc: 0.98875\n","Epoch 1 #18750 -- loss: 0.03506606426730286, acc: 0.99125\n","Epoch 1 #18800 -- loss: 0.03867704624164617, acc: 0.9875\n","Epoch 1 #18850 -- loss: 0.03998148864950053, acc: 0.9875\n","Epoch 1 #18900 -- loss: 0.05586361053632572, acc: 0.985\n","Epoch 1 #18950 -- loss: 0.04007128793979064, acc: 0.9825\n","Epoch 1 #19000 -- loss: 0.03520005507220048, acc: 0.98875\n","Epoch 1 #19050 -- loss: 0.028920459529035724, acc: 0.99\n","Epoch 1 #19100 -- loss: 0.02792145192855969, acc: 0.9875\n","Epoch 1 #19150 -- loss: 0.05251223260245751, acc: 0.98\n","Epoch 1 #19200 -- loss: 0.03587212458543945, acc: 0.98375\n","Epoch 1 #19250 -- loss: 0.026894059224869125, acc: 0.9875\n","Epoch 1 #19300 -- loss: 0.02155241073574871, acc: 0.99375\n","Epoch 1 #19350 -- loss: 0.027411996173032093, acc: 0.99125\n","Epoch 1 #19400 -- loss: 0.024609614692744797, acc: 0.99\n","Epoch 1 #19450 -- loss: 0.03749071119877044, acc: 0.98375\n","Epoch 1 #19500 -- loss: 0.0197025106404908, acc: 0.99\n","Epoch 1 #19550 -- loss: 0.014642658027878497, acc: 0.99625\n","Epoch 1 #19600 -- loss: 0.032369351687084415, acc: 0.9875\n","Epoch 1 #19650 -- loss: 0.03878862597135594, acc: 0.98875\n","Epoch 1 #19700 -- loss: 0.03378382226597751, acc: 0.99\n","Epoch 1 #19750 -- loss: 0.017391678335843607, acc: 0.995\n","Epoch 1 #19800 -- loss: 0.03856468459009193, acc: 0.98625\n","Epoch 1 #19850 -- loss: 0.032073313893633895, acc: 0.98875\n","Epoch 1 #19900 -- loss: 0.02912202127627097, acc: 0.98625\n","Epoch 1 #19950 -- loss: 0.025306236523319967, acc: 0.9925\n","Epoch 1 #20000 -- loss: 0.03399175706697861, acc: 0.985\n","Epoch 1 #20050 -- loss: 0.029835692442720756, acc: 0.98625\n","Epoch 1 #20100 -- loss: 0.030272543360479177, acc: 0.98625\n","Epoch 1 #20150 -- loss: 0.021328652263327967, acc: 0.99\n","Epoch 1 #20200 -- loss: 0.03666882661054842, acc: 0.985\n","Epoch 1 #20250 -- loss: 0.02981995745038148, acc: 0.9925\n","Epoch 1 #20300 -- loss: 0.04291970063350163, acc: 0.98875\n","Epoch 1 #20350 -- loss: 0.015169648852897809, acc: 0.99625\n","Epoch 1 #20400 -- loss: 0.033040794431581165, acc: 0.99\n","Epoch 1 #20450 -- loss: 0.013380508523550817, acc: 0.99625\n","Epoch 1 #20500 -- loss: 0.049411180666647854, acc: 0.985\n","Epoch 1 #20550 -- loss: 0.040465804303530604, acc: 0.985\n","Epoch 1 #20600 -- loss: 0.038174566400120964, acc: 0.98875\n","Epoch 1 #20650 -- loss: 0.03984852351015434, acc: 0.98625\n","Epoch 1 #20700 -- loss: 0.04633995175012387, acc: 0.98125\n","Epoch 1 #20750 -- loss: 0.03337725168210454, acc: 0.9875\n","Epoch 1 #20800 -- loss: 0.02616414050629828, acc: 0.985\n","Epoch 1 #20850 -- loss: 0.017320511782891117, acc: 0.995\n","Epoch 1 #20900 -- loss: 0.0452877196969348, acc: 0.99\n","Epoch 1 #20950 -- loss: 0.01629963489394868, acc: 0.9925\n","Epoch 1 #21000 -- loss: 0.04035287267528474, acc: 0.98875\n","Epoch 1 #21050 -- loss: 0.016067892538267188, acc: 0.995\n","Epoch 1 #21100 -- loss: 0.03417431474110345, acc: 0.9875\n","Epoch 1 #21150 -- loss: 0.024019470871426165, acc: 0.99125\n","Epoch 1 #21200 -- loss: 0.029340279449825174, acc: 0.99\n","Epoch 1 #21250 -- loss: 0.01718528981145937, acc: 0.995\n","Epoch 1 #21300 -- loss: 0.028305914910743014, acc: 0.9925\n","Epoch 1 #21350 -- loss: 0.03311629967123736, acc: 0.9925\n","Epoch 1 #21400 -- loss: 0.026614741079392844, acc: 0.98875\n","Epoch 1 #21450 -- loss: 0.047423121042083946, acc: 0.985\n","Epoch 1 #21500 -- loss: 0.036093798379879444, acc: 0.9875\n","Epoch 1 #21550 -- loss: 0.041201881610322746, acc: 0.98875\n","Epoch 1 #21600 -- loss: 0.022100792191922666, acc: 0.9925\n","Epoch 1 #21650 -- loss: 0.03099350231641438, acc: 0.98875\n","Epoch 1 #21700 -- loss: 0.028903548944508656, acc: 0.99\n","Epoch 1 #21750 -- loss: 0.04426922786049545, acc: 0.98375\n","Epoch 1 #21800 -- loss: 0.03206554000498727, acc: 0.9925\n","Epoch 1 #21850 -- loss: 0.03200749531504698, acc: 0.98875\n","Epoch 1 #21900 -- loss: 0.031338828374864534, acc: 0.98625\n","Epoch 1 #21950 -- loss: 0.05900417417404242, acc: 0.97625\n","Epoch 1 #22000 -- loss: 0.05246456799563021, acc: 0.985\n","Epoch 1 #22050 -- loss: 0.037572878297651185, acc: 0.9875\n","Epoch 1 #22100 -- loss: 0.01748284404457081, acc: 0.99125\n","Epoch 1 #22150 -- loss: 0.019860274603124707, acc: 0.99625\n","Epoch 1 #22200 -- loss: 0.02885809059778694, acc: 0.99\n","Epoch 1 #22250 -- loss: 0.03744271270377794, acc: 0.99125\n","Epoch 1 #22300 -- loss: 0.023726418756414205, acc: 0.995\n","Epoch 1 #22350 -- loss: 0.04506574952683877, acc: 0.98\n","Epoch 1 #22400 -- loss: 0.02648022575653158, acc: 0.98875\n","Epoch 1 #22450 -- loss: 0.03271047819958767, acc: 0.98625\n","Epoch 1 #22500 -- loss: 0.029353438996186015, acc: 0.98875\n","Epoch 1 #22550 -- loss: 0.0366805174772162, acc: 0.99\n","Epoch 1 #22600 -- loss: 0.02742616712115705, acc: 0.99125\n","Epoch 1 #22650 -- loss: 0.03601423305692151, acc: 0.985\n","Epoch 1 #22700 -- loss: 0.02563668800808955, acc: 0.99\n","Epoch 1 #22750 -- loss: 0.03077618939219974, acc: 0.9875\n","Epoch 1 #22800 -- loss: 0.03018011197913438, acc: 0.99125\n","Epoch 1 #22850 -- loss: 0.03125537953339517, acc: 0.99125\n","Epoch 1 #22900 -- loss: 0.023891664452385157, acc: 0.99125\n","Epoch 1 #22950 -- loss: 0.014138533370569348, acc: 0.99625\n","Epoch 1 #23000 -- loss: 0.016588404810463545, acc: 0.99375\n","Epoch 1 #23050 -- loss: 0.0487621036649216, acc: 0.98125\n","Epoch 1 #23100 -- loss: 0.027139309840276838, acc: 0.99125\n","Epoch 1 #23150 -- loss: 0.03152519449213287, acc: 0.9925\n","Epoch 1 #23200 -- loss: 0.0193348830632749, acc: 0.99375\n","Epoch 1 #23250 -- loss: 0.030534026313107462, acc: 0.9875\n","Epoch 1 #23300 -- loss: 0.043320165562909095, acc: 0.98375\n","Epoch 1 #23350 -- loss: 0.017172680200310424, acc: 0.9925\n","Epoch 1 #23400 -- loss: 0.026647391849255655, acc: 0.99125\n","Epoch 1 #23450 -- loss: 0.03915809669648297, acc: 0.9875\n","Epoch 1 #23500 -- loss: 0.03568307149456814, acc: 0.98875\n","Epoch 1 #23550 -- loss: 0.04192249701998662, acc: 0.9875\n","Epoch 1 #23600 -- loss: 0.028646474808920176, acc: 0.98875\n","Epoch 1 #23650 -- loss: 0.028835597611032427, acc: 0.99375\n","Epoch 1 #23700 -- loss: 0.026875616292236372, acc: 0.99375\n","Epoch 1 #23750 -- loss: 0.03673999748658389, acc: 0.9925\n","Epoch 1 #23800 -- loss: 0.026571770408190788, acc: 0.98875\n","Epoch 1 #23850 -- loss: 0.039803266855888066, acc: 0.985\n","Epoch 1 #23900 -- loss: 0.05040184842888266, acc: 0.9825\n","Epoch 1 #23950 -- loss: 0.03231836541206576, acc: 0.99\n","Epoch 1 #24000 -- loss: 0.03841369125875645, acc: 0.985\n","Epoch 1 #24050 -- loss: 0.024379415708826856, acc: 0.98875\n","Epoch 1 #24100 -- loss: 0.044738047114224175, acc: 0.985\n","Epoch 1 #24150 -- loss: 0.016163862447137946, acc: 0.995\n","Epoch 1 #24200 -- loss: 0.027518698899075388, acc: 0.98875\n","Epoch 1 #24250 -- loss: 0.02597453414753545, acc: 0.99\n","Epoch 1 #24300 -- loss: 0.023153931976121384, acc: 0.99125\n","Epoch 1 #24350 -- loss: 0.027350822967418933, acc: 0.99\n","Epoch 1 #24400 -- loss: 0.029941727060067935, acc: 0.995\n","Epoch 1 #24450 -- loss: 0.04930922777857631, acc: 0.985\n","Epoch 1 #24500 -- loss: 0.020469422518508508, acc: 0.99125\n","Epoch 1 #24550 -- loss: 0.035060199876315895, acc: 0.99\n","Epoch 1 #24600 -- loss: 0.033137198325712235, acc: 0.98625\n","Epoch 1 #24650 -- loss: 0.02505772909265943, acc: 0.98875\n","Epoch 1 #24700 -- loss: 0.03493351902870927, acc: 0.98875\n","Epoch 1 #24750 -- loss: 0.0402060410019476, acc: 0.98625\n","Epoch 1 #24800 -- loss: 0.014037310825951863, acc: 0.9975\n","Epoch 1 #24850 -- loss: 0.01770698569715023, acc: 0.9925\n","Epoch 1 #24900 -- loss: 0.02835361275705509, acc: 0.99\n","Epoch 1 #24950 -- loss: 0.0251888021430932, acc: 0.995\n","Epoch 1 #25000 -- loss: 0.024357440969033632, acc: 0.99125\n","Epoch 1 #25050 -- loss: 0.014255213140859268, acc: 0.99625\n","Epoch 1 #25100 -- loss: 0.01262462439830415, acc: 0.995\n","Epoch 1 #25150 -- loss: 0.022506676789780612, acc: 0.99375\n","Epoch 1 #25200 -- loss: 0.02507502366497647, acc: 0.9925\n","Epoch 1 #25250 -- loss: 0.03108308658323949, acc: 0.99125\n","Epoch 1 #25300 -- loss: 0.023128449019568505, acc: 0.9925\n","Epoch 1 #25350 -- loss: 0.02084795948874671, acc: 0.99375\n","Epoch 1 #25400 -- loss: 0.04515057255688589, acc: 0.9875\n","Epoch 1 #25450 -- loss: 0.03389304630632978, acc: 0.99125\n","Epoch 1 #25500 -- loss: 0.011499712649383582, acc: 0.99625\n","Epoch 1 #25550 -- loss: 0.025173908455763012, acc: 0.9875\n","Epoch 1 #25600 -- loss: 0.02616928159550298, acc: 0.995\n","Epoch 1 #25650 -- loss: 0.03750728890125174, acc: 0.98625\n","Epoch 1 #25700 -- loss: 0.024921261246781796, acc: 0.99\n","Epoch 1 #25750 -- loss: 0.0353509849193506, acc: 0.98625\n","Epoch 1 #25800 -- loss: 0.0264795248163864, acc: 0.99\n","Epoch 1 #25850 -- loss: 0.02385886271367781, acc: 0.98875\n","Epoch 1 #25900 -- loss: 0.016787719955900685, acc: 0.9925\n","Epoch 1 #25950 -- loss: 0.03757810141280061, acc: 0.99\n","Epoch 1 #26000 -- loss: 0.034077502336585894, acc: 0.9875\n","Epoch 1 #26050 -- loss: 0.035558456243015825, acc: 0.985\n","Epoch 1 #26100 -- loss: 0.03542779901530593, acc: 0.9875\n","Epoch 1 #26150 -- loss: 0.03129274085193174, acc: 0.9925\n","Epoch 1 #26200 -- loss: 0.011658152228919789, acc: 0.99375\n","Epoch 1 #26250 -- loss: 0.026334695821278727, acc: 0.99375\n","Epoch 1 #26300 -- loss: 0.01728862103773281, acc: 0.99375\n","Epoch 1 #26350 -- loss: 0.008373556503211149, acc: 0.9975\n","Epoch 1 #26400 -- loss: 0.04458191656362032, acc: 0.98375\n","Epoch 1 #26450 -- loss: 0.029669640710926613, acc: 0.99\n","Epoch 1 #26500 -- loss: 0.03277192525973078, acc: 0.99125\n","Epoch 1 #26550 -- loss: 0.022352605651249177, acc: 0.99\n","Epoch 1 #26600 -- loss: 0.017531871205719654, acc: 0.995\n","Epoch 1 #26650 -- loss: 0.04528321482473984, acc: 0.98625\n","Epoch 1 #26700 -- loss: 0.014773632044962142, acc: 0.99125\n","Epoch 1 #26750 -- loss: 0.024618578467925544, acc: 0.99375\n","Epoch 1 #26800 -- loss: 0.025414964191731997, acc: 0.9875\n","Epoch 1 #26850 -- loss: 0.02898092109680874, acc: 0.99\n","Epoch 1 #26900 -- loss: 0.014537050475773867, acc: 0.99125\n","Epoch 1 #26950 -- loss: 0.03390584062464768, acc: 0.9875\n","Epoch 1 #27000 -- loss: 0.03149208261427702, acc: 0.9875\n","Epoch 1 #27050 -- loss: 0.04828535644337535, acc: 0.985\n","Epoch 1 #27100 -- loss: 0.021836862749187277, acc: 0.9925\n","Epoch 1 #27150 -- loss: 0.022211721312487498, acc: 0.99375\n","Epoch 1 #27200 -- loss: 0.014929661472851876, acc: 0.9925\n","Epoch 1 #27250 -- loss: 0.02395038029644638, acc: 0.99\n","Epoch 1 #27300 -- loss: 0.047871537547471234, acc: 0.98375\n","Epoch 1 #27350 -- loss: 0.02310860018245876, acc: 0.99375\n","Epoch 1 #27400 -- loss: 0.022515932037204037, acc: 0.99375\n","Epoch 1 #27450 -- loss: 0.0277145459636813, acc: 0.99\n","Epoch 1 #27500 -- loss: 0.013212197055690923, acc: 0.995\n","Epoch 1 #27550 -- loss: 0.020664338572678388, acc: 0.99375\n","Epoch 1 #27600 -- loss: 0.025181258087977765, acc: 0.99\n","Epoch 1 #27650 -- loss: 0.022100147426244804, acc: 0.995\n","Epoch 1 #27700 -- loss: 0.02993729522306239, acc: 0.9875\n","Epoch 1 #27750 -- loss: 0.030117807613569313, acc: 0.98875\n","Epoch 1 #27800 -- loss: 0.030440727850073016, acc: 0.98875\n","Epoch 1 #27850 -- loss: 0.022182317512342706, acc: 0.99125\n","Epoch 1 #27900 -- loss: 0.034899796160607365, acc: 0.9875\n","Epoch 1 #27950 -- loss: 0.026750824264017866, acc: 0.9925\n","Epoch 1 #28000 -- loss: 0.03134951050102245, acc: 0.98625\n","Epoch 1 #28050 -- loss: 0.04029436494747642, acc: 0.9875\n","Epoch 1 #28100 -- loss: 0.022855019028356766, acc: 0.98875\n","Epoch 1 #28150 -- loss: 0.02202475594851421, acc: 0.99125\n","Epoch 1 #28200 -- loss: 0.02239080913786893, acc: 0.99125\n","Epoch 1 #28250 -- loss: 0.027513625326100737, acc: 0.99125\n","Epoch 1 #28300 -- loss: 0.03136070010485128, acc: 0.98875\n","Epoch 1 #28350 -- loss: 0.020265698380244432, acc: 0.995\n","Epoch 1 #28400 -- loss: 0.021901848813140532, acc: 0.99375\n","Epoch 1 #28450 -- loss: 0.03606553155084839, acc: 0.985\n","Epoch 1 #28500 -- loss: 0.009699327273701784, acc: 0.995\n","Epoch 1 #28550 -- loss: 0.025642648220236878, acc: 0.98875\n","Epoch 1 #28600 -- loss: 0.021194440839462914, acc: 0.99125\n","Epoch 1 #28650 -- loss: 0.014462202993454411, acc: 0.99625\n","Epoch 1 #28700 -- loss: 0.017824712324363647, acc: 0.9925\n","Epoch 1 #28750 -- loss: 0.031624331224593336, acc: 0.985\n","Epoch 1 #28800 -- loss: 0.02151110404432984, acc: 0.99625\n","Epoch 1 #28850 -- loss: 0.01939462780894246, acc: 0.99375\n","Epoch 1 #28900 -- loss: 0.023815565538825467, acc: 0.99125\n","Epoch 1 #28950 -- loss: 0.02532049725865363, acc: 0.99\n","Epoch 1 #29000 -- loss: 0.023197575746307847, acc: 0.995\n","Epoch 1 #29050 -- loss: 0.027994050338165835, acc: 0.98875\n","Epoch 1 #29100 -- loss: 0.03358371677197283, acc: 0.98875\n","Epoch 1 #29150 -- loss: 0.016197410955501253, acc: 0.9925\n","Epoch 1 #29200 -- loss: 0.047399465680355204, acc: 0.9825\n","Epoch 1 #29250 -- loss: 0.025707920140703208, acc: 0.99125\n","Epoch 1 #29300 -- loss: 0.019797616762225516, acc: 0.9925\n","Epoch 1 #29350 -- loss: 0.012401669807150028, acc: 0.99625\n","Epoch 1 #29400 -- loss: 0.0169141190587834, acc: 0.99375\n","Epoch 1 #29450 -- loss: 0.023917310310062022, acc: 0.99\n","Epoch 1 #29500 -- loss: 0.046198372139187996, acc: 0.98875\n","Epoch 1 #29550 -- loss: 0.014762917729676701, acc: 0.99625\n","Epoch 1 #29600 -- loss: 0.028464340840873775, acc: 0.99375\n","Epoch 1 #29650 -- loss: 0.023237844501854853, acc: 0.98875\n","Epoch 1 #29700 -- loss: 0.0161213099208544, acc: 0.99375\n","Epoch 1 #29750 -- loss: 0.02955268887570128, acc: 0.99375\n","Epoch 1 #29800 -- loss: 0.030623899048077875, acc: 0.99125\n","Epoch 1 #29850 -- loss: 0.020831217648810706, acc: 0.99\n","Epoch 1 #29900 -- loss: 0.028150424662744627, acc: 0.985\n","Epoch 1 #29950 -- loss: 0.017076080112892668, acc: 0.99625\n","Epoch 1 #30000 -- loss: 0.024141849541338162, acc: 0.995\n","Epoch 1 #30050 -- loss: 0.03484697521227645, acc: 0.98875\n","Epoch 1 #30100 -- loss: 0.015851926625182387, acc: 0.9975\n","Epoch 1 #30150 -- loss: 0.024357886528014204, acc: 0.99\n","Epoch 1 #30200 -- loss: 0.0393579506885726, acc: 0.98625\n","Epoch 1 #30250 -- loss: 0.03159776478423737, acc: 0.9875\n","Epoch 1 #30300 -- loss: 0.02768022234493401, acc: 0.99125\n","Epoch 1 #30350 -- loss: 0.01476900273526553, acc: 0.99375\n","Epoch 1 #30400 -- loss: 0.031411773435829675, acc: 0.9875\n","Epoch 1 #30450 -- loss: 0.029463443354470657, acc: 0.99\n","Epoch 1 #30500 -- loss: 0.03620298139809165, acc: 0.98875\n","Epoch 1 #30550 -- loss: 0.013181811672111507, acc: 0.99375\n","Epoch 1 #30600 -- loss: 0.021221263693878428, acc: 0.99125\n","Epoch 1 #30650 -- loss: 0.016179410667100456, acc: 0.995\n","Epoch 1 #30700 -- loss: 0.0127100883849198, acc: 0.995\n","Epoch 1 #30750 -- loss: 0.03113543746207142, acc: 0.99\n","Epoch 1 #30800 -- loss: 0.026424673251458444, acc: 0.99125\n","Epoch 1 #30850 -- loss: 0.023976444353174885, acc: 0.98875\n","Epoch 1 #30900 -- loss: 0.026307980017445515, acc: 0.99\n","Epoch 1 #30950 -- loss: 0.03158848748047603, acc: 0.99\n","Epoch 1 #31000 -- loss: 0.012470358149148524, acc: 0.99375\n","Epoch 1 #31050 -- loss: 0.03009026194456965, acc: 0.99125\n","Epoch 1 #31100 -- loss: 0.01939504663401749, acc: 0.99125\n","Epoch 1 #31150 -- loss: 0.024370046901749445, acc: 0.9925\n","Epoch 1 #31200 -- loss: 0.041110723958117885, acc: 0.98625\n","Epoch 1 #31250 -- loss: 0.01746080914104823, acc: 0.99375\n","Epoch 1 #31300 -- loss: 0.02957673052616883, acc: 0.9875\n","Epoch 1 #31350 -- loss: 0.012641828783671372, acc: 0.995\n","Epoch 1 #31400 -- loss: 0.03929475337878102, acc: 0.9875\n","Epoch 1 #31450 -- loss: 0.01787924448668491, acc: 0.995\n","Epoch 1 #31500 -- loss: 0.029803822877001947, acc: 0.98625\n","Epoch 1 #31550 -- loss: 0.01974949405703228, acc: 0.99125\n","Epoch 1 #31600 -- loss: 0.019596630903251935, acc: 0.995\n","Epoch 1 #31650 -- loss: 0.027199595666606912, acc: 0.98875\n","Epoch 1 #31700 -- loss: 0.007635236527130473, acc: 1.0\n","Epoch 1 #31750 -- loss: 0.024064527445443674, acc: 0.99\n","Epoch 1 #31800 -- loss: 0.026281058138119987, acc: 0.99375\n","Epoch 1 #31850 -- loss: 0.01812433192622848, acc: 0.99625\n","Epoch 1 #31900 -- loss: 0.019293718981498387, acc: 0.9925\n","Epoch 1 #31950 -- loss: 0.023887255440058652, acc: 0.99625\n","Epoch 1 #32000 -- loss: 0.023578248910489492, acc: 0.99125\n","Epoch 1 #32050 -- loss: 0.017743287565826903, acc: 0.99375\n","Epoch 1 #32100 -- loss: 0.02381578702275874, acc: 0.995\n","Epoch 1 #32150 -- loss: 0.013287175006989855, acc: 0.99375\n","Epoch 1 #32200 -- loss: 0.017692497001844457, acc: 0.99375\n","Epoch 1 #32250 -- loss: 0.01840948737459257, acc: 0.995\n","Epoch 1 #32300 -- loss: 0.019255987409560475, acc: 0.99375\n","Epoch 1 #32350 -- loss: 0.027516855125431904, acc: 0.9925\n","Epoch 1 #32400 -- loss: 0.026747933162841946, acc: 0.9925\n","Epoch 1 #32450 -- loss: 0.01898287957534194, acc: 0.995\n","Epoch 1 #32500 -- loss: 0.024350325626437554, acc: 0.99\n","Epoch 1 #32550 -- loss: 0.023820255465689114, acc: 0.995\n","Epoch 1 #32600 -- loss: 0.016085229060263374, acc: 0.995\n","Epoch 1 #32650 -- loss: 0.02446808819193393, acc: 0.9925\n","Epoch 1 #32700 -- loss: 0.04115505707857665, acc: 0.985\n","Epoch 1 #32750 -- loss: 0.028033994256984444, acc: 0.99125\n","Epoch 1 #32800 -- loss: 0.016851057388994378, acc: 0.99375\n","Epoch 1 #32850 -- loss: 0.029766355013125575, acc: 0.9875\n","Epoch 1 #32900 -- loss: 0.026622287973295897, acc: 0.99375\n","Epoch 1 #32950 -- loss: 0.013367504692287185, acc: 0.995\n","Epoch 1 #33000 -- loss: 0.03050649026466999, acc: 0.99\n","\n","Epoch 1 loss: 0.0535974798091671, acc: 0.9793806818181818\n"]}],"source":["f = 5\n","e = 1\n","\n","print(f\"------------------------------ {f} fold {e} epoch------------------------------\")\n","\n","model.train()\n","epoch_perform, batch_perform = np.zeros(2), np.zeros(2)\n","print()\t\n","progress_bar = tqdm(enumerate(trainloader), total=len(trainloader), leave=True, position=0,)\n","for j, v in progress_bar:\n","  input_ids, attention_mask, labels = v['input_ids'].to(device), v['attention_mask'].to(device), v['labels'].to(device)\n","  \n","  optimizer.zero_grad()\n","  \n","  outputs = model(input_ids, attention_mask) ## label을 안 넣어서 logits값만 출력\n","  output = outputs.logits # The outputs object is a SequenceClassifierOutput\n","  loss = criterion(output, labels)\n","  loss.backward()\n","  optimizer.step()\n","  scheduler.step()\n","  for learning_rate in scheduler.get_lr():\n","    wandb.log({\"learning_rate\": learning_rate})\n","\n","  predict = output.argmax(dim=-1)\n","  predict = predict.detach().cpu().numpy()\n","  labels = labels.detach().cpu().numpy()\n","  acc = accuracy_score(labels, predict)\n","\n","  batch_perform += np.array([loss.item(), acc])\n","  epoch_perform += np.array([loss.item(), acc])\n","\n","  if (j + 1) % 50 == 0:\n","    print(\n","        f\"Epoch {e} #{j + 1} -- loss: {batch_perform[0] / 50}, acc: {batch_perform[1] / 50}\"\n","    )\n","    batch_perform = np.zeros(2)\n","print()\n","print(\n","    f\"Epoch {e} loss: {epoch_perform[0] / total_batch_}, acc: {epoch_perform[1] / total_batch_}\"\n","    )\n","wandb.log({\n","    \"epoch\": e,\n","    \"Train epoch Loss\": epoch_perform[0] / total_batch_,\n","    \"Train epoch Acc\": epoch_perform[1] / total_batch_}\n","    )\n","torch.save(model.state_dict(), f\"./models/{args.model_name}/{f}-fold/train.pt\")"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"t9qFFOiLgHOK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654740928555,"user_tz":-540,"elapsed":2250500,"user":{"displayName":"Lainie Kang","userId":"17932680864583243195"}},"outputId":"9777421b-c8e7-4920-865f-aa85b73ebe4e"},"outputs":[{"output_type":"stream","name":"stdout","text":["New best model for val accuracy : 0.9919469696969697! saving the best model..\n","=============== Fold5 Wrong DataFrame Saved ===============\n","\n",">>>> Validation loss: 0.025486182730782965, Acc: 0.9919469696969697\n","\n","==================================================\n","5fold best_val_acc_list : [0.9919469696969697]\n","=============== 5fold Final Score(ACC) : 0.9919469696969697 ===============\n"]}],"source":["f = 5\n","e = 1\n","best_val_loss, best_val_acc, = np.inf, 0\n","###### Validation\n","load_path = f'./models/{args.model_name}/{f}-fold/train.pt'\n","model.load_state_dict(torch.load(load_path,map_location=device))\n","model.to(device)\n","model.eval()\n","valid_perform = np.zeros(2)\n","\n","all_valid_predict_lst = []\n","all_valid_labels_lst = []\n","\n","# 틀린 데이터들을 wandb 기록하기 위함.\n","wrong_sample_dict = defaultdict(list)\n","\n","with torch.no_grad():\n","    for v in validloader:\n","      input_ids, attention_mask, valid_labels = v[\"input_ids\"].to(device), v[\"attention_mask\"].to(device), v[\"labels\"].to(device)\n","      \n","      valid_outputs = model(input_ids, attention_mask)\n","      valid_output = valid_outputs.logits\n","      valid_loss = criterion(valid_output, valid_labels)\n","      \n","      valid_predict = valid_output.argmax(dim=-1)\n","      valid_predict = valid_predict.detach().cpu().numpy()\n","      valid_labels = valid_labels.detach().cpu().numpy()\n","\n","      ###########################\n","      # valid eval 결과, 틀린 데이터들은 wandb에 Logging\n","      if args.logging_wrong_samples:\n","        wrong_sample_index = np.where(valid_labels!=valid_predict)[0]\n","        if len(wrong_sample_index)>0:\n","          wrong_sample_text, wrong_sample_label, wrong_sample_pred, entailment_prob, contradiction_prob = wrong_batch_for_wandb(tokenizer, wrong_sample_index, input_ids, valid_labels, valid_predict, valid_output)\n","\n","          wrong_sample_dict['입력 코드 Pair'] += wrong_sample_text\n","          wrong_sample_dict['실제값'] += wrong_sample_label\n","          wrong_sample_dict['예측값'] += wrong_sample_pred\n","          wrong_sample_dict['diff_logit'] += entailment_prob\n","          wrong_sample_dict['same_logit'] += contradiction_prob\n","      ###########################\n","\n","      valid_acc = accuracy_score(valid_labels, valid_predict)\n","      valid_perform += np.array([valid_loss.item(), valid_acc])\n","\n","      all_valid_predict_lst += list(valid_predict)\n","      all_valid_labels_lst += list(valid_labels)\n","  \n","###### Model save\n","val_total_loss = valid_perform[0] / valid_batch_\n","val_total_acc = valid_perform[1] / valid_batch_\n","best_val_loss = min(best_val_loss, val_total_loss)\n","\n","\n","if val_total_acc > best_val_acc:\n","    print(f\"New best model for val accuracy : {val_total_acc}! saving the best model..\")\n","    torch.save(model.state_dict(), f\"./models/{args.model_name}/{f}-fold/best.pt\")\n","\n","    # 참고 : Model 추가 재학습을 위한 모델을 저장하는 코드\n","    # https://tutorials.pytorch.kr/beginner/saving_loading_models.html#checkpoint\n","\n","    best_val_acc = val_total_acc\n","\n","    ### Confusion Matrix\n","    class_names = ['diff','same'] # (0,1,2)\n","    # https://wandb.ai/wandb/plots/reports/Confusion-Matrix--VmlldzozMDg1NTM\n","    wandb.log({f\"{e}_epoch_conf_mat\" : wandb.plot.confusion_matrix(probs=None,\n","                                                                      y_true=all_valid_labels_lst, preds=all_valid_predict_lst,\n","                                                                      class_names=class_names)})\n","      \n","    if args.logging_wrong_samples and val_total_acc > 0.91:\n","      ########### Logging Wrong Samples ##########\n","      # Save Wrong DataFrame\n","      wrong_sample_df = pd.DataFrame(wrong_sample_dict)\n","      wrong_sample_df.to_csv(f\"./models/{args.model_name}/{f}-fold/wrong_df.csv\",index=False)\n","      print('='*15,f'Fold{f} Wrong DataFrame Saved','='*15)\n","      # Loggin Wandb\n","      text_table = wandb.Table(data = wrong_sample_df)\n","      run.log({f\"{f}_fold_wrong_samples\" : text_table})\n","      ###########################\n","    \n","print()\n","print(\n","    f\">>>> Validation loss: {val_total_loss}, Acc: {val_total_acc}\"\n","    )\n","print()\n","wandb.log({\n","    \"epoch\": e,\n","    \"Last_Valid Loss\": val_total_loss,\n","    \"Last_Valid Acc\": val_total_acc,\n","    })\n","best_val_acc_list.append(best_val_acc)\n","print('='*50)\n","print(f\"{f}fold best_val_acc_list : {best_val_acc_list}\")\n","print('='*15, f'{f}fold Final Score(ACC) : {np.mean(best_val_acc_list)}', '='*15)\n","wandb.log({\n","f\"Total Mean ACC ({f}fold)\": np.mean(best_val_acc_list)}\n",")"]},{"cell_type":"markdown","metadata":{"id":"EXrofTlZ_oQy"},"source":["# Inference"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"dtJ1zyPcQZ9F","executionInfo":{"status":"ok","timestamp":1654741232153,"user_tz":-540,"elapsed":626,"user":{"displayName":"Lainie Kang","userId":"17932680864583243195"}}},"outputs":[],"source":["def preprocess_script(code):\n","    \n","    codea = code['code1']\n","    codeb = code['code2']\n","\n","    new_codea = deque()\n","    for line in codea.split('\\n'):\n","        if line.lstrip().startswith('#'): # 주석으로 시작되는 행 skip\n","            continue\n","        line = line.rstrip()\n","        if '#' in line:\n","            line = line[:line.index('#')] # 주석 전까지 코드만 저장\n","        line = line.replace('\\n','')      # 개행 문자를 모두 삭제함\n","        line = line.replace('    ','\\t')  # 공백 4칸을 tab으로 변환\n","\n","        if line == '': # 전처리 후 빈 라인은 skip\n","            continue\n","\n","        new_codea.append(line)\n","\n","    new_codea = '\\n'.join(new_codea)\n","    new_codea = re.sub('(\"\"\"[\\w\\W]*?\"\"\")', '<str>', new_codea)\n","    new_codea = re.sub(\"('''[\\w\\W]*?''')\", '<str>', new_codea)\n","    new_codea = re.sub('/^(file|gopher|news|nntp|telnet|http?|https?|ftps?|sftp):\\/\\/([a-z0-9-]+\\.)+[a-z0-9]{2,4}.*$/',\n","                      '<url>',\n","                      new_codea)\n","    code['code1'] = new_codea\n","\n","    new_codeb = deque()   \n","    for line in codeb.split('\\n'):\n","        if line.lstrip().startswith('#'): # 주석으로 시작되는 행 skip\n","            continue\n","        line = line.rstrip()\n","        if '#' in line:\n","            line = line[:line.index('#')] # 주석 전까지 코드만 저장\n","        line = line.replace('\\n','')      # 개행 문자를 모두 삭제함\n","        line = line.replace('    ','\\t')  # 공백 4칸을 tab으로 변환\n","\n","        if line == '': # 전처리 후 빈 라인은 skip\n","            continue\n","\n","        new_codeb.append(line)\n","\n","    new_codeb = '\\n'.join(new_codeb)\n","    new_codeb = re.sub('(\"\"\"[\\w\\W]*?\"\"\")', '<str>', new_codeb)\n","    new_codeb = re.sub(\"('''[\\w\\W]*?''')\", '<str>', new_codeb)\n","    new_codeb = re.sub('/^(file|gopher|news|nntp|telnet|http?|https?|ftps?|sftp):\\/\\/([a-z0-9-]+\\.)+[a-z0-9]{2,4}.*$/',\n","                      '<url>',\n","                      new_codeb)\n","    \n","    code['code2'] = new_codeb\n","    return code\n","\n","\n","def example_fn(examples):\n","    outputs = tokenizer(examples['code1'], examples['code2'], padding='max_length', max_length=512, truncation=True)\n","    return outputs"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"quXK4GQiQIxE","colab":{"base_uri":"https://localhost:8080/","height":528,"referenced_widgets":["4e61b4d9a5ee4e0794e99acbd431e1be","e4370df887dd4e5c834dd62b128c24d4","2e24243d8b7e4dd48475b47ed61854af","4e70160df13645b2a38a7c4ed1df7650","39cc1b258711476a924230b945e47fe4","aa0db0553afd42c8b76d8f646257655e","3d98acced69f464990dc2bb7e749717f","b2bec29e896c4b6ea447d5a3e3f0a6d3","fe87f6d2bffc442ab7974e3a869e50a9","c8ff15c647e94a948810993f94985d73","9dae3df3b3b74ceab930e2f7ba568e22","a2dc12782a4a4d698a3552c44afc1b3e","2785ad5ed4734df28fef0115acd3baa7","ffe5eb9db43f4543ac2f279436eaa6c4","26d59d38935b46b0a9f9b48b5fc28c59","00794b8fed6041fc8673be9fb5fefe78","60f71a7fb7e44947a49f94571cdc3233","4c54eb4260d54fc4909f7ba34cfafe30","2ab300e983db4956b842cd9ff565906a","519e29e46273424abd7e3385e801d0a2","7d7f38239409405f8ace2a1cd518ec28","f8f902014f584719bd9cb2be8debead4","cc8b61486f2e4f5b8095a50f51d3692b","20f0fee5bc5743fc91375b5e84a7e8b8","b9a3336d4b9940058043b83ea8a72eb8","30c456e7fb5e46379f95580e52713042","3411b32bd4bd4e3fb4a99db98b00c753","097c4d9326aa41a68cced6f3fe77e849","b1b164ca3faa45d09508c4d4cce5c23d","37ec9d3959d5453789f4f032d824e08b","4c803505621845749d8ca632358364cc","a7dddeaacf864482b0ea2e90d7345990","0e87e6fb202349ce8f0720a2726636b0","4cac73954c9c4038b8a6df477e2b5cb3","bba408c2bf5d4a489ad6533379098ed3","0469359b2a494a68b19aa444bf8c8909","dace130b595b4745a729330ec1b821e1","a86d19eda19f47178ca9273ff045588c","34f7eafbc8094963a9d1ef790c058988","53d4577b50994daf9d262dd0801c5009","3d321f54cb3b4536ad49c992c46389fe","ad75fad8fa014f27a78dc073b3e21a59","6b9067f11bc34d96a476b1ef22a2cf4f","eaf1e35c2ddc4aaf8746142689b4a996","51944d34bfac4bd2bf84923b46b8bdb4","1b4f32fae7564f2f8a8145899f76cd51","0038a234133e4d519888ba8e048e7cff","cc0ef98a6d814fda8b286954bd19bcea","5c2ab8615580418eb792ef6668bf8085","cf17627845a3483c936293fbef993b9b","197186f5a61f490e9854ccb7d49f9d9b","266079e3d183452cbd5deb5f7695bf8d","c33a915b2ad04f1b88ea33e2e5af8538","8ed13f7b2dd44ff08c010c1bb5d61b92","587b5811c0e4450fa967694e9efd1c8a","4f906ab35a9e4480befea5186241799a","9d7256e8640c42d885ba3e418a14743f","f85c7adb1b13443ca430223747dfbaaf","f255dee8300d4fc5b607db8a85b4d51c","d91aa0b7f0f24438bbdfc5c56bedd4f0","73939862ae1449caba86ee0f201f6f2b","e846922ec07244eb80987a57ec6318aa","3c73178d60054395bac2472557aa7016","76a357cb2baf498eaba742b866128296","785023c2c4164dcead7b807ff7997d9b","b2ffcdd78d484fcb91f519028fc47786","9c660e74396b47d7b5192476e6471a7e","c2aa850d23d24675b7a61f7f1b109347","aac6ee1291434c11954ed6dca2faa3a1","c1fc97ba16524d72a3ae73a31e519207","ac075d738a444d73b8653a6b4a72849a","e5b7c9d2b3fc42ecbd347204e13d9a1b","86c46d59afe148e78a4d81fb6a09d6e6","6400095371de48d086014f74db28af86","dcae633f4f8f4c1b81237ea7ea3dac9a","7e58a976636747efa2f33b9634af055e","999adb11d564456485d3566cda282745","01c5709d5db34017bc3b620197beb682","daeb68ed438d44a387f437dd34be6927","3c2e63fea487410eb4b8672bf4d899f3","9fc482b69800420e9466cfaabaedaf16","8a10a3020db94a4092f9fb6e5fdfb6f5","c6fcddfbbc804fa68b5b3245b6c0c652","2b8e31bde9774b47acff0a020043aea0","283d20093a2a4c06b1a172bcc34e6795","1645363ff696487fa8a619d5bea328f2","c9b12d634c7141d38bbfe319a06a2bd5","122cc3df057248af9aaea5f35b94e261","71f7d18023c649cc906da1e4771b6cca","df439605051746a4b982d7f67ab561d4","354c1e27ebcc45c587cd7f0e94882a96","43c46432dc124571b084799b016b2a3f","267796351bd24b63a3da878a605acc8e","f5c1f057785f4d93b051fc6e1de62b08","ee6174e285004ede8450120d8de5bd97","90269da33aa044278589fd6953513eec","cc22c6626a9a4314ac2c4c0aa9ed9379","4ff54c905bf5407bb144ff1b4a036c8c","ab0a626c4a204fde88ba90fc93ef4bc3","625d71b546824a8aa9adc9fe2c41aaa4","6a814ac002404890865772f2a840b8f6","21b67f71c6fc49d593ec68b1141f6e98","19cb06315b3742af8be9c82861b4365a","18d3231084584a42b82ec5033a35f6c1","ee11a47e9a7d42389129700850944ddc","c5db9d0a90b7413fafb7ba1dc0b46225","d63aff3949134d9dbef69eccff5b30dc","afe7940ec4df4cb98d7b437b02b5635f","644147361b8a4828a1a4731ccfc59343","5297059040724471aa3640d2c0278022","3814abeb34454475898a547d7ef142ab","634c97f0eb2342caba976a9ff90dc6d7","466d82bc39d14977b17e39764b5c3f34","4f70da1d6ab8446697c256e153793d02","14766e67cca1477b859ba7557f5fa68f","f0609e234c43459f92f57d30beed3749","d7a95d76006b4d74bdf2de3b7f169c37","168390dcac2343e29dff4c952f09494b","79b54145c3cf4c7cb216fa9bfc34a9e2","b31951e0f7f749179b915238e1ab3629","2a8991af2851441589298abd7aac69a3"]},"executionInfo":{"status":"ok","timestamp":1654756317946,"user_tz":-540,"elapsed":15035384,"user":{"displayName":"Lainie Kang","userId":"17932680864583243195"}},"outputId":"f6617061-f98e-4236-ecf1-b7aa11e99845"},"outputs":[{"output_type":"stream","name":"stderr","text":["Using custom data configuration default-13b174ecdaaff536\n"]},{"output_type":"stream","name":"stdout","text":["Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-13b174ecdaaff536/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e61b4d9a5ee4e0794e99acbd431e1be"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2dc12782a4a4d698a3552c44afc1b3e"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-13b174ecdaaff536/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc8b61486f2e4f5b8095a50f51d3692b"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/graphcodebert-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.dense.bias']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/179700 [00:00<?, ?ex/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4cac73954c9c4038b8a6df477e2b5cb3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/179700 [00:00<?, ?ex/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51944d34bfac4bd2bf84923b46b8bdb4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/5 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f906ab35a9e4480befea5186241799a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/11232 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c660e74396b47d7b5192476e6471a7e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/11232 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01c5709d5db34017bc3b620197beb682"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/11232 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71f7d18023c649cc906da1e4771b6cca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/11232 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"625d71b546824a8aa9adc9fe2c41aaa4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/11232 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3814abeb34454475898a547d7ef142ab"}},"metadata":{}}],"source":["testdataset = load_dataset(\"csv\", data_files='/content/drive/MyDrive/test.csv')['train']\n","tokenizer = AutoTokenizer.from_pretrained(\"microsoft/graphcodebert-base\")\n","tokenizer.truncation_side = 'left'\n","model = RobertaForSequenceClassification.from_pretrained(\"microsoft/graphcodebert-base\")\n","\n","preprocessed = testdataset.map(preprocess_script)\n","test_dataset = preprocessed.map(example_fn, remove_columns=['code1', 'code2'])\n","collator = DataCollatorWithPadding(tokenizer=tokenizer)\n","\n","testloader = DataLoader(test_dataset,\n","                          batch_size=16,\n","                          shuffle=False,\n","                         collate_fn = collator\n","                          )\n","\n","all_fold_logits = np.zeros((179700, 2))  # rows of df, target labels\n","for idx in tqdm(range(1, args.n_splits+1)):\n","  load_path = f'./models/{args.model_name}/{idx}-fold/best.pt'\n","  model.load_state_dict(torch.load(load_path,map_location=torch.device('cpu')))\n","  model.to(device)\n","  model.eval()\n","  progress_bar = tqdm(enumerate(testloader), total=len(testloader), leave=True, position=0,)\n","  for i, data in progress_bar:\n","    with torch.no_grad():\n","      logits = model(\n","                  data['input_ids'].to(device),\n","                  data['attention_mask'].to(device),\n","                  )\n","      logits=logits.logits\n","    if i==0:\n","      one_fold_logits = logits\n","    else:\n","      one_fold_logits = torch.cat([one_fold_logits,logits],dim=0) # (batchsize,3) + (batchsize,3) -> (batchsize+batchsize,3)\n","\n","  # torch tensor를 저장하기 위한 numpy 변환\n","  one_fold_logits = one_fold_logits.squeeze(0).detach().cpu().numpy()\n","  # numpy array 저장\n","  np.save(f'./models/{args.model_name}/{idx}-fold/numpy_logits', one_fold_logits)\n","  # np_load = np.load(f'./models/{args.model_name}/{idx}-fold/numpy_logits.npy')\n","  all_fold_logits += one_fold_logits\n","  if idx == 1:\n","    all_fold_predictions = np.argmax(one_fold_logits, axis=1)\n","  else:\n","    one_fold_predictions = np.argmax(one_fold_logits, axis=1)\n","    all_fold_predictions = np.vstack([all_fold_predictions, one_fold_predictions])\n","\n","soft_output = list(np.argmax(all_fold_logits, axis=1))\n","hard_output = ([max(list(Counter(lst).items()), key=lambda x:x[1])[0] for lst in all_fold_predictions.T])\n"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"o1Ua0c9RgR2f","executionInfo":{"status":"ok","timestamp":1654756335677,"user_tz":-540,"elapsed":678,"user":{"displayName":"Lainie Kang","userId":"17932680864583243195"}}},"outputs":[],"source":["submission_path = \"/content/drive/MyDrive/sample_submission.csv\"\n","\n","submissionsoft = pd.read_csv(submission_path)\n","submissionhard = pd.read_csv(submission_path)"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"4SoN7SP7Tr4y","executionInfo":{"status":"ok","timestamp":1654756338581,"user_tz":-540,"elapsed":679,"user":{"displayName":"Lainie Kang","userId":"17932680864583243195"}}},"outputs":[],"source":["submissionsoft['similar']=soft_output\n","submissionhard['similar']=hard_output\n","submissionsoft.to_csv('/content/drive/MyDrive/submissionsoft.csv', index=False)\n","submissionhard.to_csv('/content/drive/MyDrive/submissionhard.csv', index=False)"]}],"metadata":{"accelerator":"GPU","canvas":{"colorPalette":["inherit","inherit","inherit","inherit","inherit","inherit","inherit","inherit","inherit","inherit"],"parameters":[],"version":"1.0"},"colab":{"collapsed_sections":["0uSilsCYzfL9","2FCZRkoS8jqh","Os1EX6BY9N9e","gNeLWJwJ9SkK","himCwOP89Vau","AxK5yqcP9Yfa","jUPKLxXQBvsg","w77P1zyh9cXl","7YC3_0G3gD9J","FEwM3PFigGUm","Tr8TDbdfgGUo","HyxTFWTWgHOH"],"machine_shape":"hm","name":"evaya (2).ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"widgets":{"application/vnd.jupyter.widget-state+json":{"02036367186b49d88b8f930e7f740393":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e71e1ad48884f8d8292846920440086","max":33000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_16ce2c9b25b94d9b80c9c16aa84a47dc","value":33000}},"0f286c788f634d288560c83ee41c2d43":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1216dd019ce4499a9710d81b9c655699","IPY_MODEL_b3542b00ac7e4ba1998eac60058b51da","IPY_MODEL_7501bc5a6b3a44dba16522696e2a28c5"],"layout":"IPY_MODEL_9a0aa4fdb5be4b83a0d74f888cac0016"}},"1216dd019ce4499a9710d81b9c655699":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6745a54208064a80886a8cc075d26633","placeholder":"​","style":"IPY_MODEL_6b17a2e9b0af458a8c8d49b5297ede1e","value":"100%"}},"16ce2c9b25b94d9b80c9c16aa84a47dc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"345f460ed5d04e70931d406d9877ee82":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"41c2d7055e2d4da4aabc827cfe0c9893":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6745a54208064a80886a8cc075d26633":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b17a2e9b0af458a8c8d49b5297ede1e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"726b0b11e9764f268aa7fce45a61e1f2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7501bc5a6b3a44dba16522696e2a28c5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a5b380bebf2648ca9d55f35bf9ec4db2","placeholder":"​","style":"IPY_MODEL_e6f37051372b45e7a35c544c2a679c11","value":" 33000/33000 [7:41:45&lt;00:00,  1.19it/s]"}},"77145c92d6cf419a9cfc409a0b7284eb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7fcd77c7d14a430c983b8661b4217286":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8e71e1ad48884f8d8292846920440086":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91aa2129d54e452eb4f2bd8345d7855a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f3ced7d7e17e495a83f8b27517b3dbae","IPY_MODEL_02036367186b49d88b8f930e7f740393","IPY_MODEL_df8badfdb8c04a34ae8b17fe011a1b4e"],"layout":"IPY_MODEL_f6b92706841148a5be9d30fee4b3d074"}},"9a0aa4fdb5be4b83a0d74f888cac0016":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a267825d847e46baa4116337210125bd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a5b380bebf2648ca9d55f35bf9ec4db2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3542b00ac7e4ba1998eac60058b51da":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_726b0b11e9764f268aa7fce45a61e1f2","max":33000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_345f460ed5d04e70931d406d9877ee82","value":33000}},"df8badfdb8c04a34ae8b17fe011a1b4e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_77145c92d6cf419a9cfc409a0b7284eb","placeholder":"​","style":"IPY_MODEL_41c2d7055e2d4da4aabc827cfe0c9893","value":" 33000/33000 [13:28:31&lt;00:00,  1.48s/it]"}},"e6f37051372b45e7a35c544c2a679c11":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f3ced7d7e17e495a83f8b27517b3dbae":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a267825d847e46baa4116337210125bd","placeholder":"​","style":"IPY_MODEL_7fcd77c7d14a430c983b8661b4217286","value":"100%"}},"f6b92706841148a5be9d30fee4b3d074":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"112844234ed34baeae8078de9fe35cc1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b1c338ed5fc44be59058575e5e30b711","IPY_MODEL_993c1a270e0c4b70afa177bf85065e68","IPY_MODEL_d705c5bb43294582ac59eccc361b9e42"],"layout":"IPY_MODEL_8e82722f7105415f8784f179d02d51f3"}},"b1c338ed5fc44be59058575e5e30b711":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cc2e24c639344c44bef14492c7073c16","placeholder":"​","style":"IPY_MODEL_5222d9693e6f44ada7d83b16864a4277","value":"Downloading data files: 100%"}},"993c1a270e0c4b70afa177bf85065e68":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f98cd6661ab84221a5329670e8885d32","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_00be25629bbd4dcdbdc5842fca4a60a9","value":1}},"d705c5bb43294582ac59eccc361b9e42":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2235c063da3245ef846a7770dba10c09","placeholder":"​","style":"IPY_MODEL_359015d2c1fa4fe28ba112ce004a97f2","value":" 1/1 [00:00&lt;00:00, 39.18it/s]"}},"8e82722f7105415f8784f179d02d51f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc2e24c639344c44bef14492c7073c16":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5222d9693e6f44ada7d83b16864a4277":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f98cd6661ab84221a5329670e8885d32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"00be25629bbd4dcdbdc5842fca4a60a9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2235c063da3245ef846a7770dba10c09":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"359015d2c1fa4fe28ba112ce004a97f2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4293e482d481450b8e825065d533bccb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5d6a59032dff4f01b2c9ded016e364dc","IPY_MODEL_9a1972301743424690d54d957230e0f5","IPY_MODEL_47a8c27b623a458ab85e0d8be9f56930"],"layout":"IPY_MODEL_0fe125574804428bbab3b2520d8d0629"}},"5d6a59032dff4f01b2c9ded016e364dc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e981c910459484eaff3102c302d5876","placeholder":"​","style":"IPY_MODEL_d5efa316226048a9a7cb7086f0a6de63","value":"Extracting data files: 100%"}},"9a1972301743424690d54d957230e0f5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_73215ffad18243e8b7ee29c31727d96b","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fc53609b207f4c1f89ecf3e46dff4fda","value":1}},"47a8c27b623a458ab85e0d8be9f56930":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5242f0dc8d974a02866dbafa162bdf37","placeholder":"​","style":"IPY_MODEL_cc9e8b959ec046fe8ae871454afa2bc6","value":" 1/1 [00:00&lt;00:00, 16.63it/s]"}},"0fe125574804428bbab3b2520d8d0629":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e981c910459484eaff3102c302d5876":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5efa316226048a9a7cb7086f0a6de63":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"73215ffad18243e8b7ee29c31727d96b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc53609b207f4c1f89ecf3e46dff4fda":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5242f0dc8d974a02866dbafa162bdf37":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc9e8b959ec046fe8ae871454afa2bc6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"013caefa41504366b8fdef2f1f859431":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b742bc63634c4a279b3ce6eaabfb24dc","IPY_MODEL_f4f16d4c57924555b53c1c6d8becbe44","IPY_MODEL_5b19797748b34c3e85620e64ae94ee49"],"layout":"IPY_MODEL_eb8f6d6b2f684da88c9d6ba8deecd143"}},"b742bc63634c4a279b3ce6eaabfb24dc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b8a00768f624728acd581bfe5bb223f","placeholder":"​","style":"IPY_MODEL_277ed4f96e92425192bc2891c53d2b55","value":"100%"}},"f4f16d4c57924555b53c1c6d8becbe44":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d17e516b4b6a4c62b6cf9db8645df0ef","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_86a34006d456476597692efbbbac154c","value":1}},"5b19797748b34c3e85620e64ae94ee49":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d47661fc3ed74fee888527c0987c6faf","placeholder":"​","style":"IPY_MODEL_0c9626f369bf4756ad4c40e0393567de","value":" 1/1 [00:00&lt;00:00, 30.83it/s]"}},"eb8f6d6b2f684da88c9d6ba8deecd143":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b8a00768f624728acd581bfe5bb223f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"277ed4f96e92425192bc2891c53d2b55":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d17e516b4b6a4c62b6cf9db8645df0ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86a34006d456476597692efbbbac154c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d47661fc3ed74fee888527c0987c6faf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c9626f369bf4756ad4c40e0393567de":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"38058c752ec9489dbe93d56314742c09":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_da6b0526c7564196a0a0bb14da839445","IPY_MODEL_01321919e3b64ac8b84f8191c8426a5f","IPY_MODEL_25918155e67c40e48a8679fc148fde95"],"layout":"IPY_MODEL_dd31938070374b35bea2d224cc08c80d"}},"da6b0526c7564196a0a0bb14da839445":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dfb1ec85880547eda93443639da3998b","placeholder":"​","style":"IPY_MODEL_1811c9f58b954b669d780ff44d26eb29","value":"Downloading data files: 100%"}},"01321919e3b64ac8b84f8191c8426a5f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e34dc6db5904c8093a2b42a305c80dd","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2681beb3b4fb40acb38ae241c2d401e6","value":1}},"25918155e67c40e48a8679fc148fde95":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cc72d31c413d4691bf8fa315378797af","placeholder":"​","style":"IPY_MODEL_d7df7110a06f478ea6ac07fd909ab9fc","value":" 1/1 [00:00&lt;00:00, 34.19it/s]"}},"dd31938070374b35bea2d224cc08c80d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dfb1ec85880547eda93443639da3998b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1811c9f58b954b669d780ff44d26eb29":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8e34dc6db5904c8093a2b42a305c80dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2681beb3b4fb40acb38ae241c2d401e6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cc72d31c413d4691bf8fa315378797af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7df7110a06f478ea6ac07fd909ab9fc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"efffaa722f7341b889e84349ff4ba9f1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9b4001b1726549839531d84c2cf0e07c","IPY_MODEL_d544a8c9e0124ad6bb175de589b1a14e","IPY_MODEL_7aac4283a2c34f4e8c1f3a9bd42a5abc"],"layout":"IPY_MODEL_6e57fce3d7d24becbceb11bd87f37ba1"}},"9b4001b1726549839531d84c2cf0e07c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8bcec088fccd4a51a6f00398b52a354b","placeholder":"​","style":"IPY_MODEL_14c18a7f69a1465db9ddece3215ea3ca","value":"Extracting data files: 100%"}},"d544a8c9e0124ad6bb175de589b1a14e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fbe218a40ba146feb4a93080df331978","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3ed9b521d6bf4ed5bd8eff74b4905fc2","value":1}},"7aac4283a2c34f4e8c1f3a9bd42a5abc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_62bb046ce5d5498fb0a2b604cbf31414","placeholder":"​","style":"IPY_MODEL_59fe5b9cf22245a2ba0766d4b5a05c1d","value":" 1/1 [00:00&lt;00:00, 24.30it/s]"}},"6e57fce3d7d24becbceb11bd87f37ba1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8bcec088fccd4a51a6f00398b52a354b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"14c18a7f69a1465db9ddece3215ea3ca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fbe218a40ba146feb4a93080df331978":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ed9b521d6bf4ed5bd8eff74b4905fc2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"62bb046ce5d5498fb0a2b604cbf31414":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59fe5b9cf22245a2ba0766d4b5a05c1d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7d6203626a1a4fa9aca36dc3361b468f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_35ae4f134b5f46f4b1d65d25f6dba08b","IPY_MODEL_6ab664fd6563409887699f4bd6d0c7b5","IPY_MODEL_f04ef6b79aa149fbb45e33a5570b6281"],"layout":"IPY_MODEL_2700d8db40c641d48f37ddd3c7a5acdf"}},"35ae4f134b5f46f4b1d65d25f6dba08b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c78cb1064104620b893511a0facf484","placeholder":"​","style":"IPY_MODEL_973c74bf0ef640cb94938fa80703de69","value":"100%"}},"6ab664fd6563409887699f4bd6d0c7b5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_20470e454180403fbdc63fe76f23658b","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4cf29f9fe7334237acba5082776f733d","value":1}},"f04ef6b79aa149fbb45e33a5570b6281":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc613f29e50c4da2bd3937e48ee82220","placeholder":"​","style":"IPY_MODEL_0b8cb3d0dd7a4722a4bb1ba89cbb6148","value":" 1/1 [00:00&lt;00:00, 37.43it/s]"}},"2700d8db40c641d48f37ddd3c7a5acdf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c78cb1064104620b893511a0facf484":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"973c74bf0ef640cb94938fa80703de69":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"20470e454180403fbdc63fe76f23658b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4cf29f9fe7334237acba5082776f733d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bc613f29e50c4da2bd3937e48ee82220":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b8cb3d0dd7a4722a4bb1ba89cbb6148":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b9312c7aa2bc47a68c306692f260aa2f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8bd69ba1525d4493a2e25bec21ebbb21","IPY_MODEL_9252d5a43cd144a582ba847b30a8a56f","IPY_MODEL_d0c6e20f3b6047fea186eab7957ba63d"],"layout":"IPY_MODEL_82efbc933b05433481a2876ab16288ac"}},"8bd69ba1525d4493a2e25bec21ebbb21":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c2cbb3a79cfd4657886aa908ec048077","placeholder":"​","style":"IPY_MODEL_610a5d36ed68435bbb8e6d8346ef74a5","value":"Downloading: 100%"}},"9252d5a43cd144a582ba847b30a8a56f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3bda627818b54583ad4e08ba26fc9235","max":25,"min":0,"orientation":"horizontal","style":"IPY_MODEL_02b8a64f6b5f4b90844d9cf23d994893","value":25}},"d0c6e20f3b6047fea186eab7957ba63d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bae79945e61246f0b5188b1a81fb2abe","placeholder":"​","style":"IPY_MODEL_2ffb4a0f34cc44e498ca1b30b4eabe94","value":" 25.0/25.0 [00:00&lt;00:00, 1.01kB/s]"}},"82efbc933b05433481a2876ab16288ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2cbb3a79cfd4657886aa908ec048077":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"610a5d36ed68435bbb8e6d8346ef74a5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3bda627818b54583ad4e08ba26fc9235":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"02b8a64f6b5f4b90844d9cf23d994893":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bae79945e61246f0b5188b1a81fb2abe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ffb4a0f34cc44e498ca1b30b4eabe94":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e7a62f6ada4d464cb5b9831dde9ad7be":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2f3a4b25ec034906946af33ce319a1e5","IPY_MODEL_dac97754ff4844e6a0ce5c389f58a4c6","IPY_MODEL_29c7b94afddf4ddd8f479bdbbfd51fcb"],"layout":"IPY_MODEL_108fb7feaad742dcaba8b32134afb893"}},"2f3a4b25ec034906946af33ce319a1e5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1891ca41557c4454940295f0e519c46e","placeholder":"​","style":"IPY_MODEL_a0ca4512fc40463fb6e6d82d70a62cf3","value":"Downloading: 100%"}},"dac97754ff4844e6a0ce5c389f58a4c6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a09295b921c94a2d86c56d9dc989044d","max":539,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d16b1596053044fdb6722ccdbdc4f762","value":539}},"29c7b94afddf4ddd8f479bdbbfd51fcb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8e5c066a4b5425281e4acee929f8060","placeholder":"​","style":"IPY_MODEL_2e5554212dd84a77a5a56bfa28d7e5f6","value":" 539/539 [00:00&lt;00:00, 20.5kB/s]"}},"108fb7feaad742dcaba8b32134afb893":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1891ca41557c4454940295f0e519c46e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0ca4512fc40463fb6e6d82d70a62cf3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a09295b921c94a2d86c56d9dc989044d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d16b1596053044fdb6722ccdbdc4f762":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e8e5c066a4b5425281e4acee929f8060":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e5554212dd84a77a5a56bfa28d7e5f6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4db282fb60f744689e3ed92c8063e1f0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dc967b43eee24e15a61cf0444523c54f","IPY_MODEL_8be4e9ce636c4de6a535d388477119d9","IPY_MODEL_21446a9f3ee1497d9dd8fbc60ed05728"],"layout":"IPY_MODEL_01e31275f7444aaf9e884ff09f2a4fa8"}},"dc967b43eee24e15a61cf0444523c54f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_744c8660d9f34e19a955614f4910ae43","placeholder":"​","style":"IPY_MODEL_3040f8e4c47342929ebca6540a0f3de6","value":"Downloading: 100%"}},"8be4e9ce636c4de6a535d388477119d9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_222733c8ae304d83868d63e161de4a90","max":898822,"min":0,"orientation":"horizontal","style":"IPY_MODEL_db6e1aafb7464642b5a6c3eaeb9cfb0b","value":898822}},"21446a9f3ee1497d9dd8fbc60ed05728":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b472740b5a1432993301388f2394a67","placeholder":"​","style":"IPY_MODEL_ecb2f2bc49cf4a5dbefaefb4b0d1c0af","value":" 878k/878k [00:00&lt;00:00, 2.60MB/s]"}},"01e31275f7444aaf9e884ff09f2a4fa8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"744c8660d9f34e19a955614f4910ae43":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3040f8e4c47342929ebca6540a0f3de6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"222733c8ae304d83868d63e161de4a90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db6e1aafb7464642b5a6c3eaeb9cfb0b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5b472740b5a1432993301388f2394a67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ecb2f2bc49cf4a5dbefaefb4b0d1c0af":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6ae7d011d2184acd8d1741712e07c37d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9a6e6a6e96724dd9a0a69c9320ecc2f4","IPY_MODEL_268e45e6d4af4d8cb79ca0c640f2e4a6","IPY_MODEL_f076cdf849744b378ba54fbde58a064b"],"layout":"IPY_MODEL_0c63a3459a544e0db3072ee6b23138e5"}},"9a6e6a6e96724dd9a0a69c9320ecc2f4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_64e5fcf9d49f41ae80bbb9f7345062c1","placeholder":"​","style":"IPY_MODEL_9ae4de1a9c9e4540a18fa8b8ba13c3a6","value":"Downloading: 100%"}},"268e45e6d4af4d8cb79ca0c640f2e4a6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b50e01bcbc654594a10fe8bffe228e2f","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5724897745f0457e8a3870583af101b4","value":456318}},"f076cdf849744b378ba54fbde58a064b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_782c5fd9f94e4b5f8f4b5111aa4b4d8d","placeholder":"​","style":"IPY_MODEL_56a592e02e534221ab7077e2ef97c64f","value":" 446k/446k [00:00&lt;00:00, 845kB/s]"}},"0c63a3459a544e0db3072ee6b23138e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64e5fcf9d49f41ae80bbb9f7345062c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ae4de1a9c9e4540a18fa8b8ba13c3a6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b50e01bcbc654594a10fe8bffe228e2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5724897745f0457e8a3870583af101b4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"782c5fd9f94e4b5f8f4b5111aa4b4d8d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"56a592e02e534221ab7077e2ef97c64f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"de46fd632b274a79a3c515506f6d87c2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_76e6a9ce52c041399272fded55ba08d3","IPY_MODEL_e8c4833486b34955b87c30d872f9a08e","IPY_MODEL_6c449e3821d54b67bdb8b507eb41bd25"],"layout":"IPY_MODEL_4e9376a023664ef0b1df6b086e1780e6"}},"76e6a9ce52c041399272fded55ba08d3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_71d495c3518349b9bc9cf365ff97bf7b","placeholder":"​","style":"IPY_MODEL_9a6fe04fc7514eb9b22437ca69a62665","value":"Downloading: 100%"}},"e8c4833486b34955b87c30d872f9a08e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c23344be027d4c93bd07d7de48a5dd7e","max":772,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4c75af8bb6694dd5b19048fd93a41592","value":772}},"6c449e3821d54b67bdb8b507eb41bd25":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d50998c302af4ea4a6505b24c98fc233","placeholder":"​","style":"IPY_MODEL_a779e730ca8d4a75abd17ad3c2af3b03","value":" 772/772 [00:00&lt;00:00, 31.3kB/s]"}},"4e9376a023664ef0b1df6b086e1780e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71d495c3518349b9bc9cf365ff97bf7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a6fe04fc7514eb9b22437ca69a62665":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c23344be027d4c93bd07d7de48a5dd7e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c75af8bb6694dd5b19048fd93a41592":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d50998c302af4ea4a6505b24c98fc233":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a779e730ca8d4a75abd17ad3c2af3b03":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"713dd00540ab468ebcb09f4ba97258b7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e3036b1703f84c229e4f70d8d7a487a8","IPY_MODEL_fc11ba12fb37456fb3924ae10535574a","IPY_MODEL_25bcb5b890ce430da3d95372f9020e05"],"layout":"IPY_MODEL_2a1b90149c99466aa1004e3bf5b8588e"}},"e3036b1703f84c229e4f70d8d7a487a8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f11a6b3b3354ee4a7c1d8d974b76167","placeholder":"​","style":"IPY_MODEL_b92d5b6147bc43bd8cc209c13ec6ec95","value":"100%"}},"fc11ba12fb37456fb3924ae10535574a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_283cf36952804e2ea72b04b0f2a67f90","max":660000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a888e8c521954e479cc186fdfadd179a","value":660000}},"25bcb5b890ce430da3d95372f9020e05":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3157617001a8469582ad1dce9125b1c3","placeholder":"​","style":"IPY_MODEL_16906426b0fd486d8dcb8e0397e9744b","value":" 660000/660000 [10:39&lt;00:00, 1010.71ex/s]"}},"2a1b90149c99466aa1004e3bf5b8588e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f11a6b3b3354ee4a7c1d8d974b76167":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b92d5b6147bc43bd8cc209c13ec6ec95":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"283cf36952804e2ea72b04b0f2a67f90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a888e8c521954e479cc186fdfadd179a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3157617001a8469582ad1dce9125b1c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16906426b0fd486d8dcb8e0397e9744b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"172e97c6df2d414393eedd3167fda750":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3961aa4379e6457abde58d199277d39c","IPY_MODEL_d19d38dc7d3343a9956b1991cfc63268","IPY_MODEL_1e92eceeb0664ef0b49ea7e645bf3f09"],"layout":"IPY_MODEL_174d9f524eb3451db6f121f43bd6cfaf"}},"3961aa4379e6457abde58d199277d39c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8eaa2d3fcc91465597286eca5ab65c39","placeholder":"​","style":"IPY_MODEL_5b2f4bdc3d0643ba92b63378bfd177da","value":"Downloading: 100%"}},"d19d38dc7d3343a9956b1991cfc63268":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ac640cf10e544f684b0aa646b6869bf","max":498845934,"min":0,"orientation":"horizontal","style":"IPY_MODEL_10835ec645a74d5fac9f536bd805a0c0","value":498845934}},"1e92eceeb0664ef0b49ea7e645bf3f09":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9638b8d5737e478fa9f21de5fa5a3d3f","placeholder":"​","style":"IPY_MODEL_12b1de06bee540e29f3558da0604a2ce","value":" 476M/476M [00:15&lt;00:00, 37.3MB/s]"}},"174d9f524eb3451db6f121f43bd6cfaf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8eaa2d3fcc91465597286eca5ab65c39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b2f4bdc3d0643ba92b63378bfd177da":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3ac640cf10e544f684b0aa646b6869bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"10835ec645a74d5fac9f536bd805a0c0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9638b8d5737e478fa9f21de5fa5a3d3f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12b1de06bee540e29f3558da0604a2ce":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4e61b4d9a5ee4e0794e99acbd431e1be":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e4370df887dd4e5c834dd62b128c24d4","IPY_MODEL_2e24243d8b7e4dd48475b47ed61854af","IPY_MODEL_4e70160df13645b2a38a7c4ed1df7650"],"layout":"IPY_MODEL_39cc1b258711476a924230b945e47fe4"}},"e4370df887dd4e5c834dd62b128c24d4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa0db0553afd42c8b76d8f646257655e","placeholder":"​","style":"IPY_MODEL_3d98acced69f464990dc2bb7e749717f","value":"Downloading data files: 100%"}},"2e24243d8b7e4dd48475b47ed61854af":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b2bec29e896c4b6ea447d5a3e3f0a6d3","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fe87f6d2bffc442ab7974e3a869e50a9","value":1}},"4e70160df13645b2a38a7c4ed1df7650":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c8ff15c647e94a948810993f94985d73","placeholder":"​","style":"IPY_MODEL_9dae3df3b3b74ceab930e2f7ba568e22","value":" 1/1 [00:00&lt;00:00, 35.98it/s]"}},"39cc1b258711476a924230b945e47fe4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa0db0553afd42c8b76d8f646257655e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d98acced69f464990dc2bb7e749717f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b2bec29e896c4b6ea447d5a3e3f0a6d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe87f6d2bffc442ab7974e3a869e50a9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c8ff15c647e94a948810993f94985d73":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9dae3df3b3b74ceab930e2f7ba568e22":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a2dc12782a4a4d698a3552c44afc1b3e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2785ad5ed4734df28fef0115acd3baa7","IPY_MODEL_ffe5eb9db43f4543ac2f279436eaa6c4","IPY_MODEL_26d59d38935b46b0a9f9b48b5fc28c59"],"layout":"IPY_MODEL_00794b8fed6041fc8673be9fb5fefe78"}},"2785ad5ed4734df28fef0115acd3baa7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_60f71a7fb7e44947a49f94571cdc3233","placeholder":"​","style":"IPY_MODEL_4c54eb4260d54fc4909f7ba34cfafe30","value":"Extracting data files: 100%"}},"ffe5eb9db43f4543ac2f279436eaa6c4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ab300e983db4956b842cd9ff565906a","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_519e29e46273424abd7e3385e801d0a2","value":1}},"26d59d38935b46b0a9f9b48b5fc28c59":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d7f38239409405f8ace2a1cd518ec28","placeholder":"​","style":"IPY_MODEL_f8f902014f584719bd9cb2be8debead4","value":" 1/1 [00:00&lt;00:00, 19.67it/s]"}},"00794b8fed6041fc8673be9fb5fefe78":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60f71a7fb7e44947a49f94571cdc3233":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c54eb4260d54fc4909f7ba34cfafe30":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2ab300e983db4956b842cd9ff565906a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"519e29e46273424abd7e3385e801d0a2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7d7f38239409405f8ace2a1cd518ec28":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8f902014f584719bd9cb2be8debead4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cc8b61486f2e4f5b8095a50f51d3692b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_20f0fee5bc5743fc91375b5e84a7e8b8","IPY_MODEL_b9a3336d4b9940058043b83ea8a72eb8","IPY_MODEL_30c456e7fb5e46379f95580e52713042"],"layout":"IPY_MODEL_3411b32bd4bd4e3fb4a99db98b00c753"}},"20f0fee5bc5743fc91375b5e84a7e8b8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_097c4d9326aa41a68cced6f3fe77e849","placeholder":"​","style":"IPY_MODEL_b1b164ca3faa45d09508c4d4cce5c23d","value":"100%"}},"b9a3336d4b9940058043b83ea8a72eb8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_37ec9d3959d5453789f4f032d824e08b","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4c803505621845749d8ca632358364cc","value":1}},"30c456e7fb5e46379f95580e52713042":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7dddeaacf864482b0ea2e90d7345990","placeholder":"​","style":"IPY_MODEL_0e87e6fb202349ce8f0720a2726636b0","value":" 1/1 [00:00&lt;00:00, 33.27it/s]"}},"3411b32bd4bd4e3fb4a99db98b00c753":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"097c4d9326aa41a68cced6f3fe77e849":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1b164ca3faa45d09508c4d4cce5c23d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"37ec9d3959d5453789f4f032d824e08b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c803505621845749d8ca632358364cc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a7dddeaacf864482b0ea2e90d7345990":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e87e6fb202349ce8f0720a2726636b0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4cac73954c9c4038b8a6df477e2b5cb3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bba408c2bf5d4a489ad6533379098ed3","IPY_MODEL_0469359b2a494a68b19aa444bf8c8909","IPY_MODEL_dace130b595b4745a729330ec1b821e1"],"layout":"IPY_MODEL_a86d19eda19f47178ca9273ff045588c"}},"bba408c2bf5d4a489ad6533379098ed3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_34f7eafbc8094963a9d1ef790c058988","placeholder":"​","style":"IPY_MODEL_53d4577b50994daf9d262dd0801c5009","value":"100%"}},"0469359b2a494a68b19aa444bf8c8909":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d321f54cb3b4536ad49c992c46389fe","max":179700,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ad75fad8fa014f27a78dc073b3e21a59","value":179700}},"dace130b595b4745a729330ec1b821e1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b9067f11bc34d96a476b1ef22a2cf4f","placeholder":"​","style":"IPY_MODEL_eaf1e35c2ddc4aaf8746142689b4a996","value":" 179700/179700 [00:20&lt;00:00, 8585.50ex/s]"}},"a86d19eda19f47178ca9273ff045588c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34f7eafbc8094963a9d1ef790c058988":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53d4577b50994daf9d262dd0801c5009":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3d321f54cb3b4536ad49c992c46389fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad75fad8fa014f27a78dc073b3e21a59":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6b9067f11bc34d96a476b1ef22a2cf4f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eaf1e35c2ddc4aaf8746142689b4a996":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"51944d34bfac4bd2bf84923b46b8bdb4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1b4f32fae7564f2f8a8145899f76cd51","IPY_MODEL_0038a234133e4d519888ba8e048e7cff","IPY_MODEL_cc0ef98a6d814fda8b286954bd19bcea"],"layout":"IPY_MODEL_5c2ab8615580418eb792ef6668bf8085"}},"1b4f32fae7564f2f8a8145899f76cd51":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf17627845a3483c936293fbef993b9b","placeholder":"​","style":"IPY_MODEL_197186f5a61f490e9854ccb7d49f9d9b","value":"100%"}},"0038a234133e4d519888ba8e048e7cff":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_266079e3d183452cbd5deb5f7695bf8d","max":179700,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c33a915b2ad04f1b88ea33e2e5af8538","value":179700}},"cc0ef98a6d814fda8b286954bd19bcea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8ed13f7b2dd44ff08c010c1bb5d61b92","placeholder":"​","style":"IPY_MODEL_587b5811c0e4450fa967694e9efd1c8a","value":" 179700/179700 [02:51&lt;00:00, 1189.10ex/s]"}},"5c2ab8615580418eb792ef6668bf8085":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf17627845a3483c936293fbef993b9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"197186f5a61f490e9854ccb7d49f9d9b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"266079e3d183452cbd5deb5f7695bf8d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c33a915b2ad04f1b88ea33e2e5af8538":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8ed13f7b2dd44ff08c010c1bb5d61b92":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"587b5811c0e4450fa967694e9efd1c8a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4f906ab35a9e4480befea5186241799a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9d7256e8640c42d885ba3e418a14743f","IPY_MODEL_f85c7adb1b13443ca430223747dfbaaf","IPY_MODEL_f255dee8300d4fc5b607db8a85b4d51c"],"layout":"IPY_MODEL_d91aa0b7f0f24438bbdfc5c56bedd4f0"}},"9d7256e8640c42d885ba3e418a14743f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_73939862ae1449caba86ee0f201f6f2b","placeholder":"​","style":"IPY_MODEL_e846922ec07244eb80987a57ec6318aa","value":"100%"}},"f85c7adb1b13443ca430223747dfbaaf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c73178d60054395bac2472557aa7016","max":5,"min":0,"orientation":"horizontal","style":"IPY_MODEL_76a357cb2baf498eaba742b866128296","value":5}},"f255dee8300d4fc5b607db8a85b4d51c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_785023c2c4164dcead7b807ff7997d9b","placeholder":"​","style":"IPY_MODEL_b2ffcdd78d484fcb91f519028fc47786","value":" 5/5 [4:07:13&lt;00:00, 2966.00s/it]"}},"d91aa0b7f0f24438bbdfc5c56bedd4f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73939862ae1449caba86ee0f201f6f2b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e846922ec07244eb80987a57ec6318aa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3c73178d60054395bac2472557aa7016":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76a357cb2baf498eaba742b866128296":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"785023c2c4164dcead7b807ff7997d9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2ffcdd78d484fcb91f519028fc47786":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9c660e74396b47d7b5192476e6471a7e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c2aa850d23d24675b7a61f7f1b109347","IPY_MODEL_aac6ee1291434c11954ed6dca2faa3a1","IPY_MODEL_c1fc97ba16524d72a3ae73a31e519207"],"layout":"IPY_MODEL_ac075d738a444d73b8653a6b4a72849a"}},"c2aa850d23d24675b7a61f7f1b109347":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e5b7c9d2b3fc42ecbd347204e13d9a1b","placeholder":"​","style":"IPY_MODEL_86c46d59afe148e78a4d81fb6a09d6e6","value":"100%"}},"aac6ee1291434c11954ed6dca2faa3a1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6400095371de48d086014f74db28af86","max":11232,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dcae633f4f8f4c1b81237ea7ea3dac9a","value":11232}},"c1fc97ba16524d72a3ae73a31e519207":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e58a976636747efa2f33b9634af055e","placeholder":"​","style":"IPY_MODEL_999adb11d564456485d3566cda282745","value":" 11232/11232 [49:24&lt;00:00,  3.78it/s]"}},"ac075d738a444d73b8653a6b4a72849a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e5b7c9d2b3fc42ecbd347204e13d9a1b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86c46d59afe148e78a4d81fb6a09d6e6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6400095371de48d086014f74db28af86":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dcae633f4f8f4c1b81237ea7ea3dac9a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7e58a976636747efa2f33b9634af055e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"999adb11d564456485d3566cda282745":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"01c5709d5db34017bc3b620197beb682":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_daeb68ed438d44a387f437dd34be6927","IPY_MODEL_3c2e63fea487410eb4b8672bf4d899f3","IPY_MODEL_9fc482b69800420e9466cfaabaedaf16"],"layout":"IPY_MODEL_8a10a3020db94a4092f9fb6e5fdfb6f5"}},"daeb68ed438d44a387f437dd34be6927":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6fcddfbbc804fa68b5b3245b6c0c652","placeholder":"​","style":"IPY_MODEL_2b8e31bde9774b47acff0a020043aea0","value":"100%"}},"3c2e63fea487410eb4b8672bf4d899f3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_283d20093a2a4c06b1a172bcc34e6795","max":11232,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1645363ff696487fa8a619d5bea328f2","value":11232}},"9fc482b69800420e9466cfaabaedaf16":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c9b12d634c7141d38bbfe319a06a2bd5","placeholder":"​","style":"IPY_MODEL_122cc3df057248af9aaea5f35b94e261","value":" 11232/11232 [49:23&lt;00:00,  3.79it/s]"}},"8a10a3020db94a4092f9fb6e5fdfb6f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6fcddfbbc804fa68b5b3245b6c0c652":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b8e31bde9774b47acff0a020043aea0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"283d20093a2a4c06b1a172bcc34e6795":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1645363ff696487fa8a619d5bea328f2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c9b12d634c7141d38bbfe319a06a2bd5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"122cc3df057248af9aaea5f35b94e261":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"71f7d18023c649cc906da1e4771b6cca":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_df439605051746a4b982d7f67ab561d4","IPY_MODEL_354c1e27ebcc45c587cd7f0e94882a96","IPY_MODEL_43c46432dc124571b084799b016b2a3f"],"layout":"IPY_MODEL_267796351bd24b63a3da878a605acc8e"}},"df439605051746a4b982d7f67ab561d4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f5c1f057785f4d93b051fc6e1de62b08","placeholder":"​","style":"IPY_MODEL_ee6174e285004ede8450120d8de5bd97","value":"100%"}},"354c1e27ebcc45c587cd7f0e94882a96":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_90269da33aa044278589fd6953513eec","max":11232,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cc22c6626a9a4314ac2c4c0aa9ed9379","value":11232}},"43c46432dc124571b084799b016b2a3f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4ff54c905bf5407bb144ff1b4a036c8c","placeholder":"​","style":"IPY_MODEL_ab0a626c4a204fde88ba90fc93ef4bc3","value":" 11232/11232 [49:21&lt;00:00,  3.79it/s]"}},"267796351bd24b63a3da878a605acc8e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5c1f057785f4d93b051fc6e1de62b08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee6174e285004ede8450120d8de5bd97":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"90269da33aa044278589fd6953513eec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc22c6626a9a4314ac2c4c0aa9ed9379":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4ff54c905bf5407bb144ff1b4a036c8c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab0a626c4a204fde88ba90fc93ef4bc3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"625d71b546824a8aa9adc9fe2c41aaa4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6a814ac002404890865772f2a840b8f6","IPY_MODEL_21b67f71c6fc49d593ec68b1141f6e98","IPY_MODEL_19cb06315b3742af8be9c82861b4365a"],"layout":"IPY_MODEL_18d3231084584a42b82ec5033a35f6c1"}},"6a814ac002404890865772f2a840b8f6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ee11a47e9a7d42389129700850944ddc","placeholder":"​","style":"IPY_MODEL_c5db9d0a90b7413fafb7ba1dc0b46225","value":"100%"}},"21b67f71c6fc49d593ec68b1141f6e98":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d63aff3949134d9dbef69eccff5b30dc","max":11232,"min":0,"orientation":"horizontal","style":"IPY_MODEL_afe7940ec4df4cb98d7b437b02b5635f","value":11232}},"19cb06315b3742af8be9c82861b4365a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_644147361b8a4828a1a4731ccfc59343","placeholder":"​","style":"IPY_MODEL_5297059040724471aa3640d2c0278022","value":" 11232/11232 [49:22&lt;00:00,  3.77it/s]"}},"18d3231084584a42b82ec5033a35f6c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee11a47e9a7d42389129700850944ddc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5db9d0a90b7413fafb7ba1dc0b46225":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d63aff3949134d9dbef69eccff5b30dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"afe7940ec4df4cb98d7b437b02b5635f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"644147361b8a4828a1a4731ccfc59343":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5297059040724471aa3640d2c0278022":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3814abeb34454475898a547d7ef142ab":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_634c97f0eb2342caba976a9ff90dc6d7","IPY_MODEL_466d82bc39d14977b17e39764b5c3f34","IPY_MODEL_4f70da1d6ab8446697c256e153793d02"],"layout":"IPY_MODEL_14766e67cca1477b859ba7557f5fa68f"}},"634c97f0eb2342caba976a9ff90dc6d7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f0609e234c43459f92f57d30beed3749","placeholder":"​","style":"IPY_MODEL_d7a95d76006b4d74bdf2de3b7f169c37","value":"100%"}},"466d82bc39d14977b17e39764b5c3f34":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_168390dcac2343e29dff4c952f09494b","max":11232,"min":0,"orientation":"horizontal","style":"IPY_MODEL_79b54145c3cf4c7cb216fa9bfc34a9e2","value":11232}},"4f70da1d6ab8446697c256e153793d02":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b31951e0f7f749179b915238e1ab3629","placeholder":"​","style":"IPY_MODEL_2a8991af2851441589298abd7aac69a3","value":" 11232/11232 [49:22&lt;00:00,  3.79it/s]"}},"14766e67cca1477b859ba7557f5fa68f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0609e234c43459f92f57d30beed3749":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7a95d76006b4d74bdf2de3b7f169c37":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"168390dcac2343e29dff4c952f09494b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79b54145c3cf4c7cb216fa9bfc34a9e2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b31951e0f7f749179b915238e1ab3629":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a8991af2851441589298abd7aac69a3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}