{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdccdb56-b73a-44e9-acef-5263fc1d3527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57da6d25-fa8a-4fcc-9230-945c173a8219",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_folder = \"./code\"\n",
    "problem_folders = os.listdir(code_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9318d9ba-5e24-4bc8-8be5-e413d09e4f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 300/300 [00:02<00:00, 142.85it/s]\n"
     ]
    }
   ],
   "source": [
    "def preprocess_script(script):\n",
    "    with open(script, \"r\", encoding=\"utf-8\") as file:\n",
    "        lines = file.readlines()\n",
    "        preproc_lines = list()\n",
    "        for line in lines:\n",
    "            if line.lstrip().startswith(\"#\"):\n",
    "                continue\n",
    "            line = line.rstrip()\n",
    "            if \"#\" in line:\n",
    "                line = line[:line.index(\"#\")]\n",
    "            line = line.replace(\"\\n\", \"\")\n",
    "            line = line.replace(\"    \", \"\\t\")\n",
    "            if line == \"\":\n",
    "                continue\n",
    "            preproc_lines.append(line)\n",
    "        preprocessed_script = \"\\n\".join(preproc_lines)\n",
    "    return preprocessed_script\n",
    "\n",
    "preproc_scripts = list()\n",
    "problem_nums = list()\n",
    "\n",
    "for problem_folder in tqdm(problem_folders):\n",
    "    scripts = os.listdir(os.path.join(code_folder, problem_folder))\n",
    "    problem_num = scripts[0].split(\"_\")[0]\n",
    "    for script in scripts:\n",
    "        script_file = os.path.join(code_folder, problem_folder, script)\n",
    "        preprocessed_script = preprocess_script(script_file)\n",
    "        \n",
    "        preproc_scripts.append(preprocessed_script)\n",
    "    problem_nums.extend([problem_num]*len(scripts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5c3001f-7592-4cbc-86e3-ab40a0710fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data = {\"code\":preproc_scripts, \"problem_num\":problem_nums})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b014b2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'problem092': 150, 'problem098': 150, 'problem266': 150, 'problem097': 150, 'problem290': 150, 'problem127': 150, 'problem220': 150, 'problem148': 151, 'problem133': 150, 'problem044': 150, 'problem226': 150, 'problem071': 150, 'problem094': 150, 'problem272': 150, 'problem115': 150, 'problem068': 152, 'problem212': 150, 'problem193': 151, 'problem073': 151, 'problem186': 150, 'problem210': 150, 'problem057': 150, 'problem161': 150, 'problem149': 151, 'problem227': 150, 'problem268': 150, 'problem244': 150, 'problem014': 151, 'problem105': 150, 'problem284': 150, 'problem024': 150, 'problem232': 150, 'problem246': 150, 'problem196': 150, 'problem039': 150, 'problem077': 150, 'problem124': 150, 'problem271': 150, 'problem179': 150, 'problem183': 150, 'problem125': 151, 'problem280': 150, 'problem020': 150, 'problem106': 151, 'problem275': 150, 'problem205': 151, 'problem103': 150, 'problem169': 150, 'problem209': 150, 'problem146': 150, 'problem060': 151, 'problem008': 150, 'problem116': 150, 'problem248': 150, 'problem297': 150, 'problem167': 151, 'problem109': 151, 'problem081': 150, 'problem064': 150, 'problem201': 151, 'problem234': 150, 'problem282': 150, 'problem200': 150, 'problem206': 150, 'problem173': 150, 'problem079': 150, 'problem168': 150, 'problem021': 151, 'problem004': 150, 'problem187': 150, 'problem140': 150, 'problem138': 150, 'problem276': 150, 'problem298': 150, 'problem062': 153, 'problem267': 150, 'problem088': 150, 'problem016': 150, 'problem264': 150, 'problem059': 152, 'problem153': 150, 'problem270': 150, 'problem181': 150, 'problem171': 150, 'problem019': 151, 'problem208': 150, 'problem054': 150, 'problem070': 150, 'problem142': 150, 'problem107': 150, 'problem235': 150, 'problem198': 150, 'problem050': 150, 'problem287': 151, 'problem143': 150, 'problem296': 150, 'problem128': 151, 'problem029': 150, 'problem286': 151, 'problem022': 151, 'problem278': 151, 'problem218': 150, 'problem249': 151, 'problem239': 150, 'problem285': 150, 'problem034': 151, 'problem233': 150, 'problem026': 150, 'problem245': 150, 'problem176': 150, 'problem292': 150, 'problem078': 150, 'problem025': 150, 'problem265': 150, 'problem223': 150, 'problem194': 151, 'problem243': 150, 'problem197': 150, 'problem172': 150, 'problem214': 151, 'problem295': 150, 'problem188': 150, 'problem009': 150, 'problem117': 150, 'problem031': 150, 'problem027': 151, 'problem151': 150, 'problem084': 151, 'problem052': 150, 'problem123': 150, 'problem204': 151, 'problem281': 150, 'problem219': 150, 'problem279': 151, 'problem238': 150, 'problem256': 150, 'problem047': 150, 'problem121': 150, 'problem157': 150, 'problem048': 150, 'problem155': 150, 'problem074': 150, 'problem162': 151, 'problem066': 150, 'problem006': 150, 'problem224': 150, 'problem211': 151, 'problem001': 150, 'problem018': 151, 'problem045': 150, 'problem190': 150, 'problem055': 151, 'problem257': 151, 'problem013': 150, 'problem203': 150, 'problem195': 150, 'problem145': 150, 'problem096': 150, 'problem032': 151, 'problem056': 150, 'problem122': 150, 'problem111': 150, 'problem015': 151, 'problem177': 150, 'problem231': 150, 'problem293': 150, 'problem164': 150, 'problem283': 150, 'problem063': 151, 'problem185': 150, 'problem119': 150, 'problem163': 150, 'problem237': 151, 'problem086': 151, 'problem273': 152, 'problem230': 150, 'problem221': 150, 'problem136': 152, 'problem095': 151, 'problem288': 150, 'problem007': 151, 'problem165': 150, 'problem033': 150, 'problem241': 150, 'problem202': 150, 'problem003': 150, 'problem118': 150, 'problem154': 150, 'problem101': 150, 'problem072': 151, 'problem260': 150, 'problem139': 150, 'problem160': 150, 'problem113': 151, 'problem028': 151, 'problem023': 150, 'problem093': 150, 'problem114': 151, 'problem137': 150, 'problem005': 151, 'problem049': 150, 'problem132': 151, 'problem236': 151, 'problem289': 150, 'problem170': 150, 'problem250': 150, 'problem152': 152, 'problem067': 151, 'problem083': 150, 'problem053': 150, 'problem100': 150, 'problem299': 150, 'problem192': 151, 'problem258': 150, 'problem251': 150, 'problem099': 151, 'problem242': 150, 'problem129': 150, 'problem036': 151, 'problem217': 151, 'problem061': 150, 'problem135': 150, 'problem254': 151, 'problem150': 150, 'problem166': 151, 'problem178': 151, 'problem040': 150, 'problem277': 150, 'problem175': 152, 'problem222': 150, 'problem261': 150, 'problem002': 150, 'problem216': 152, 'problem191': 150, 'problem174': 152, 'problem058': 150, 'problem126': 151, 'problem228': 150, 'problem184': 151, 'problem225': 150, 'problem180': 150, 'problem051': 150, 'problem182': 151, 'problem156': 150, 'problem189': 150, 'problem207': 150, 'problem076': 150, 'problem017': 150, 'problem294': 150, 'problem010': 150, 'problem041': 150, 'problem263': 151, 'problem035': 150, 'problem030': 151, 'problem012': 150, 'problem065': 150, 'problem159': 151, 'problem090': 151, 'problem199': 150, 'problem144': 152, 'problem229': 150, 'problem120': 150, 'problem131': 150, 'problem262': 153, 'problem291': 150, 'problem069': 150, 'problem110': 150, 'problem085': 151, 'problem091': 150, 'problem112': 151, 'problem043': 151, 'problem158': 151, 'problem213': 151, 'problem252': 150, 'problem300': 150, 'problem215': 150, 'problem240': 151, 'problem011': 151, 'problem080': 150, 'problem075': 151, 'problem141': 150, 'problem104': 150, 'problem046': 151, 'problem134': 151, 'problem253': 150, 'problem087': 150, 'problem247': 150, 'problem042': 151, 'problem274': 150, 'problem108': 150, 'problem130': 150, 'problem082': 152, 'problem269': 151, 'problem102': 151, 'problem147': 151, 'problem037': 150, 'problem259': 150, 'problem255': 150, 'problem089': 150, 'problem038': 150}\n"
     ]
    }
   ],
   "source": [
    "temp_dict = dict()\n",
    "for code, prob_num in zip(df[\"code\"], df[\"problem_num\"]):\n",
    "    if prob_num in temp_dict:\n",
    "        temp_dict[prob_num] += 1\n",
    "    else:\n",
    "        temp_dict[prob_num] = 1\n",
    "\n",
    "print(temp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92c24572-eebc-4399-98a4-5bfa3aa3975a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45101"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aeaf4555-712d-4799-8cac-ac3236ca1f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (541 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>45101.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>160.123789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>500.930345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>61.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>108.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>97566.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                len\n",
       "count  45101.000000\n",
       "mean     160.123789\n",
       "std      500.930345\n",
       "min        5.000000\n",
       "25%       61.000000\n",
       "50%      108.000000\n",
       "75%      200.000000\n",
       "max    97566.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/graphcodebert-base\")\n",
    "df[\"tokens\"] = df[\"code\"].apply(tokenizer.tokenize)\n",
    "df[\"len\"] = df[\"tokens\"].apply(len)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85ed19cf-62d0-4f99-ad4d-f435beebce4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>43647.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>137.920842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>104.933475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>104.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>187.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>512.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                len\n",
       "count  43647.000000\n",
       "mean     137.920842\n",
       "std      104.933475\n",
       "min        5.000000\n",
       "25%       60.000000\n",
       "50%      104.000000\n",
       "75%      187.000000\n",
       "max      512.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndf = df[df[\"len\"] <= 512].reset_index(drop=True)\n",
    "ndf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c686693-1df2-477c-a117-89ebc043976b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.read_csv(\"./test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f28eb1e-c872-40bc-bdb3-767b4d952d53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    179700.000000\n",
       "mean        392.408347\n",
       "std         923.698933\n",
       "min          20.000000\n",
       "25%         153.000000\n",
       "50%         255.000000\n",
       "75%         489.000000\n",
       "max      203699.000000\n",
       "Name: code1_len, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame[\"code1_len\"] = data_frame[\"code1\"].apply(len)\n",
    "data_frame[\"code1_len\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b21656d-7b75-4d45-9b0a-b9104e962b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    179700.000000\n",
       "mean        390.010367\n",
       "std        1333.079216\n",
       "min          15.000000\n",
       "25%         146.000000\n",
       "50%         254.000000\n",
       "75%         477.000000\n",
       "max      203669.000000\n",
       "Name: code2_len, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame[\"code2_len\"] = data_frame[\"code2\"].apply(len)\n",
    "data_frame[\"code2_len\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05512b08-2ae0-45f4-88a9-51a6c305e7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, valid_df, train_label, valid_label = train_test_split(\n",
    "    ndf,\n",
    "    ndf[\"problem_num\"],\n",
    "    random_state=42,\n",
    "    test_size=0.1,\n",
    "    stratify=ndf[\"problem_num\"],\n",
    ")\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "valid_df = valid_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "805610e6-369e-4903-8dfa-481af9691617",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159cc5e4-3a67-4b04-8456-bd102bae75f9",
   "metadata": {},
   "source": [
    "#### Train negative pair 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4ed7de96-95fe-4249-9578-dfdad15ccf66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 300/300 [14:45<00:00,  2.95s/it]\n"
     ]
    }
   ],
   "source": [
    "codes = train_df[\"code\"].to_list()\n",
    "problems = train_df[\"problem_num\"].unique().tolist()\n",
    "problems.sort()\n",
    "\n",
    "tokenized_corpus = [tokenizer.tokenize(code) for code in codes]\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "total_positive_pairs = list()\n",
    "total_negative_pairs = list()\n",
    "\n",
    "for problem in tqdm(problems):\n",
    "    solution_codes = train_df[train_df[\"problem_num\"] == problem][\"code\"]\n",
    "    positive_pairs = list(combinations(solution_codes.to_list(), 2))\n",
    "    \n",
    "    solution_codes_indices = solution_codes.index.to_list()\n",
    "    negative_pairs = list()\n",
    "    \n",
    "    first_tokenized_code = tokenizer.tokenize(positive_pairs[0][0])\n",
    "    negative_code_scores = bm25.get_scores(first_tokenized_code)\n",
    "    negative_code_ranking = negative_code_scores.argsort()[::-1]\n",
    "    ranking_idx = 0\n",
    "    \n",
    "    for solution_code in solution_codes:\n",
    "        negative_solutions = list()\n",
    "        while len(negative_solutions) < len(positive_pairs) // len(solution_codes):\n",
    "            high_score_idx = negative_code_ranking[ranking_idx]\n",
    "            \n",
    "            if high_score_idx not in solution_codes_indices:\n",
    "                negative_solutions.append(train_df[\"code\"].iloc[high_score_idx])\n",
    "            ranking_idx += 1\n",
    "        \n",
    "        for negative_solution in negative_solutions:\n",
    "            negative_pairs.append((solution_code, negative_solution))\n",
    "    \n",
    "    total_positive_pairs.extend(positive_pairs)\n",
    "    total_negative_pairs.extend(negative_pairs)\n",
    "\n",
    "pos_code1 = list(map(lambda x : x[0], total_positive_pairs))\n",
    "pos_code2 = list(map(lambda x : x[1], total_positive_pairs))\n",
    "\n",
    "neg_code1 = list(map(lambda x : x[0], total_negative_pairs))\n",
    "neg_code2 = list(map(lambda x : x[1], total_negative_pairs))\n",
    "\n",
    "pos_label = [1] * len(pos_code1)\n",
    "neg_label = [0] * len(neg_code1)\n",
    "\n",
    "pos_code1.extend(neg_code1)\n",
    "total_code1 = pos_code1\n",
    "pos_code2.extend(neg_code2)\n",
    "total_code2 = pos_code2\n",
    "pos_label.extend(neg_label)\n",
    "total_label = pos_label\n",
    "pair_data = pd.DataFrame(data={\n",
    "    \"code1\" : total_code1,\n",
    "    \"code2\" : total_code2,\n",
    "    \"similar\" : total_label\n",
    "})\n",
    "pair_data = pair_data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "pair_data.to_csv(\"./data/train_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1597b05-bdef-4af0-b1d1-62dfa32e9dd7",
   "metadata": {},
   "source": [
    "#### Validation negative pair 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "eaf8cf9d-12e1-4de7-afad-a8afe64ca4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 300/300 [00:55<00:00,  5.39it/s]\n"
     ]
    }
   ],
   "source": [
    "codes = valid_df[\"code\"].to_list()\n",
    "problems = valid_df[\"problem_num\"].unique().tolist()\n",
    "problems.sort()\n",
    "\n",
    "tokenized_corpus = [tokenizer.tokenize(code) for code in codes]\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "total_positive_pairs = list()\n",
    "total_negative_pairs = list()\n",
    "\n",
    "for problem in tqdm(problems):\n",
    "    solution_codes = valid_df[valid_df[\"problem_num\"] == problem][\"code\"]\n",
    "    positive_pairs = list(combinations(solution_codes.to_list(), 2))\n",
    "    \n",
    "    solution_codes_indices = solution_codes.index.to_list()\n",
    "    negative_pairs = list()\n",
    "    \n",
    "    first_tokenized_code = tokenizer.tokenize(positive_pairs[0][0])\n",
    "    negative_code_scores = bm25.get_scores(first_tokenized_code)\n",
    "    negative_code_ranking = negative_code_scores.argsort()[::-1]\n",
    "    ranking_idx = 0\n",
    "    \n",
    "    for solution_code in solution_codes:\n",
    "        negative_solutions = list()\n",
    "        while len(negative_solutions) < len(positive_pairs) // len(solution_codes):\n",
    "            high_score_idx = negative_code_ranking[ranking_idx]\n",
    "            \n",
    "            if high_score_idx not in solution_codes_indices:\n",
    "                negative_solutions.append(valid_df[\"code\"].iloc[high_score_idx])\n",
    "            ranking_idx += 1\n",
    "        \n",
    "        for negative_solution in negative_solutions:\n",
    "            negative_pairs.append((solution_code, negative_solution))\n",
    "    \n",
    "    total_positive_pairs.extend(positive_pairs)\n",
    "    total_negative_pairs.extend(negative_pairs)\n",
    "\n",
    "pos_code1 = list(map(lambda x : x[0], total_positive_pairs))\n",
    "pos_code2 = list(map(lambda x : x[1], total_positive_pairs))\n",
    "\n",
    "neg_code1 = list(map(lambda x : x[0], total_negative_pairs))\n",
    "neg_code2 = list(map(lambda x : x[1], total_negative_pairs))\n",
    "\n",
    "pos_label = [1] * len(pos_code1)\n",
    "neg_label = [0] * len(neg_code1)\n",
    "\n",
    "pos_code1.extend(neg_code1)\n",
    "total_code1 = pos_code1\n",
    "pos_code2.extend(neg_code2)\n",
    "total_code2 = pos_code2\n",
    "pos_label.extend(neg_label)\n",
    "total_label = pos_label\n",
    "pair_data = pd.DataFrame(data={\n",
    "    \"code1\" : total_code1,\n",
    "    \"code2\" : total_code2,\n",
    "    \"similar\" : total_label\n",
    "})\n",
    "pair_data = pair_data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "pair_data.to_csv(\"./data/valid_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de202a2-f602-482b-a67c-e844465ce7f6",
   "metadata": {},
   "source": [
    "#### Train Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c74dc87b-f2c5-4f6a-a7ca-07aa8a8406d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/microsoft/graphcodebert-base/resolve/main/config.json from cache at /home/piai/.cache/huggingface/transformers/8edef9fb59cf1f2670191d673b13a719a79361a2ae12cc806f942649b8b90db8.62db6c94b05689b7cb238a1a38840e19d1014fc755a9e328ab74a6c672db2d3d\n",
      "Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/microsoft/graphcodebert-base/resolve/main/pytorch_model.bin from cache at /home/piai/.cache/huggingface/transformers/790fa523a045ef75a0bb2c78f19ccb8531275871a4a2a88b524292725e0e65c8.459848ee0fb5942db5cb70ab4db4066013ff7b1f52071fc5e5792f691a813b6c\n",
      "Some weights of the model checkpoint at microsoft/graphcodebert-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, RobertaForSequenceClassification\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = AutoModel.from_pretrained(\"microsoft/graphcodebert-base\")\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"microsoft/graphcodebert-base\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788ee5e6-7b3a-4321-b0b5-cf22d85df485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b7a3d399-1e6e-46e0-8594-f7750548c5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, Trainer, TrainingArguments, DataCollatorWithPadding, EarlyStoppingCallback\n",
    "import numpy as np\n",
    "from datasets import load_dataset, load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f896608f-52c9-438d-974f-79026ce23268",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-ce35a410e25f9cbd\n",
      "Reusing dataset csv (/home/piai/.cache/huggingface/datasets/csv/default-ce35a410e25f9cbd/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dad45b673c80494aa870e87b8c1bdf8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-cc9a8ee57a12244a\n",
      "Reusing dataset csv (/home/piai/.cache/huggingface/datasets/csv/default-cc9a8ee57a12244a/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f45336a5b77e40d9b007861f4b499a1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e52bedc27a33482a9db734e7f6a8b492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5133767 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf3b1c5081894298ae83ed568114a29c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59389 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f4458c2cf7e4a33ab81b915decb8311",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/1.84k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL = \"microsoft/graphcodebert-base\"\n",
    "INPUT = \"./data/train_data.csv\"\n",
    "VAL_INPUT = \"./data/valid_data.csv\"\n",
    "MAX_LEN = 512\n",
    "\n",
    "dataset = load_dataset(\"csv\", data_files=INPUT)['train']\n",
    "val_dataset = load_dataset(\"csv\", data_files=VAL_INPUT)[\"train\"]\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n",
    "def example_fn(examples):\n",
    "    outputs = tokenizer(examples['code1'], examples['code2'], padding=True, max_length=MAX_LEN,truncation=True)\n",
    "    if 'similar' in examples:\n",
    "        outputs[\"labels\"] = examples[\"similar\"]\n",
    "    return outputs\n",
    "\n",
    "dataset = dataset.map(example_fn, remove_columns=['code1', 'code2', 'similar'])\n",
    "val_dataset = val_dataset.map(example_fn, remove_columns=[\"code1\", \"code2\", \"similar\"])\n",
    "    \n",
    "# model = RobertaForSequenceClassification.from_pretrained(MODEL) # RobertaForSequenceClassification 는 BertForSequenceClassification 와 달리 pooler가 없는게 기본이기 때문에 문장 유사도에 사용 가능.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "9641de08-17ba-4702-b065-cb5c7ca85b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "_metric = load_metric(\"glue\", \"sst2\")\n",
    "\n",
    "def metric_fn(p):\n",
    "    preds, labels = p\n",
    "    output =  _metric.compute(references=labels, predictions=np.argmax(preds, axis=-1))\n",
    "    return output\n",
    "\n",
    "args = TrainingArguments(\n",
    "    './runs/',\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    #save_strategy=\"epoch\",\n",
    "    save_strategy=\"steps\",\n",
    "    #logging_strategy=\"epoch\",\n",
    "    logging_strategy=\"steps\",\n",
    "    #evaluation_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    learning_rate=2e-5,\n",
    "    #metric_for_best_model= \"f1\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        data_collator=_collator,\n",
    "        train_dataset=dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics= metric_fn,\n",
    "        callbacks = [EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "7be02611-122c-44d1-a147-e4d020cd6da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 5133767\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1925163\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3000' max='1925163' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   3000/1925163 1:25:52 < 917:40:57, 0.58 it/s, Epoch 0/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.040500</td>\n",
       "      <td>0.861998</td>\n",
       "      <td>0.908367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.272800</td>\n",
       "      <td>0.401158</td>\n",
       "      <td>0.896631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.213100</td>\n",
       "      <td>0.296671</td>\n",
       "      <td>0.923690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.200300</td>\n",
       "      <td>0.245116</td>\n",
       "      <td>0.932530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.197500</td>\n",
       "      <td>0.259828</td>\n",
       "      <td>0.938659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.168900</td>\n",
       "      <td>0.271056</td>\n",
       "      <td>0.931267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./runs/checkpoint-500\n",
      "Configuration saved in ./runs/checkpoint-500/config.json\n",
      "Model weights saved in ./runs/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ./runs/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ./runs/checkpoint-500/special_tokens_map.json\n",
      "/home/piai/anaconda3/envs/iml/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./runs/checkpoint-1000\n",
      "Configuration saved in ./runs/checkpoint-1000/config.json\n",
      "Model weights saved in ./runs/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in ./runs/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in ./runs/checkpoint-1000/special_tokens_map.json\n",
      "/home/piai/anaconda3/envs/iml/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./runs/checkpoint-1500\n",
      "Configuration saved in ./runs/checkpoint-1500/config.json\n",
      "Model weights saved in ./runs/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in ./runs/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in ./runs/checkpoint-1500/special_tokens_map.json\n",
      "/home/piai/anaconda3/envs/iml/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./runs/checkpoint-2000\n",
      "Configuration saved in ./runs/checkpoint-2000/config.json\n",
      "Model weights saved in ./runs/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in ./runs/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in ./runs/checkpoint-2000/special_tokens_map.json\n",
      "/home/piai/anaconda3/envs/iml/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./runs/checkpoint-2500\n",
      "Configuration saved in ./runs/checkpoint-2500/config.json\n",
      "Model weights saved in ./runs/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in ./runs/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in ./runs/checkpoint-2500/special_tokens_map.json\n",
      "/home/piai/anaconda3/envs/iml/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 59389\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./runs/checkpoint-3000\n",
      "Configuration saved in ./runs/checkpoint-3000/config.json\n",
      "Model weights saved in ./runs/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in ./runs/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in ./runs/checkpoint-3000/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./runs/checkpoint-2000 (score: 0.24511641263961792).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3000, training_loss=0.18219283294677735, metrics={'train_runtime': 5153.5255, 'train_samples_per_second': 2988.498, 'train_steps_per_second': 373.562, 'total_flos': 6054395050455840.0, 'train_loss': 0.18219283294677735, 'epoch': 0.0})"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gpu cashe clear\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "e6d7cca2-ace1-4bfd-9b93-facbb3ad44e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default-e82830c223845fb2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/piai/.cache/huggingface/datasets/csv/default-e82830c223845fb2/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec130b7ed0f74048bf6e568ddde4af0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f5b07056f844b8d9617575db60b5d24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/piai/.cache/huggingface/datasets/csv/default-e82830c223845fb2/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0feeb9a7c5e4412972d1fdb46914900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4e16f8c90094e8cb0693bd0398310f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/179700 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: pair_id. If pair_id are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 179700\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5616' max='5616' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5616/5616 33:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "TEST = \"./data/test.csv\"\n",
    "SUB = \"./data/sample_submission.csv\"\n",
    "\n",
    "test_dataset = load_dataset(\"csv\", data_files=TEST)[\"train\"]\n",
    "test_dataset = test_dataset.map(example_fn, remove_columns=[\"code1\", \"code2\"])\n",
    "\n",
    "predictions = trainer.predict(test_dataset)\n",
    "\n",
    "df = pd.read_csv(SUB)\n",
    "df[\"similar\"] = np.argmax(predictions.predictions, axis=-1)\n",
    "df.to_csv(\"./submissions/submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7901ec6-65e5-4f15-aa81-c3438f613b0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
